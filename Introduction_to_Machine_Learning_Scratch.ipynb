{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Introduction_to_Machine_Learning_Scratch.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Wh9FyvkhptzQNL7DbQw_mKFqkxVav3Ng","authorship_tag":"ABX9TyNtpD4TnaSF7k9KaWp0cb7K"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"cI6ci8F44QO3"},"source":["Sprintの目的\n","機械学習スクラッチの準備をする\n","\n","どのように学ぶか\n","今後の学習でスクラッチで実装する機械学習プログラムを、まずは scikit-learn を用いて実装します。"]},{"cell_type":"markdown","metadata":{"id":"zCKigBuE4QYS"},"source":["2.スクラッチとは\n","\n","NumPy などに備わっている基本的なライブラリを組み合わせることで、scikit-learn などの応用的なライブラリに実装されている機能と等価なクラス・関数を自作することができます。これをスクラッチと呼びます。\n","\n","\n","スクラッチを通して、scikit-learnなどのライブラリを動かすだけでは掴みづらい、アルゴリズムの深い理解を目指します。コーディングのスキル向上も兼ねていますが、それは主な目的ではありません。\n","\n","\n","以下のような効果を狙っています。\n","\n","\n","新たな手法に出会った時に理論・数式を理解しやすくする\n","ライブラリを使う上での曖昧さを減らす\n","既存の実装を読みやすくする\n","\n","今回はまず、機械学習のプログラムを完全にはスクラッチせず、scikit-learn を用いて実装します。そして、次回から段階的に scikit-learn を用いた実装をスクラッチに移行していきます。\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2tWvB7Cw4Qhn"},"source":["【問題1】train_test_split のスクラッチ\n","まずは、scikit-learnの train_test_split をスクラッチしてみます。以下の雛形をベースに関数を実装してください。\n","\n","\n","sklearn.model_selection.train_test_split - scikit-learn stable version documentation\n","\n","\n","なお、作成した関数がscikit-learnの train_test_split と同じ動作をするか必ず確認をしましょう。\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JP7eJdjY5J3u"},"source":["雛形\n","\n","\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","def scratch_train_test_split(X, y, train_size=0.8):\n","    \"\"\"検証データを分割する。\n","    Parameters\n","    ----------\n","    X : ndarray\n","      訓練データ (n_samples, n_features)\n","    y : ndarray\n","      正解値 (n_samples,)\n","    train_size : float\n","      何割をtrainとするか指定 (0 < train_size < 1)\n","    Returns\n","    -------\n","    X_train : ndarray\n","      訓練データ (n_samples, n_features)\n","    X_test : ndarray\n","      検証データ (n_samples, n_features)\n","    y_train : ndarray\n","      訓練データの正解値 (n_samples,)\n","    y_test : ndarray\n","      検証データの正解値 (n_samples,)\n","    \"\"\"\n","    # ここにコードを書く\n","    pass\n","    return X_train, X_test, y_train, y_test\n","\n"]},{"cell_type":"code","metadata":{"id":"KhXz1eFa5Q9g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627022994918,"user_tz":-540,"elapsed":356,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"d0d43437-7048-43e4-97d0-cdd55d4c4914"},"source":["import numpy as np\n","# import pandas as pd\n","# import matplotlib\n","# import matplotlib.pyplot as plt\n","# %matplotlib inline\n","# import warnings\n","# warnings.filterwarnings('ignore')\n","\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","# from sklearn.svm import LinearSVC\n","\n","iris_dataset = load_iris()\n","\n","#説明変数\n","iris_dataset_data = pd.DataFrame(iris_dataset.data, columns=[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"])\n","iris_dataset_all = pd.concat([iris_dataset_data], axis=1)\n","X = iris_dataset_all\n","# print(X)\n","# print(type(X))\n","#目的変数（花の種類）も同様にyに格納してください。\n","iris_dataset_target = pd.DataFrame(iris_dataset.target, columns=[\"Species\"])\n","iris_dataset_all2 = pd.concat([iris_dataset_target], axis=1)\n","y = iris_dataset_all2\n","# print(type(y))\n","\n","oldy=y[(y['Species'] == 1) | (y['Species'] == 2)]#virgicolorとvirginica\n","# print(type(oldy))\n","# print(oldy)\n","\n","X = iris_dataset_all\n","# print(\"sepal_lengthとpetal_lengthのndarray\")\n","X=X.loc[50:149,[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"]]\n","sc=preprocessing.StandardScaler()\n","# sc=StandardScaler()\n","sc.fit(X)\n","X_std=sc.transform(X)\n","X=X_std\n","y=oldy\n","\n","\n","def scratch_train_test_split(X, y, train_size=0.8):\n","    \"\"\"検証データを分割する。\n","    Parameters\n","    ----------\n","    X : ndarray\n","      訓練データ (n_samples, n_features)\n","    y : ndarray\n","      正解値 (n_samples,)\n","    train_size : float\n","      何割をtrainとするか指定 (0 < train_size < 1)\n","    Returns\n","    -------\n","    X_train : ndarray\n","      訓練データ (n_samples, n_features)\n","    X_test : ndarray\n","      検証データ (n_samples, n_features)\n","    y_train : ndarray\n","      訓練データの正解値 (n_samples,)\n","    y_test : ndarray\n","      検証データの正解値 (n_samples,)\n","    \"\"\"\n","    # ここにコードを書く\n","    # X_train = X * train_size\n","    # y_train = y * train_size\n","    # X_test =  X * (1 - train_size)\n","    # y_test = y * (1 - train_size)\n","\n","       # make several parameters to be used\n","    n_samples = X.shape[0]\n","    n_train = np.floor((1-train_size) * n_samples).astype(int)\n","    n_test = n_samples - n_train\n","    # classes = np.unique(y)\n","    # n_classes = len(classes)\n","    # class_counts = np.bincount(y)\n","    # class_indices = np.split(np.argsort(y, kind='mergesort'),\n","    #                          np.cumsum(class_counts)[:-1])\n","\n","    X_train = X[:n_test-1]\n","    # print(len(X_train))\n","    X_test = X[n_test-1:(n_test + n_train)]\n","    # print(len(X_test))\n","    y_train = y[:n_test-1]\n","    y_test = y[n_test-1:(n_test + n_train)]\n","    pass\n","    return X_train, X_test, y_train, y_test\n","\n","print(\"scratch_train_test_splitのデータ分割結果（学習データ８割、検証データ２割になっていること示す）\")\n","X_train, X_test, train_label, test_label= scratch_train_test_split(X, y, train_size= 0.8)\n","print(\"X_train\")\n","# print(X_train)\n","# print(type(X_train))\n","print(len(X_train))\n","print(\"X_test\")\n","# print(X_test)\n","# print(type(X_test))\n","print(len(X_test))\n","print(\"y_train\")\n","# print(y_train)\n","# print(type(y_train))\n","print(len(y_train))\n","print(\"y_test\")\n","# print(y_test)\n","# print(type(y_test))\n","print(len(y_test))\n","\n","print(\"---------------------------------\")\n","print(\"train_test_splitのデータ分割結果（学習データ８割、検証データ２割になっていること示す）\")\n","X_train, X_test, train_label, test_label = train_test_split(X, y, train_size= 0.8, test_size=0.2)\n","print(\"X_train2\")\n","# print(X_train)\n","# print(type(X_train))\n","print(len(X_train))\n","print(\"X_test2\")\n","# print(X_test)\n","# print(type(X_test))\n","print(len(X_test))\n","print(\"y_train2\")\n","# print(y_train)\n","# print(type(y_train))\n","print(len(y_train))\n","print(\"y_test2\")\n","# print(y_test)\n","# print(type(y_test))\n","print(len(y_test))\n"],"execution_count":221,"outputs":[{"output_type":"stream","text":["scratch_train_test_splitのデータ分割結果（学習データ８割、検証データ２割になっていること示す）\n","X_train\n","80\n","X_test\n","20\n","y_train\n","80\n","y_test\n","20\n","---------------------------------\n","train_test_splitのデータ分割結果（学習データ８割、検証データ２割になっていること示す）\n","X_train2\n","80\n","X_test2\n","20\n","y_train2\n","80\n","y_test2\n","20\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yanGF-EScHNT"},"source":["3.scikit-learnを用いて機械学習を行うコードの実装\n","\n","scikit-learnを使ったコードを実装しベースラインモデルを作成していきます。\n","\n","\n","検証データの分割には問題1で作成した自作の関数を用いてください。クロスバリデーションではなくホールドアウト法で構いません。\n","\n","\n","分類問題\n","分類は3種類の手法をscikit-learnを使って実装します。\n","\n","\n","ロジスティック回帰\n","SVM\n","決定木\n","\n","scikit-learnにおいてLogisticRegressionクラスとSGDClassifierクラスの2種類から使用できます。ここでは勾配降下法を用いて計算するSGDClassifierクラスを利用してください。引数でloss=”log”とすることでロジスティック回帰の計算になります。\n","\n","\n","scikit-learn にはロジスティック回帰に使える分類器として LogisticRegression クラスと SGDClassifier クラスが用意されています。ここでは勾配降下法を用いて計算する SGDClassifier クラスを用います。引数で loss=\"log\" を指定することでロジスティック回帰の計算ができます。\n","\n","\n","sklearn.linear_model.SGDClassifier — scikit-learn 0.21.3 documentation\n","sklearn.svm.SVC — scikit-learn 0.21.3 documentation\n","sklearn.tree.DecisionTreeClassifier — scikit-learn 0.21.3 documentation\n","\n","3種類のデータセットを用いて動作を確認します。\n","\n","\n","1つ目は事前学習期間同様のirisデータセットです。\n","\n","\n","sklearn.datasets.load_iris - scikit-learn stable version documentation\n","\n","\n","2値分類としたいため、以下の2つの目的変数のみ利用します。特徴量は4種類すべて使います。\n","\n","\n","virgicolorとvirginica\n","\n","残り2つは特徴量が2つのデータセットを人工的に用意します。以下のコードで説明変数X,目的変数yが作成可能です。「シンプルデータセット1」「シンプルデータセット2」とします。特徴量が2つであるため可視化が容易です。\n","\n","\n","シンプルデータセット1作成コード\n","\n","\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","import numpy as np\n","np.random.seed(seed=0)\n","n_samples = 500\n","f0 = [-1, 2]\n","f1 = [2, -1]\n","cov = [[1.0,0.8], [0.8, 1.0]]\n","f0 = np.random.multivariate_normal(f0, cov, n_samples // 2)\n","f1 = np.random.multivariate_normal(f1, cov, n_samples // 2)\n","X = np.concatenate([f0, f1])\n","y = np.concatenate([\n","    np.full(n_samples // 2, 1),\n","    np.full(n_samples // 2, -1)\n","])\n","\n","シンプルデータセット2作成コード\n","\n","\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","X = np.array([\n","    [-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n","    [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n","    [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n","    [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n","    [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n","    [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n","    [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n","    [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n","    [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n","    [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n","    [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n","    [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n","    [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n","    [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n","    [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n","    [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n","    [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n","    [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n","    [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n","    [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ],\n","])\n","y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"]},{"cell_type":"markdown","metadata":{"id":"n-pJ7TLJ5KAs"},"source":["【問題2】 分類問題を解くコードの作成\n","上記3種類の手法で3種類のデータセットを学習・推定するコードを作成してください。\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y1WMQvrtbMSk","executionInfo":{"status":"ok","timestamp":1627022995299,"user_tz":-540,"elapsed":26,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"96b9fe8a-d915-4ba4-f951-dcc3f144cd40"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import LinearSVC\n","\n","iris_dataset = load_iris()\n","\n","#説明変数\n","iris_dataset_data = pd.DataFrame(iris_dataset.data, columns=[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"])\n","iris_dataset_all = pd.concat([iris_dataset_data], axis=1)\n","X = iris_dataset_all\n","print(X)\n","print(type(X))\n","#目的変数（花の種類）も同様にyに格納してください。\n","iris_dataset_target = pd.DataFrame(iris_dataset.target, columns=[\"Species\"])\n","iris_dataset_all2 = pd.concat([iris_dataset_target], axis=1)\n","y = iris_dataset_all2\n","print(type(y))\n","# print(y)\n","\n","# print(\"sepal_lengthとpetal_lengthのデータフレーム\")\n","# x=X.loc[:,['sepal_length','petal_length']]\n","# print(type(x))\n","# print(x)\n","\n","oldy=y[(y['Species'] == 1) | (y['Species'] == 2)]#virgicolorとvirginica\n","print(type(oldy))\n","print(oldy)\n","\n"],"execution_count":222,"outputs":[{"output_type":"stream","text":["     sepal_length  sepal_width  petal_length  petal_width\n","0             5.1          3.5           1.4          0.2\n","1             4.9          3.0           1.4          0.2\n","2             4.7          3.2           1.3          0.2\n","3             4.6          3.1           1.5          0.2\n","4             5.0          3.6           1.4          0.2\n","..            ...          ...           ...          ...\n","145           6.7          3.0           5.2          2.3\n","146           6.3          2.5           5.0          1.9\n","147           6.5          3.0           5.2          2.0\n","148           6.2          3.4           5.4          2.3\n","149           5.9          3.0           5.1          1.8\n","\n","[150 rows x 4 columns]\n","<class 'pandas.core.frame.DataFrame'>\n","<class 'pandas.core.frame.DataFrame'>\n","<class 'pandas.core.frame.DataFrame'>\n","     Species\n","50         1\n","51         1\n","52         1\n","53         1\n","54         1\n","..       ...\n","145        2\n","146        2\n","147        2\n","148        2\n","149        2\n","\n","[100 rows x 1 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hiBGRFZl5ZSk","executionInfo":{"status":"ok","timestamp":1627022995299,"user_tz":-540,"elapsed":24,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}}},"source":["# import numpy as np\n","# from sklearn.linear_model import SGDClassifier\n","# from sklearn.preprocessing import StandardScaler\n","# from sklearn.pipeline import make_pipeline\n","# from sklearn.pipeline import Pipeline\n","# X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n","# Y = np.array([1, 1, 2, 2])\n","# # Always scale the input. The most convenient way is to use a pipeline.\n","# clf = make_pipeline(StandardScaler(),\n","#                    SGDClassifier(max_iter=1000, tol=1e-3))\n","# clf.fit(X, Y)\n","# Pipeline(steps=[('standardscaler', StandardScaler()),\n","#                 ('sgdclassifier', SGDClassifier())])\n","# print(clf.predict([[-0.8, -1]]))"],"execution_count":223,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jBtQ8IxGhJZR","executionInfo":{"status":"ok","timestamp":1627022995300,"user_tz":-540,"elapsed":24,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"fe1b9368-e14b-4f16-81e1-2f5f2f88ad26"},"source":["#解説 1：ライブラリのインポート--------------------------------\n","import numpy as np #numpyという行列などを扱うライブラリを利用\n","import pandas as pd #pandasというデータ分析ライブラリを利用\n","import matplotlib.pyplot as plt #プロット用のライブラリを利用\n","#from sklearn import linear_model, metrics, preprocessing, cross_validation #機械学習用のライブラリを利用\n","from sklearn import linear_model, metrics, preprocessing #機械学習用のライブラリを利用\n","from mlxtend.plotting import plot_decision_regions #学習結果をプロットする外部ライブラリを利用\n","from sklearn.preprocessing import StandardScaler\n","\n","\n","# #解説 2：Wineのデータセットを読み込む--------------------------------\n","# df_wine_all=pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header=None)\n","# #品種(0列、1～3)と色（10列）とプロリンの量(13列)を使用する\n","# df_wine=df_wine_all[[0,10,13]]\n","# df_wine.columns = [u'class', u'color', u'proline']\n","# pd.DataFrame(df_wine)  #この行を実行するとデータが見れる\n"," \n","# #解説 3：プロットしてみる------------------------------------------------------\n","# %matplotlib inline\n"," \n","# x=df_wine[\"color\"]\n","# y=df_wine[\"proline\"]\n","# z=df_wine[\"class\"]-1\n","# #plt.scatter(x,y, c=z)\n","# #plt.show\n"," \n","#解説 4：データの整形-------------------------------------------------------\n","# X=df_wine[[\"color\",\"proline\"]]\n","\n","X = iris_dataset_all\n","print(\"sepal_lengthとpetal_lengthのndarray\")\n","X=X.loc[50:149,[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"]]\n","sc=preprocessing.StandardScaler()\n","# sc=StandardScaler()\n","sc.fit(X)\n","X_std=sc.transform(X)\n","X=X_std\n","y=oldy\n","\n","#解説 5：機械学習で分類する---------------------------------------------------\n","#clf_result=linear_model.SGDClassifier(loss=\"hinge\") #loss=\"hinge\", loss=\"log\"\n","clf_result=linear_model.SGDClassifier(loss=\"log\") #loss=\"hinge\", loss=\"log\"\n"," \n"," \n","# #解説 6：K分割交差検証（cross validation）で性能を評価する---------------------\n","# scores=cross_validation.cross_val_score(clf_result, X_std, z, cv=10)\n","# print(\"平均正解率 = \", scores.mean())\n","# print(\"正解率の標準偏差 = \", scores.std())\n"," \n","#解説 7：トレーニングデータとテストデータに分けて実行してみる------------------\n","# X_train, X_test, train_label, test_label=cross_validation.train_test_split(X_std,z, test_size=0.1, random_state=0)\n","X_train, X_test, train_label, test_label=scratch_train_test_split(X, y, train_size=0.8)\n","# X_train, X_test, train_label, test_label= train_test_split(X, y, train_size= 0.8, test_size=0.2)\n","# print(X_train)\n","# print(type(X_train))\n","# print(X_test)\n","# print(type(X_test))\n","# print(train_label)\n","# print(type(train_label))\n","# print(test_label)\n","# print(type(test_label))\n","\n","clf_result.fit(X_train, train_label)\n","#正答率を求める\n","pre=clf_result.predict(X_test)\n","print(\"予測値=\",pre)\n","ac_score=metrics.accuracy_score(test_label,pre)\n","print(\"正答率 = \",ac_score)\n","#plotする\n","X_train_plot=np.vstack(X_train)\n","train_label_plot=np.hstack(train_label)\n","X_test_plot=np.vstack(X_test)\n","test_label_plot=np.hstack(test_label)\n","#plot_decision_regions(X_train_plot, train_label_plot, clf=clf_result, res=0.01) #学習データをプロット\n","# plot_decision_regions(X_test_plot, test_label_plot, clf=clf_result, res=0.01, legend=2) #テストデータをプロット\n"," \n"," \n","#解説 8：任意のデータに対する識別結果を見てみる------------------\n","#predicted_label=clf_result.predict([1,-1])\n","#print(\"このテストデータのラベル = \", predicted_label)\n"," \n","#解説 9：識別平面の式を手に入れる--------------------------------\n","print(clf_result.intercept_)\n","# print(clf_result.coef_ )  #coef[0]*x+coef[1]*y+intercept=0"],"execution_count":224,"outputs":[{"output_type":"stream","text":["sepal_lengthとpetal_lengthのndarray\n","予測値= [2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n","正答率 =  0.95\n","[-2.29275371]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Tw0B1kwyRae","executionInfo":{"status":"ok","timestamp":1627022995300,"user_tz":-540,"elapsed":20,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"d544b6ad-f7d0-4ead-dff0-8d8e927b60f0"},"source":["#シンプルデータセット1作成コード\n","import numpy as np\n","np.random.seed(seed=0)\n","n_samples = 500\n","f0 = [-1, 2]\n","f1 = [2, -1]\n","cov = [[1.0,0.8], [0.8, 1.0]]\n","f0 = np.random.multivariate_normal(f0, cov, n_samples // 2)\n","f1 = np.random.multivariate_normal(f1, cov, n_samples // 2)\n","X2 = np.concatenate([f0, f1])\n","y2= np.concatenate([\n","    np.full(n_samples // 2, 1),\n","    np.full(n_samples // 2, -1)\n","])\n","\n","\n","#トレーニングデータとテストデータに分けて実行してみる------------------\n","X_train2, X_test2, train_label2, test_label2=scratch_train_test_split(X2, y2, train_size=0.8)\n","\n","\n","clf_result.fit(X_train2, train_label2)\n","\n","#正答率を求める\n","pre2=clf_result.predict(X_test2)\n","print(\"予測値=\",pre2)\n","ac_score2=metrics.accuracy_score(test_label2,pre2)\n","print(\"正答率 = \",ac_score2)"],"execution_count":225,"outputs":[{"output_type":"stream","text":["予測値= [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n"," -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n"," -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n"," -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n"," -1 -1 -1 -1]\n","正答率 =  1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8YsOvu2WyRk5","executionInfo":{"status":"ok","timestamp":1627022995300,"user_tz":-540,"elapsed":17,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"b3b2df0e-fb1f-4993-e788-92a3a85246ef"},"source":["#シンプルデータセット2作成コード\n","X3 = np.array([\n","    [-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n","    [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n","    [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n","    [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n","    [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n","    [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n","    [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n","    [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n","    [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n","    [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n","    [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n","    [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n","    [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n","    [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n","    [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n","    [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n","    [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n","    [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n","    [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n","    [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ],\n","])\n","y3 = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","\n","#トレーニングデータとテストデータに分けて実行してみる------------------\n","X_train3, X_test3, train_label3, test_label3=scratch_train_test_split(X3, y3, train_size=0.8)\n","\n","\n","clf_result.fit(X_train3, train_label3)\n","\n","#正答率を求める\n","pre3=clf_result.predict(X_test3)\n","print(\"予測値=\",pre3)\n","ac_score3=metrics.accuracy_score(test_label3,pre3)\n","print(\"正答率 = \",ac_score3)"],"execution_count":226,"outputs":[{"output_type":"stream","text":["予測値= [0 0 1 0 1 1 1 1]\n","正答率 =  0.625\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M7swixgEunjD","executionInfo":{"status":"ok","timestamp":1627022995301,"user_tz":-540,"elapsed":14,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"78ebe225-0271-4011-dc4d-b1ccdd5822b6"},"source":["#SVM\n","\n","import numpy as np\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","import pandas as pd\n","from sklearn.datasets import load_iris\n","\n","\n","# X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n","# y = np.array([1, 1, 2, 2])\n","\n","\n","iris_dataset = load_iris()\n","\n","#説明変数\n","iris_dataset_data4 = pd.DataFrame(iris_dataset.data, columns=[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"])\n","iris_dataset_all4 = pd.concat([iris_dataset_data4], axis=1)\n","X4 = iris_dataset_all\n","print(X4)\n","print(type(X4))\n","#目的変数（花の種類）も同様にyに格納してください。\n","iris_dataset_target4 = pd.DataFrame(iris_dataset.target, columns=[\"Species\"])\n","iris_dataset_all4 = pd.concat([iris_dataset_target4], axis=1)\n","y4 = iris_dataset_all4\n","print(type(y4))\n","# print(y)\n","\n","oldy4=y4[(y4['Species'] == 1) | (y4['Species'] == 2)]#virgicolorとvirginica\n","print(type(oldy4))\n","print(oldy4)\n","\n","\n","print(\"sepal_lengthとpetal_lengthのndarray\")\n","X4=X4.loc[50:149,[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"]]\n","sc=preprocessing.StandardScaler()\n","# sc=StandardScaler()\n","sc.fit(X4)\n","X_std4=sc.transform(X4)\n","X_std4=X_std4\n","y4=oldy4\n","\n","#トレーニングデータとテストデータに分けて実行してみる------------------\n","X_train4, X_test4, train_label4, test_label4=scratch_train_test_split(X4, y4, train_size=0.8)\n","from sklearn.svm import SVC\n","clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n","clf.fit(X_train4, train_label4)\n","Pipeline(steps=[('standardscaler', StandardScaler()),\n","                ('svc', SVC(gamma='auto'))])"],"execution_count":227,"outputs":[{"output_type":"stream","text":["     sepal_length  sepal_width  petal_length  petal_width\n","0             5.1          3.5           1.4          0.2\n","1             4.9          3.0           1.4          0.2\n","2             4.7          3.2           1.3          0.2\n","3             4.6          3.1           1.5          0.2\n","4             5.0          3.6           1.4          0.2\n","..            ...          ...           ...          ...\n","145           6.7          3.0           5.2          2.3\n","146           6.3          2.5           5.0          1.9\n","147           6.5          3.0           5.2          2.0\n","148           6.2          3.4           5.4          2.3\n","149           5.9          3.0           5.1          1.8\n","\n","[150 rows x 4 columns]\n","<class 'pandas.core.frame.DataFrame'>\n","<class 'pandas.core.frame.DataFrame'>\n","<class 'pandas.core.frame.DataFrame'>\n","     Species\n","50         1\n","51         1\n","52         1\n","53         1\n","54         1\n","..       ...\n","145        2\n","146        2\n","147        2\n","148        2\n","149        2\n","\n","[100 rows x 1 columns]\n","sepal_lengthとpetal_lengthのndarray\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["Pipeline(memory=None,\n","         steps=[('standardscaler',\n","                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n","                ('svc',\n","                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n","                     coef0=0.0, decision_function_shape='ovr', degree=3,\n","                     gamma='auto', kernel='rbf', max_iter=-1, probability=False,\n","                     random_state=None, shrinking=True, tol=0.001,\n","                     verbose=False))],\n","         verbose=False)"]},"metadata":{"tags":[]},"execution_count":227}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"umm-sMZNunw8","executionInfo":{"status":"ok","timestamp":1627022995301,"user_tz":-540,"elapsed":10,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"77b2a338-c5f7-45b8-fe1c-6ed0d881b458"},"source":["# pre3=clf.predict([[-0.8, -1]])\n","pre4=clf.predict(X_test4)\n","print(\"予測値=\",pre4)\n","# pre2=clf_result.predict(X_test2)\n","ac_score4=metrics.accuracy_score(test_label4,pre4)\n","print(\"正答率 = \",ac_score4)"],"execution_count":228,"outputs":[{"output_type":"stream","text":["予測値= [2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n","正答率 =  0.9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-EJoWrF4CMoI","executionInfo":{"status":"ok","timestamp":1627022995557,"user_tz":-540,"elapsed":19,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"1da6b290-f26b-45b1-952d-f66051ac0982"},"source":["#SVMのモデルで、シンプルデータセット１を使用して、学習と正答率を算出する\n","#シンプルデータセット1作成コード\n","import numpy as np\n","np.random.seed(seed=0)\n","n_samples = 500\n","f0 = [-1, 2]\n","f1 = [2, -1]\n","cov = [[1.0,0.8], [0.8, 1.0]]\n","f0 = np.random.multivariate_normal(f0, cov, n_samples // 2)\n","f1 = np.random.multivariate_normal(f1, cov, n_samples // 2)\n","X4_2 = np.concatenate([f0, f1])\n","y4_2= np.concatenate([\n","    np.full(n_samples // 2, 1),\n","    np.full(n_samples // 2, -1)\n","])\n","\n","\n","#トレーニングデータとテストデータに分けて実行してみる------------------\n","X_train4_2, X_test4_2, train_label4_2, test_label4_2=scratch_train_test_split(X4_2, y4_2, train_size=0.8)\n","\n","\n","clf.fit(X_train4_2, train_label4_2)\n","\n","#正答率を求める\n","pre4_2=clf.predict(X_test4_2)\n","print(\"予測値=\",pre4_2)\n","ac_score4_2=metrics.accuracy_score(test_label4_2,pre4_2)\n","print(\"正答率 = \",ac_score4_2)"],"execution_count":229,"outputs":[{"output_type":"stream","text":["予測値= [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n"," -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n"," -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n"," -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n"," -1 -1 -1 -1]\n","正答率 =  1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v_EamqumEbbX","executionInfo":{"status":"ok","timestamp":1627022995558,"user_tz":-540,"elapsed":18,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"7ac04c5a-06b3-41b6-85c8-3dd57a1d7ac0"},"source":["#SVMのモデルで、シンプルデータセット2を使用して、学習と正答率を算出する\n","#シンプルデータセット2作成コード\n","\n","X4_3 = np.array([\n","    [-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n","    [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n","    [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n","    [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n","    [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n","    [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n","    [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n","    [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n","    [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n","    [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n","    [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n","    [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n","    [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n","    [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n","    [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n","    [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n","    [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n","    [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n","    [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n","    [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ],\n","])\n","y4_3 = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","\n","#トレーニングデータとテストデータに分けて実行してみる------------------\n","X_train4_3, X_test4_3, train_label4_3, test_label4_3=scratch_train_test_split(X4_3, y4_3, train_size=0.8)\n","\n","\n","clf.fit(X_train4_3, train_label4_3)\n","\n","#正答率を求める\n","pre4_3=clf.predict(X_test4_3)\n","print(\"予測値=\",pre4_3)\n","ac_score4_3=metrics.accuracy_score(test_label4_3,pre4_3)\n","print(\"正答率 = \",ac_score4_3)"],"execution_count":230,"outputs":[{"output_type":"stream","text":["予測値= [0 0 0 0 0 1 0 0]\n","正答率 =  0.125\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p4P0EA5XEbgQ","executionInfo":{"status":"ok","timestamp":1627022995559,"user_tz":-540,"elapsed":15,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"8933c2af-92b2-49c9-bd8d-982729cb261d"},"source":["#決定木\n","from sklearn.datasets import load_iris\n","from sklearn import tree\n","import numpy as np\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","import pandas as pd\n","\n","\n","def main():\n","  # アヤメのデータを読み込む\n","  iris = load_iris()\n","  iris_dataset = load_iris()\n","\n","  #説明変数\n","  iris_dataset_data5 = pd.DataFrame(iris_dataset.data, columns=[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"])\n","  iris_dataset_all5 = pd.concat([iris_dataset_data5], axis=1)\n","  X5 = iris_dataset_all5\n","  # print(X5)\n","  # print(type(X5))\n","  #目的変数（花の種類）も同様にyに格納してください。\n","  iris_dataset_target5 = pd.DataFrame(iris_dataset.target, columns=[\"Species\"])\n","  iris_dataset_all5 = pd.concat([iris_dataset_target5], axis=1)\n","  y5 = iris_dataset_all5\n","  # print(type(y5))\n","  # print(y5)\n","\n","  oldy5=y5[(y5['Species'] == 1) | (y5['Species'] == 2)]#virgicolorとvirginica\n","  # print(type(oldy5))\n","  # print(oldy5)\n","\n","\n","  # print(\"sepal_lengthとpetal_lengthのndarray\")\n","  X5=X5.loc[50:149,[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"]]\n","  sc=preprocessing.StandardScaler()\n","  # sc=StandardScaler()\n","  sc.fit(X5)\n","  X_std5=sc.transform(X5)\n","  X_std5=X_std5\n","  y5=oldy5\n","\n","  #トレーニングデータとテストデータに分けて実行してみる------------------\n","  X_train5, X_test5, train_label5, test_label5=scratch_train_test_split(X5, y5, train_size=0.8)\n","\n","  # モデルを作成\n","  tree_clf = tree.DecisionTreeClassifier(max_depth = 3)\n","  tree_clf = tree_clf.fit(X_train5, train_label5)\n","\n","  # 作成したモデルを用いて予測を実行\n","  predicted = tree_clf.predict(X_test5)\n","\n","  pre5=tree_clf.predict(X_test5)\n","  print(\"予測値=\",pre5)\n","  ac_score5=metrics.accuracy_score(test_label5,pre5)\n","  print(\"正答率 = \",ac_score5)\n","\n","if __name__ == '__main__':\n","  main()"],"execution_count":231,"outputs":[{"output_type":"stream","text":["予測値= [2 2 2 1 1 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2]\n","正答率 =  0.85\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mUrp8JebCM5N","executionInfo":{"status":"ok","timestamp":1627022995559,"user_tz":-540,"elapsed":12,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"5d6240b6-df3a-4dfd-e030-913e080a95d2"},"source":["#決定木シンプルデータセット１で学習と正答率を算出する\n","import numpy as np\n","np.random.seed(seed=0)\n","n_samples = 500\n","f0 = [-1, 2]\n","f1 = [2, -1]\n","cov = [[1.0,0.8], [0.8, 1.0]]\n","f0 = np.random.multivariate_normal(f0, cov, n_samples // 2)\n","f1 = np.random.multivariate_normal(f1, cov, n_samples // 2)\n","X5_2 = np.concatenate([f0, f1])\n","y5_2= np.concatenate([\n","    np.full(n_samples // 2, 1),\n","    np.full(n_samples // 2, -1)\n","])\n","\n","\n","#トレーニングデータとテストデータに分けて実行してみる------------------\n","X_train5_2, X_test5_2, train_label5_2, test_label5_2=scratch_train_test_split(X5_2, y5_2, train_size=0.8)\n","\n"," # モデルを作成\n","tree_clf = tree.DecisionTreeClassifier(max_depth = 3)\n","tree_clf.fit(X_train5_2, train_label5_2)\n","# clf.fit(X_train4_2, train_label4_2)\n","\n","#正答率を求める\n","pre5_2=tree_clf.predict(X_test5_2)\n","print(\"予測値=\",pre5_2)\n","ac_score5_2=metrics.accuracy_score(test_label5_2,pre5_2)\n","print(\"正答率 = \",ac_score5_2)"],"execution_count":232,"outputs":[{"output_type":"stream","text":["予測値= [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1\n"," -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n"," -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n"," -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n"," -1 -1 -1 -1]\n","正答率 =  0.99\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v-gfo7PxLAms","executionInfo":{"status":"ok","timestamp":1627022995837,"user_tz":-540,"elapsed":286,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"c09b4a7d-bc86-4ae9-8b1e-2ec0eeee21c6"},"source":["#決定木シンプルデータセット2で学習と正答率を算出する\n","X5_3 = np.array([\n","    [-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n","    [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n","    [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n","    [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n","    [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n","    [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n","    [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n","    [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n","    [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n","    [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n","    [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n","    [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n","    [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n","    [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n","    [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n","    [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n","    [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n","    [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n","    [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n","    [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ],\n","])\n","y5_3 = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","\n","#トレーニングデータとテストデータに分けて実行してみる------------------\n","X_train5_3, X_test5_3, train_label5_3, test_label5_3=scratch_train_test_split(X5_3, y5_3, train_size=0.8)\n","\n","\n","# clf.fit(X_train5_3, train_label5_3)\n"," # モデルを作成\n","tree_clf = tree.DecisionTreeClassifier(max_depth = 3)\n","tree_clf.fit(X_train5_3, train_label5_3)\n","\n","\n","#正答率を求める\n","pre5_3=clf.predict(X_test5_3)\n","print(\"予測値=\",pre5_3)\n","ac_score5_3=metrics.accuracy_score(test_label5_3,pre5_3)\n","print(\"正答率 = \",ac_score5_3)"],"execution_count":233,"outputs":[{"output_type":"stream","text":["予測値= [0 0 0 0 0 1 0 0]\n","正答率 =  0.125\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MEFMF7nib0dD"},"source":["回帰問題\n","次に回帰は1種類をscikit-learnを使って実装します。\n","\n","\n","線形回帰\n","\n","線形回帰は勾配降下法を用いて計算する SGDRegressor クラスを利用してください。\n","\n","\n","sklearn.linear_model.SGDRegressor - scikit-lear stable version documentation\n","\n","\n","データセットは事前学習期間同様にHouse Pricesコンペティションのものを使います。\n","\n","\n","House Prices: Advanced Regression Techniques\n","\n","\n","train.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使います。\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"1ZQ9sUEC5KIN"},"source":["【問題3】 回帰問題を解くコードの作成\n","線形回帰でHouse Pricesデータセットを学習・推定するコードを作成してください。"]},{"cell_type":"code","metadata":{"id":"YGXj60G249Bb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627022995838,"user_tz":-540,"elapsed":6,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"a9a58d5e-acca-4cbf-8751-3017855e3733"},"source":["import pandas as pd\n","# import os\n","# os.listdir()\n","# print(os.pwd)\n","df = pd.read_csv('/content/drive/MyDrive/DIC/train.csv')\n","# print(df)\n","\n","x=df.loc[:,['GrLivArea','YearBuilt']]\n","# print(type(x))\n","# print(x)\n","\n","target = df.loc[:, ['SalePrice']]\n","# print(target[:])\n","# print(type(target))\n","\n","X=x\n","#print(df.sample(n=3))\n","X = X.sample(n=500)#サンプル数を5００へ絞り込み\n","X=X.values\n","\n","X=X.tolist()\n","scaler = StandardScaler()\n","scaler.fit(X)\n","X6=scaler.transform(X)\n","\n","# 目的変数\n","# Y = boston.target\n","Y = target\n","Y = Y.sample(n=500)#サンプル数を5００へ絞り込み\n","y6=Y.values\n","\n","#トレーニングデータとテストデータに分けて実行してみる------------------\n","X_train6, X_test6, train_label6, test_label6=scratch_train_test_split(X6, y6, train_size=0.8)\n","\n","\n","import numpy as np\n","from sklearn.linear_model import SGDRegressor\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","# n_samples, n_features = 10, 5\n","rng = np.random.RandomState(0)\n","# y = rng.randn(n_samples)\n","# X = rng.randn(n_samples, n_features)\n","\n","# Always scale the input. The most convenient way is to use a pipeline.\n","reg = make_pipeline(StandardScaler(),\n","                  SGDRegressor(max_iter=1000, tol=1e-3))\n","reg.fit(X6, y6)\n","\n","#予測値を求める\n","pre6=reg.predict(X_test6)\n","# print(pre6)\n","# print(pre6.mean())\n","print(\"予測値 は、 \",'{:.1f}'.format(pre6.mean()))\n","\n","#参考\n","# num = 123.456\n","# print('{:.1f}'.format(num))\n","# # => 123.5"],"execution_count":234,"outputs":[{"output_type":"stream","text":["予測値 は、  176716.7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M5-8URcSpQoB","executionInfo":{"status":"ok","timestamp":1627022995839,"user_tz":-540,"elapsed":4,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}}},"source":[""],"execution_count":234,"outputs":[]}]}