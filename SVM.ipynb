{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SVM.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOGZZ9bFlwvKnLOjzMTZIhw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"eLqrksjInWHU"},"source":["Sprintの目的\n","スクラッチを通してSVMを理解する\n","線形モデルと異なる手法に触れる\n"]},{"cell_type":"markdown","metadata":{"id":"SLLlWzVTnpmd"},"source":["2.SVMスクラッチ\n","\n","分類のためのサポートベクターマシン（SVM、サポートベクトルマシン）のクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n","\n","\n","SVMには学習時に分類の間違いを認めるソフトマージンSVMと、認めないハードマージンSVMがありますが、ここでは実装が単純なハードマージンSVMを扱います。\n","\n","\n","以下に雛形を用意してあります。このScratchSVMClassifierクラスにコードを書き加えていってください。\n","\n"]},{"cell_type":"markdown","metadata":{"id":"BiIH-Hz6n5jL"},"source":["【問題1】ラグランジュの未定乗数法による最急降下\n","SVMの学習は、ラグランジュの未定乗数法を用います。サンプル数分のラグランジュ乗数 \n","λ\n"," を用意して、以下の式により更新していきます。この計算を行うメソッドをScratchSVMClassifierクラスに実装してください。\n","\n","\n","\n","$$\n","λ_{i}^{new}=λ_i+α(1−\\sum_{i=1}^{m}λ_jy_iy_jk(x_i,x_j))\n","$$\n","\n","ここで \n","$$\n","k(x_i,x_j)\n","$$\n"," はカーネル関数です。線形カーネルの場合は次のようになります。他のカーネル関数にも対応できるように、この部分は独立したメソッドとしておきましょう。\n","\n","$$\n","k(x_i,x_j)=x_i^Tx_j\n","$$\n","\n","条件として、更新毎に \n","λi>=0\n","を満たす必要があります。満たさない場合は \n","λi=0\n","とします。\n","\n","\n","i,j : サンプルのインデックス\n","\n","\n","$$\n","λ_{i}^{new}: 更新後のi番目のサンプルのラグランジュ乗数\n","$$\n","\n","λi: 更新前のi番目のサンプルのラグランジュ乗数\n","\n","\n","α\n"," : 学習率\n","\n","\n","λ\n","j\n"," : j番目のサンプルのラグランジュ乗数\n","\n","\n","y\n","i\n"," : i番目のサンプルのラベル\n","\n","\n","y\n","j\n"," : j番目のサンプルのラベル\n","\n","\n","x\n","i\n"," : i番目のサンプルの特徴量ベクトル\n","\n","\n","x\n","j\n"," : j番目のサンプルの特徴量ベクトル\n","\n","\n","あるサンプルに対してのすべてのサンプルとの関係を計算していくことになります。\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"ipB3YkFunk3H","executionInfo":{"status":"ok","timestamp":1628650010497,"user_tz":-540,"elapsed":356,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}}},"source":["class ScratchSVMClassifier():\n","    \"\"\"\n","    SVM分類器のスクラッチ実装\n","    Parameters\n","    ----------\n","    num_iter : int\n","      イテレーション数\n","    lr : float\n","      学習率\n","    kernel : str\n","      カーネルの種類。線形カーネル（linear）か多項式カーネル（polly）\n","    threshold : float\n","      サポートベクターを選ぶための閾値\n","    verbose : bool\n","      学習過程を出力する場合はTrue\n","    Attributes\n","    ----------\n","    self.n_support_vectors : int\n","      サポートベクターの数\n","    self.index_support_vectors : 次の形のndarray, shape (n_support_vectors,)\n","      サポートベクターのインデックス\n","    self.X_sv :  次の形のndarray, shape(n_support_vectors, n_features)\n","      サポートベクターの特徴量\n","    self.lam_sv :  次の形のndarray, shape(n_support_vectors, 1)\n","      サポートベクターの未定乗数\n","    self.y_sv :  次の形のndarray, shape(n_support_vectors, 1)\n","      サポートベクターのラベル\n","    \"\"\"\n","    # def __init__(self, num_iter, lr, kernel='linear', threshold=1e-5, verbose=False):\n","    def __init__(self, num_iter, lr, kernel, threshold, verbose):\n","        # ハイパーパラメータを属性として記録\n","        # print(\"num_iter\")\n","        # print(num_iter)\n","        # print(\"kernel\")\n","        # print(kernel)\n","        # print(\"threshold\")\n","        # print(threshold)\n","        # print(\"verbose\")\n","        # print(verbose)\n","        self.iter = num_iter \n","        self.lr = lr \n","        self.kernel = kernel\n","        self.threshold = threshold\n","        self.verbose = verbose\n","        self.lamda = np.array([])  # 初期値\n","        self.lam_sv = np.array([])  # サポートベクターの保存する変数初期値\n","        self.X_sv = np.array([]) #サポートベクターのn番目のラベル初期値\n","        self.y_sv = np.array([]) #サポートベクターのn番目の特徴量初期値\n","        self.sv_pred = np.array([]) #推定値を保存する変数初期値\n","\n","    def fit(self, X, y, X_val=None, y_val=None):\n","        \"\"\"\n","        SVM分類器を学習する。検証データが入力された場合はそれに対する精度もイテレーションごとに計算する。\n","        Parameters\n","        ----------\n","        X : 次の形のndarray, shape (n_samples, n_features)\n","            訓練データの特徴量\n","        y : 次の形のndarray, shape (n_samples, )\n","            訓練データの正解値\n","        X_val : 次の形のndarray, shape (n_samples, n_features)\n","            検証データの特徴量\n","        y_val : 次の形のndarray, shape (n_samples, )\n","            検証データの正解値\n","        \"\"\"\n","        # print(\"X1\")\n","        # print(X)\n","        # print(X.shape)\n","        # print(\"y\")\n","        # print(y)\n","        # print(y.shape)\n","\n","        # m = X.shape[0]\n","        # hoge = np.ones((m, 1))\n","        # X = np.hstack((hoge,X)) #１がいらない\n","\n","        # m2 = X_val.shape[0]\n","        # hoge2 = np.ones((m2, 1))\n","        # X_val = np.hstack((hoge2,X_val))\n","                            \n","        self.lamda = np.zeros(X.shape[0]) #X.shape[1]：行列Xの列数を表す。np.zeros(X.shape[1])で、列数がX.shape[1]である０だけで構成される行列を作成している\n","        self.sv_pred = np.zeros(X.shape[0])\n","      \n","\n","        # メイン処理\n","        for k in range(self.iter):\n","          kern = self._kernel2(X,X) #カーネル関数\n","          # 問題1解答（ラグランジュの未定乗数法による最急降下）\n","          # self.lamda = self._svm_gradient_descent(X,y,kern)\n","          self.lamda = self._svm_gradient_descent(X,y)\n","          # print(\"self.lamda1\")\n","          # print(self.lamda)\n","          # print(self.lamda.shape)\n","          # print(len(self.lamda))\n","          # print(\"self.verbose2\")\n","          # print(self.verbose)\n","          if(self.verbose ==True):# 問題2解答（サポートベクターの決定）\n","            # print(\"self.verbose\")\n","            # print(self.verbose)\n","            mmm = np.where(self.lamda >= self.threshold)  #if(self.lamda>=10**-5):を元々書いたがこれだと処理できない\n","            #mmm = np.where(self.lamda >= self.threshold) 閾値超えるself.lamdaのインデックスをmmmに代入している\n","            # print(\"mmm\")\n","            # print(mmm)\n","            # print(\"np.where(self.lamda >= self.threshold)\")\n","            # print(np.where(self.lamda >= self.threshold))\n","            self.lam_sv = np.append( self.lam_sv, self.lamda[mmm] )\n","            # print(\"self.lam_sv\")\n","            # print(self.lam_sv)\n","            # print(self.lam_sv.shape)\n","            # print(len(self.lam_sv))\n","            self.X_sv = np.append( self.X_sv, X[mmm] )\n","            # print(\"self.X_sv\")\n","            # self.X_sv = self.X_sv[::100]\n","            # print(self.X_sv)\n","            # print(len(self.X_sv))\n","            # print(self.X_sv.shape)\n","            self.y_sv = np.append( self.y_sv, y[mmm] )\n","            # print(\"self.y_sv\")\n","            # print(self.y_sv)\n","            # print(len(self.y_sv))\n","            # print(self.y_sv.shape)\n","\n"," \n","\n","    #カーネル関数実装\n","    def _kernel2(self,X1,X2):\n","      \"\"\"\n","      カーネル関数を計算する\n","      Parameters\n","      ----------\n","      X : 次の形のndarray, shape (n_samples, n_features)\n","        訓練データ\n","      Returns\n","      -------\n","        次の形のndarray, shape (n_samples, 1)\n","        カーネル関数による推定結果\n","      \"\"\"\n","      # print(X)\n","      # print(\"X1\")\n","      # print(X1.shape)\n","      # print(\"X2\")\n","      # print(X2.shape)\n","      kern = X1.T @ X2\n","      # print(\"kern\")\n","      # print(kern)\n","      # print(kern.shape)\n","      return kern\n","      #return = kernel3\n","      # if(self.kernel=='linear'):\n","      #   kernel3 = X @ X\n","      #   return = kernel3\n","      # else:\n","      #   pass #取り敢えず、カーネル関数以外でも設定できるようにしたが、設定が\"\"linear(線形)\"だから使用することはない\n","    # return = kernel2\n","    \n","    # 問題１解答\n","    # def _svm_gradient_descent(self,X,y,kern):\n","    def _svm_gradient_descent(self,X,y):\n","        \"\"\"\n","        最急降下法によるパラメータの更新値計算\n","        適当な重みIrを掛けてλが小さくなる方へ徐々に転がっていくようにする\n","         X : 次の形のndarray, shape (n_samples, n_features)\n","            サンプル\n","         y_true : 入力するモデルの学習に使用する正解値\n","        Returns\n","        -------\n","        λである。\n","        \"\"\"\n","        m=X.shape[0] #n_samplesサンプル数\n","        # n=X.shape[1] #n_features特徴量の数\n","        # print(\"X111\")\n","        # print(X.shape)\n","        # print(\"X222\")\n","        # print(X.T)\n","        # print((X.T).shape)\n","        # print(\"y\")\n","        # print(y)\n","        # print(y.shape)\n","        for i in range(m):\n","          gradient = 0\n","          for j in range(m):\n","            # print(\"self.lamda[j]\")\n","            # print(self.lamda)\n","            # print(self.lamda.shape)\n","            # print(\"y\")\n","            # print(y)\n","            # print(y.shape)\n","            # print(\"X.T\")\n","            # print(X.T)\n","            # print(X.T.shape)\n","            # print(type(X.T))\n","            # print(\"X\")\n","            # print(X)\n","            # print(X.shape)\n","            # print(type(X))\n","            gradient += (self.lamda[j] * y[i] * y[j] * (X[i].T @ X[j]))\n","            # print(\"gradient\")\n","            # print(gradient)\n","            # print(gradient.shape)\n","          self.lamda[i] +=  self.lr * (1-gradient)\n","          # print(\"self.lamda[i]\")\n","          # print(self.lamda[i])\n","          # print(self.lamda.shape)\n","\n","          # self.lamda[i] = round(self.lamda[i])\n","          if(self.lamda[i]>=0):\n","          # self.lamda[i] +=  self.lr * (1-gradient)\n","            self.lamda = self.lamda\n","            # print(\"self.lamda3\")\n","            # print(self.lamda[i])\n","          else:\n","            self.lamda = 0\n","          # print(\"gradient\")\n","          # print(gradient)\n","          # print(\"self.lamda\")\n","          # print(self.lamda)\n","          return self.lamda\n","\n","\n","    def predict(self, X):\n","        \"\"\"\n","        SVM分類器を使いラベルを推定する。\n","        Parameters\n","        ----------\n","        X : 次の形のndarray, shape (n_samples, n_features)\n","            サンプル\n","        Returns\n","        -------\n","            次の形のndarray, shape (n_samples, 1)\n","            SVM分類器による推定結果\n","        \"\"\"\n","        N = len(self.lam_sv)\n","        print(\"N = len(self.lam_sv)\")\n","        print(N)\n","        sv_pre = 0\n","        # self.X_sv = self.X_sv[0:100]\n","        m = self.X_sv.shape[0]\n","        print(\"m\")\n","        print(m)\n","        hoge = np.ones((m, 1))\n","        # print(\"hoge\")\n","        # print(hoge)\n","        print(\"self.X_sv\")\n","        print(self.X_sv)\n","        print(len(self.X_sv))\n","        print(self.X_sv.shape)\n","        # print(self.X_sv.shape)\n","        # self.X_sv = self.X_sv.reshape(m,1)\n","        # self.X_sv = np.hstack((hoge,self.X_sv))\n","        print(\"X\")\n","        print(X)\n","        print(X.shape)\n","\n","        for n in range(N):\n","          # print(\"self.lam_sv\")\n","          # print(self.lam_sv)\n","          # print(len(self.lam_sv))\n","          # print(self.lam_sv.shape)\n","          # print(\"self.y_sv\")\n","          # print(self.y_sv)\n","          # print(len(self.y_sv))\n","          # print(self.y_sv.shape)\n","          # print(\"X\")\n","          # print(X)\n","          # print(len(X))\n","          # print(X.shape)\n","          \n","          \n","          # print(\"self.X_sv2\")\n","          # print(self.X_sv)\n","          # print(len(self.X_sv))\n","          # print(self.X_sv.shape)\n","          # print(\"sv_pre\")\n","          # # print(len(sv_pre))\n","          # print(sv_pre)\n","          # sv_pre += self.lam_sv[n]*self.y_sv[n]* self._kernel2(X,self.X_sv)\n","          # sv_pre += self.lam_sv[n]*self.y_sv[n]* (X @ self.X_sv.T)\n","          # print(\"self.lam_sv[n]\")\n","          # print(self.lam_sv[n])\n","          # print(self.lam_sv.shape)\n","          # print(\"self.y_sv[n]\")\n","          # print(self.y_sv[n])\n","          # print(self.y_sv[n].shape)\n","          \n","          # print(\"X[n]\")\n","          # print(X[n])\n","          # print(X[n].shape)\n","          # print(\"self.X_sv[n].T\")\n","          # print(self.X_sv[n].T)\n","          # print(self.X_sv[n].T.shape)\n","          # sv_pre += self.lam_sv[n]*self.y_sv[n]* (X[n] @ self.X_sv[n])\n","          sv_pre += self.lam_sv[n]*self.y_sv[n]* (X.T[n] * self.X_sv[n])\n","        return sv_pre"],"execution_count":121,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tkaJu2GxniFp"},"source":["【問題2】サポートベクターの決定\n","計算したラグランジュ乗数 \n","λ\n"," が設定した閾値より大きいサンプルをサポートベクターとして扱います。推定時にサポートベクターが必要になります。サポートベクターを決定し、インスタンス変数として保持しておくコードを書いてください。\n","\n","\n","閾値はハイパーパラメータですが、1e-5程度からはじめると良いでしょう。サポートベクターの数を出力させられるようにしておくと学習がうまく行えているかを確認できます。\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"t5iQJMnFnlVw","executionInfo":{"status":"ok","timestamp":1628650010884,"user_tz":-540,"elapsed":12,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}}},"source":["#問題１に解答しました"],"execution_count":122,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bc7fxel9niSO"},"source":["【問題3】推定\n","\n","推定時には、推定したいデータの特徴量とサポートベクターの特徴量をカーネル関数によって計算します。求めた \n","\n","$$\n","k(x_i,x_j)=x_i^Tx_j\n","$$\n","\n","f(x)\n"," の符号が分類結果です。\n","\n","$$\n","f(x)=\\sum_{n=1}^{N}λ_ny_{sv_n}k(x,s_n)\n","$$\n","\n","x\n"," : 推定したいデータの特徴量ベクトル\n","\n","\n","N\n"," : サポートベクターの数\n","\n","\n","n\n"," : サポートベクターのインデックス\n","\n","\n","λ\n","n\n"," : \n","n\n","番目のサポートベクターのラグランジュ乗数\n","\n","\n","$y_{sv_n}$ \n","番目のサポートベクターのラベル\n","\n","\n","k\n","(\n",")\n"," : カーネル関数\n","\n","\n","s\n","n\n"," : \n","n\n","番目のサポートベクターの特徴量\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"oDSs1cppnl3T","executionInfo":{"status":"ok","timestamp":1628650010884,"user_tz":-540,"elapsed":11,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}}},"source":["#問題１に解答しました"],"execution_count":123,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qe2HypspnicV"},"source":["3.検証\n","\n","【問題4】学習と推定\n","機械学習スクラッチ入門のSprintで用意したシンプルデータセット1の2値分類に対してスクラッチ実装の学習と推定を行なってください。\n","\n","\n","scikit-learnによる実装と比べ、正しく動いているかを確認してください。\n","\n","\n","AccuracyやPrecision、Recallなどの指標値はscikit-learnを使用してください。\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"daF_nvSLnmXN","executionInfo":{"status":"ok","timestamp":1628650010885,"user_tz":-540,"elapsed":12,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"4d876e23-26b9-48d1-d333-dfab32792266"},"source":["#SVMのモデルで、シンプルデータセット１を使用して、学習と正答率を算出する\n","#シンプルデータセット1作成コード\n","#scikit-learnによる実装\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","np.random.seed(seed=0)\n","n_samples = 500\n","f0 = [-1, 2]\n","f1 = [2, -1]\n","cov = [[1.0,0.8], [0.8, 1.0]]\n","f0 = np.random.multivariate_normal(f0, cov, n_samples // 2)\n","f1 = np.random.multivariate_normal(f1, cov, n_samples // 2)\n","X1_1 = np.concatenate([f0, f1])\n","y1_1= np.concatenate([\n","    np.full(n_samples // 2, 1),\n","    np.full(n_samples // 2, -1)\n","])\n","\n","\n","#トレーニングデータとテストデータに分けて実行してみる------------------\n","X_train, X_test, y_train, y_test=train_test_split(X1_1, y1_1, train_size=0.8)\n","from sklearn.svm import SVC\n","# 線形SVMのインスタンスを生成\n","model = SVC(kernel='linear', random_state=None)\n","\n","# モデルの学習。fit関数で行う。\n","model.fit(X_train, y_train)\n","\n","from sklearn import linear_model, metrics, preprocessing #機械学習用のライブラリを利用\n","from mlxtend.plotting import plot_decision_regions #学習結果をプロットする外部ライブラリを利用\n","#正答率を求める\n","pre1=model.predict(X_test)\n","# print(\"予測値=\",pre1)\n","ac_score1=metrics.accuracy_score(y_test,pre1)\n","# print(\"正答率 = \",ac_score1)\n","\n","\n","from sklearn.metrics import classification_report\n","import pandas as pd\n","import pprint\n","\n","\n","pre1=model.predict(X_test)\n","y_true_multi=y_test\n","\n","y_pred_multi=pre1\n","print(classification_report(y_true_multi, y_pred_multi)) #引数に入れるのは、下記でサイトで調べた"],"execution_count":124,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","          -1       1.00      1.00      1.00        43\n","           1       1.00      1.00      1.00        57\n","\n","    accuracy                           1.00       100\n","   macro avg       1.00      1.00      1.00       100\n","weighted avg       1.00      1.00      1.00       100\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x24Psyu_qVPy","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1628650011117,"user_tz":-540,"elapsed":240,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"7089f6b7-e43d-4888-b53f-f1016093f0b4"},"source":["#スクラッチSVM実装でシンプルデータセット１を使用して、学習と正答率を算出する\n","\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","import random\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import classification_report\n","import pprint\n","from sklearn import linear_model, metrics, preprocessing #機械学習用のライブラリを利用\n","from mlxtend.plotting import plot_decision_regions #学習結果をプロットする外部ライブラリを利用\n","\n","#シンプルデータセット1作成コード\n","np.random.seed(seed=0)\n","n_samples = 500\n","f0 = [-1, 2]\n","f1 = [2, -1]\n","cov = [[1.0,0.8], [0.8, 1.0]]\n","f0 = np.random.multivariate_normal(f0, cov, n_samples // 2)\n","f1 = np.random.multivariate_normal(f1, cov, n_samples // 2)\n","X1_1 = np.concatenate([f0, f1])\n","y1_1= np.concatenate([\n","    np.full(n_samples // 2, 1),\n","    np.full(n_samples // 2, -1)\n","])\n","\n","# print(\"X1_1\")\n","# print(X1_1.shape)\n","# print(\"y1_1\")\n","# print(y1_1.shape)\n","\n","\n","#トレーニングデータとテストデータに分けて実行してみる------------------\n","X_train, X_test, y_train, y_test=train_test_split(X1_1, y1_1, train_size=0.8)\n","\n","\n","\n","scaler = StandardScaler()\n","scaler.fit(X_train)\n","X_train=scaler.transform(X_train)\n","X_test=scaler.transform(X_test)\n","\n","\n","model = ScratchSVMClassifier(num_iter=100, lr=0.1, kernel='linear', threshold=1e-5, verbose=True)\n","# モデルの学習。fit関数で行う。\n","model.fit(X_train, y_train)\n","\n","# sv_pre = self.predict(X)\n","# # print(\"sv_pre\")\n","# # print(sv_pre)\n","# # print(\"self.lam_sv\")\n","# # print(self.lam_sv)\n","# # print(self.lam_sv.shape)\n","# # print(\"self.y_sv\")\n","# # print(self.y_sv)\n","# # print(self.y_sv.shape)\n","# # print(\"X\")\n","# # print(X)\n","# # print(X.shape)\n","# # print(\"self.X_sv\")\n","# # print(self.X_sv)\n","# # print(self.X_sv.shape)\n","# # print(\"sv_pre\")\n","# # print(sv_pre)\n","# self.sv_pred = np.append( self.sv_pred, sv_pre ) #物凄く時間がかかった所。（空ののself.lossにnumpy ndarrayの要素を追加する方法）\n","\n","#正答率を求める\n","print(\"X_test\")\n","print(X_test.shape)\n","\n","pre1=model.predict(X_test)\n","print(\"予測値=\",pre1)\n","# ac_score1=metrics.accuracy_score(y_test,pre1)\n","# print(\"正答率 = \",ac_score1)\n","\n","y_true_multi=y_test\n","y_pred_multi=pre1\n","print(\"y_true_multi\")\n","print(y_true_multi)\n","print(y_true_multi.shape)\n","print(\"y_pred_multi\")\n","print(y_pred_multi)\n","print(y_pred_multi.shape)\n","print(classification_report(y_true_multi, y_pred_multi)) "],"execution_count":125,"outputs":[{"output_type":"stream","text":["X_test\n","(100, 2)\n","N = len(self.lam_sv)\n","100\n","m\n","200\n","self.X_sv\n","[-0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097 -0.11179853 -0.96235097 -0.11179853 -0.96235097\n"," -0.11179853 -0.96235097]\n","200\n","(200,)\n","X\n","[[ 0.09495868 -1.54426673]\n"," [-0.66863052  0.66310545]\n"," [-1.49786098  0.00504818]\n"," [-0.27022475  1.75436981]\n"," [-2.08689054 -0.3540802 ]\n"," [-1.33270816  0.41467339]\n"," [ 1.8982587   0.43105832]\n"," [ 0.86857251 -0.48179481]\n"," [ 0.75192666 -0.98941635]\n"," [ 0.55073705 -1.30355742]\n"," [ 0.81134562 -0.79474219]\n"," [-1.4407809   0.41742629]\n"," [-2.27970794 -0.06020315]\n"," [ 0.60294404 -0.62154555]\n"," [-0.86915261  0.52485776]\n"," [-1.02488955  1.12057684]\n"," [-0.72646447  0.78335752]\n"," [ 0.24370447 -0.76220218]\n"," [ 1.72457524 -0.02685409]\n"," [-0.91278047  0.4461206 ]\n"," [-1.04503868  0.83297289]\n"," [-0.34793534  1.15159318]\n"," [ 0.14427713 -1.63914289]\n"," [ 0.32786389 -0.75756883]\n"," [-1.38562862  0.6049962 ]\n"," [ 1.039441   -1.38501964]\n"," [-1.230606    0.3501619 ]\n"," [ 1.89252024 -0.34299615]\n"," [-0.89571662  1.13145856]\n"," [ 0.88097872 -0.86275905]\n"," [-0.09233943  1.10491069]\n"," [-1.15551876  0.80414807]\n"," [-1.17913796  0.91027521]\n"," [ 0.86990698 -0.70265243]\n"," [-0.0207836   1.84625158]\n"," [-0.33894859  1.25406962]\n"," [-1.02005542  0.80641317]\n"," [-0.63709892  0.99980676]\n"," [ 0.85735217 -0.84144045]\n"," [ 1.29167302 -0.94691194]\n"," [-1.32462753  0.56452777]\n"," [ 0.86854529 -0.84918026]\n"," [ 0.52401162 -1.04623566]\n"," [-0.91383835  0.97522787]\n"," [ 1.1054783  -0.78115054]\n"," [ 0.47718976 -0.83480023]\n"," [-1.23536231  0.28033067]\n"," [ 0.09766281  1.90557702]\n"," [-1.43966486 -0.00496243]\n"," [ 1.20221675 -0.25181411]\n"," [ 1.65905779  0.02732205]\n"," [-0.1826931   1.71439813]\n"," [-0.0023428   1.66429438]\n"," [ 0.26891843  1.8195732 ]\n"," [-1.09667403  0.87205487]\n"," [ 0.22597673 -0.76588179]\n"," [-0.84359208  0.93362665]\n"," [-0.55454364  0.79099266]\n"," [-1.43308137  1.0253078 ]\n"," [ 0.89621279 -0.31318463]\n"," [ 1.06460439 -0.85136512]\n"," [-0.06376425  1.81460757]\n"," [-0.54821069  1.04056593]\n"," [-0.54444812  0.93523584]\n"," [ 1.02527038 -0.1181992 ]\n"," [-1.19098791  0.65251917]\n"," [ 1.10034483 -0.44410491]\n"," [ 1.78782213 -0.13342117]\n"," [ 1.22949156 -0.36922914]\n"," [ 1.06075032 -0.53661729]\n"," [ 1.00611127 -0.21410601]\n"," [-0.62356623  0.53575991]\n"," [ 1.24066997 -0.27999229]\n"," [-0.1757954   1.3876607 ]\n"," [-0.20530007  1.01990225]\n"," [-1.49205372  0.71293164]\n"," [ 1.76177426 -0.2734046 ]\n"," [ 1.33016769 -0.48538103]\n"," [-0.16429571  1.79302901]\n"," [-0.16911906  1.31538833]\n"," [-0.51448069  1.60043425]\n"," [-0.68160934  1.20870343]\n"," [-1.45095986  0.58525159]\n"," [-0.237207   -2.29076419]\n"," [-1.15752034  0.50897447]\n"," [ 0.33704619 -1.46198891]\n"," [ 1.09956225 -0.1482933 ]\n"," [-1.23576538  0.4532055 ]\n"," [-1.05089513  0.89933897]\n"," [ 0.665257   -1.52576561]\n"," [ 1.69526071  0.19413488]\n"," [-0.46135602  1.24270347]\n"," [ 0.34258883  2.31368434]\n"," [ 0.27425781 -1.04888774]\n"," [-1.45036479  0.41535817]\n"," [-1.84276341 -0.60854599]\n"," [-0.72505461  0.8794767 ]\n"," [ 0.5217836  -1.09220841]\n"," [-2.00625058  0.3475189 ]\n"," [ 0.65050588 -0.55512317]]\n","(100, 2)\n"],"name":"stdout"},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-125-19723daf149d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mpre1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"予測値=\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpre1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# ac_score1=metrics.accuracy_score(y_test,pre1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-121-bc86872adde8>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    289\u001b[0m           \u001b[0;31m# print(self.X_sv[n].T.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m           \u001b[0;31m# sv_pre += self.lam_sv[n]*self.y_sv[n]* (X[n] @ self.X_sv[n])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m           \u001b[0msv_pre\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlam_sv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_sv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_sv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msv_pre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"]}]},{"cell_type":"markdown","metadata":{"id":"MpsBmeAQ2eQ7"},"source":["まだスクラッチ実装が正しく動作してない"]},{"cell_type":"markdown","metadata":{"id":"jGHWX4QWninO"},"source":["【問題5】決定領域の可視化\n","決定領域を可視化してください。\n","\n","\n","以下の例のようにサポートベクターは異なる色で示してください。"]},{"cell_type":"code","metadata":{"id":"59QWocimnnP5","executionInfo":{"status":"aborted","timestamp":1628650011113,"user_tz":-540,"elapsed":7,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}}},"source":["import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap\n","import matplotlib.patches as mpatches\n","import numpy as np\n","import itertools\n","# def decision_region(X, y, model, step=0.1, title='decision region', xlabel='xlabel', ylabel='ylabel', target_names=['1','-1']):\n","#     \"\"\"\n","#     2値分類を2次元の特徴量で学習したモデルの決定領域を描く。\n","#     背景の色が学習したモデルによる推定値から描画される。\n","#     散布図の点は訓練データまたは検証データである。\n","#     Parameters\n","#     ----------------\n","#     X : ndarray, shape(n_samples, 2)\n","#         特徴量\n","#     y : ndarray, shape(n_samples,)\n","#         ラベル\n","#     model : object\n","#         学習したモデルのインスンタスを入れる\n","#     step : float, (default : 0.1)\n","#         推定値を計算する間隔を設定する\n","#     title : str\n","#         グラフのタイトルの文章を与える\n","#     xlabel, ylabel : str\n","#         軸ラベルの文章を与える\n","#     target_names= : list of str\n","#         凡例の一覧を与える\n","#     \"\"\"\n","#     # setting\n","#     scatter_color = ['red', 'blue']\n","#     contourf_color = ['pink', 'skyblue']\n","#     n_class = 2\n","#     # pred\n","#     mesh_f0, mesh_f1  = np.meshgrid(np.arange(np.min(X[:,0])-0.5, np.max(X[:,0])+0.5, step), np.arange(np.min(X[:,1])-0.5, np.max(X[:,1])+0.5, step))\n","#     mesh = np.c_[np.ravel(mesh_f0),np.ravel(mesh_f1)]\n","#     # y_pred = model.predict(mesh).reshape(mesh_f0.shape)\n","#     y_pred = model.predict(mesh)\n","#     # plot\n","#     plt.title(title)\n","#     plt.xlabel(xlabel)\n","#     plt.ylabel(ylabel)\n","#     plt.contourf(mesh_f0, mesh_f1, y_pred, n_class-1, cmap=ListedColormap(contourf_color))\n","#     plt.contour(mesh_f0, mesh_f1, y_pred, n_class-1, colors='y', linewidths=3, alpha=0.5)\n","#     for i, target in enumerate(set(y)):\n","#         plt.scatter(X[y==target][:, 0], X[y==target][:, 1], s=80, color=scatter_color[i], label=target_names[i], marker='o')\n","#     patches = [mpatches.Patch(color=scatter_color[i], label=target_names[i]) for i in range(n_class)]\n","#     plt.legend(handles=patches)\n","#     plt.legend()\n","#     plt.show()\n","\n","\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import warnings\n","warnings.filterwarnings('ignore')\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import LinearSVC\n","iris_dataset = load_iris()\n","\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap\n","import matplotlib.patches as mpatches\n","import itertools\n","\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","import random\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import classification_report\n","import pprint\n","from sklearn import linear_model, metrics, preprocessing #機械学習用のライブラリを利用\n","from mlxtend.plotting import plot_decision_regions #学習結果をプロットする外部ライブラリを利用\n","\n","#シンプルデータセット1作成コード\n","np.random.seed(seed=0)\n","n_samples = 500\n","f0 = [-1, 2]\n","f1 = [2, -1]\n","cov = [[1.0,0.8], [0.8, 1.0]]\n","f0 = np.random.multivariate_normal(f0, cov, n_samples // 2)\n","f1 = np.random.multivariate_normal(f1, cov, n_samples // 2)\n","X1_1 = np.concatenate([f0, f1])\n","y1_1= np.concatenate([\n","    np.full(n_samples // 2, 1),\n","    np.full(n_samples // 2, -1)\n","])\n","\n","print(\"X1_1\")\n","print(X1_1.shape)\n","print(\"y1_1\")\n","print(y1_1.shape)\n","\n","\n","#トレーニングデータとテストデータに分けて実行してみる------------------\n","X_train, X_test, y_train, y_test=train_test_split(X1_1, y1_1, train_size=0.8)\n","\n","model = ScratchSVMClassifier(num_iter=5, lr=0.1, kernel='linear', threshold=1e-5, verbose=True)\n","\n","# scaler = StandardScaler()\n","# scaler.fit(X_train)\n","# X_train=scaler.transform(X_train)\n","# X_test=scaler.transform(X_test)\n","\n","\n","#標準化は「平均が0、標準偏差が1になるようにデータを加工（スケーリング）」し、正規化は「最低が0、最高が1になるようにデータを加工（スケーリング）する」モジュールと説明されています。\n","#標準化（standardization） と 正規化（normalization）\n","from sklearn.preprocessing import StandardScaler\n","\n","X_train_data = X_train \n","scaler = StandardScaler()\n","scaler.fit(X_train_data)\n","X_train_transformed = scaler.transform(X_train_data)\n","\n","X_test_data = X_test\n","X_test_transformed = scaler.transform(X_test_data)\n","\n","y_train_data = y_train \n","# scaler.fit(y_train_data)\n","# y_train_transformed = scaler.transform(y_train_data)\n","\n","y_test_data = y_test\n","# y_test_transformed = scaler.transform(y_test_data)\n","\n","def decision_region(X, y, model, step=0.1, title='decision region', xlabel='xlabel', ylabel='ylabel', target_names=['1','-1']):\n","    \"\"\"\n","    2値分類を2次元の特徴量で学習したモデルの決定領域を描く。\n","    背景の色が学習したモデルによる推定値から描画される。\n","    散布図の点は訓練データまたは検証データである。\n","    Parameters\n","    ----------------\n","    X : ndarray, shape(n_samples, 2)\n","        特徴量\n","    y : ndarray, shape(n_samples,)\n","        ラベル\n","    model : object\n","        学習したモデルのインスンタスを入れる\n","    step : float, (default : 0.1)\n","        推定値を計算する間隔を設定する\n","    title : str\n","        グラフのタイトルの文章を与える\n","    xlabel, ylabel : str\n","        軸ラベルの文章を与える\n","    target_names= : list of str\n","        凡例の一覧を与える\n","    \"\"\"\n","    # setting\n","    scatter_color = ['red', 'blue']\n","    contourf_color = ['pink', 'skyblue']\n","    n_class = 2\n","    # pred\n","    mesh_f0, mesh_f1  = np.meshgrid(np.arange(np.min(X[:,0])-0.5, np.max(X[:,0])+0.5, step), np.arange(np.min(X[:,1])-0.5, np.max(X[:,1])+0.5, step))\n","    mesh = np.c_[np.ravel(mesh_f0),np.ravel(mesh_f1)]\n","    print(type(predict))\n","    y_pred = model.predict(mesh).reshape(mesh_f0.shape)\n","    # y_pred = model.predict(mesh)\n","    # plot\n","    plt.title(title)\n","    plt.xlabel(xlabel)\n","    plt.ylabel(ylabel)\n","    plt.contourf(mesh_f0, mesh_f1, y_pred, n_class-1, cmap=ListedColormap(contourf_color))\n","    plt.contour(mesh_f0, mesh_f1, y_pred, n_class-1, colors='y', linewidths=3, alpha=0.5)\n","    for i, target in enumerate(set(y)):\n","        plt.scatter(X[y==target][:, 0], X[y==target][:, 1], s=80, color=scatter_color[i], label=target_names[i], marker='o')\n","    patches = [mpatches.Patch(color=scatter_color[i], label=target_names[i]) for i in range(n_class)]\n","    plt.legend(handles=patches)\n","    plt.legend()\n","    plt.show()\n","\n","\n","#ロジスティック回帰 \n","#訓練データをプロット\n","from sklearn.linear_model import LogisticRegression\n","# X2_1=scaler.transform(X_train_transformed)\n","# y2_1=list(itertools.chain.from_iterable(y_train_data))\n","\n","fig = plt.figure()\n","model2 = model.fit(X_train_transformed,y_train_data)\n","decision_region(X_train_transformed, y_train_data, model2, step=0.1, title='decision region', xlabel='xlabel', ylabel='ylabel', target_names=['1','-1'])\n","# decision_region(X2, y2, model, step=0.01, title='decision region', xlabel='xlabel', ylabel='ylabel', target_names=['versicolor', 'virginica'])\n","\n","ax2 = fig.add_subplot(1, 3, 2)\n","fig.tight_layout()              #レイアウトの設定\n","plt.show()\n","\n","# #検証データをプロット\n","# # X_test_data_list = list(itertools.chain.from_iterable(X_test_data))\n","# # print(X_test_data_list)\n","# X2_2=scaler.transform(X_test_data)\n","# # print(X2_2)\n","# y2_2=list(itertools.chain.from_iterable(y_test_data))\n","# # print(y2_2)\n","# decision_region(X2_2, y2_2, reg, step=0.01, title='Logistic regression validation data decision region', xlabel='xlabel', ylabel='ylabel', target_names=['versicolor', 'virginica'])\n","# ax3 = fig.add_subplot(1, 3, 3)\n","# fig.tight_layout()              #レイアウトの設定\n","# plt.show()\n","\n","\n","# from sklearn.metrics import classification_report\n","# import pandas as pd\n","# import pprint\n","\n","\n","# predict2 = reg.predict(X_test6)\n","# y_true_multi2=test_label6\n","# y_pred_multi2=predict2\n","# print(classification_report(y_true_multi2, y_pred_multi2)) #引数に入れるのは、下記でサイトで調べた\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QgmGzRqqni0B"},"source":[""]},{"cell_type":"code","metadata":{"id":"Qfc__PSynnuf","executionInfo":{"status":"aborted","timestamp":1628650011113,"user_tz":-540,"elapsed":7,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}}},"source":["# import numpy as np\n","# X = [10 ,10]\n","# print(\"X1\")\n","# print(X)\n","# # print(X.shape)\n","# X = np.array(X)\n","# print(\"X2\")\n","# print(X)\n","# print(X.shape)\n","# h = X @ X\n","# print(h)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_XFAijHBTrtj","executionInfo":{"status":"aborted","timestamp":1628650011114,"user_tz":-540,"elapsed":8,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}}},"source":["# #カーネル関数実装\n","# def _kernel2(X1,X2):\n","#   \"\"\"\n","#   カーネル関数を計算する\n","#   Parameters\n","#   ----------\n","#   X : 次の形のndarray, shape (n_samples, n_features)\n","#     訓練データ\n","#   Returns\n","#   -------\n","#     次の形のndarray, shape (n_samples, 1)\n","#     カーネル関数による推定結果\n","#   \"\"\"\n","#   # print(X)\n","#   # print(\"X1\")\n","#   # print(X1.shape)\n","#   # print(\"X2\")\n","#   # print(X2.shape)\n","#   kern = X1.T @ X2\n","#   return kern\n","\n","# X1 = X_train\n","# print(\"X1\")\n","# print(X1)\n","# print(X1.shape)\n","\n","# X2 = X_train\n","# print(\"X2\")\n","# print(X2)\n","# print(X2.shape)\n","# kern = _kernel2(X1,X2)\n","# print(kern)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ySjaZnTFK5Hk","executionInfo":{"status":"aborted","timestamp":1628650011114,"user_tz":-540,"elapsed":8,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}}},"source":["# import matplotlib.pyplot as plt\n","# from matplotlib.colors import ListedColormap\n","# import matplotlib.patches as mpatches\n","# import numpy as np\n","# import itertools\n","\n","# import numpy as np\n","# import pandas as pd\n","# import matplotlib\n","# import matplotlib.pyplot as plt\n","# %matplotlib inline\n","# import warnings\n","# warnings.filterwarnings('ignore')\n","\n","# from sklearn.datasets import load_iris\n","# from sklearn.model_selection import train_test_split\n","# from sklearn.svm import LinearSVC\n","\n","# iris_dataset = load_iris()\n","\n","\n","\n","# #説明変数\n","# iris_dataset_data = pd.DataFrame(iris_dataset.data, columns=[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"])\n","# iris_dataset_all = pd.concat([iris_dataset_data], axis=1)\n","# X = iris_dataset_all\n","# # print(X)\n","# print(type(X))\n","# #目的変数（花の種類）も同様にyに格納してください。\n","# iris_dataset_target = pd.DataFrame(iris_dataset.target, columns=[\"Species\"])\n","# iris_dataset_all2 = pd.concat([iris_dataset_target], axis=1)\n","# y = iris_dataset_all2\n","# print(type(y))\n","# # print(y)\n","\n","# # df = pd.concat([X, y], axis=1)\n","# # print(df)\n","\n","# #sepal_lengthとpetal_length\n","# print(\"sepal_lengthとpetal_lengthのデータフレーム\")\n","# x=X.loc[:,['sepal_length','petal_length']]\n","# print(type(x))\n","# print(x)\n","# # X.loc[50:149,['sepal_length','petal_length']]\n","# # print(X.loc[50:149,['sepal_length','petal_length']])\n","# # x = pd.DataFrame(iris_dataset.data, columns=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"])\n","# # print(x)\n","# # print(df_concat['sepal_width'])\n","\n","# # x = x.loc[50:149, [\"sepal_length\", \"petal_length\"]]\n","\n","# # y = pd.Series(iris_dataset.target, name=\"y\")\n","# oldy=y[(y['Species'] == 1) | (y['Species'] == 2)]\n","# print(type(oldy))\n","# print(oldy)\n","# # y = pd.DataFrame(iris_dataset.target, columns=[\"y\"])\n","\n","# # print(\"virgicolorとvirginicaのデータフレーム\")\n","# # y = y[(y['y'] != 0)]\n","# # print(y)\n","# # print(y.shape)\n","# # print(type(y))\n","\n","\n","\n","# #PandasのDataFrameをNumPyのndarrayに変換\n","# print(\"sepal_lengthとpetal_lengthのndarray\")\n","# x=x.loc[50:149,['sepal_length','petal_length']]\n","# print(type(x))\n","# print(x)\n","# print(\"xの型は\")\n","# print(type(x))\n","# X = x.values\n","# print(X)\n","# print(\"Xの型は\")\n","# print(type(X))\n","# # X_list=X.tolist()\n","# # print(X_list)\n","# # print(\"X_listの型は\")\n","# # print(type(X_list))\n","\n","\n","# print(\"X2の型は\")\n","# print(type(X))\n","# X=X.tolist()\n","# print(X)\n","\n","# #PandasのDataFrameをNumPyのndarrayに変換\n","# print(\"virgicolorとvirginicaのndarray\")\n","# oldy = oldy\n","# # oldy = y[(y['y'] != 0)]\n","# print(oldy)\n","# print(oldy.shape)\n","# print(\"oldyの型は\")\n","# print(type(oldy))\n","# y = oldy.values\n","# print(\"yの型は\")\n","# print(type(y))\n","# #訓練データ75%、検証データ25%として分割\n","# X_train, X_test, y_train, y_test = train_test_split(\n","# X, y, train_size= 0.75, test_size=0.25)\n","# print(\"sepal_lengthとpetal_lengthの訓練データ\")\n","# print(X_train)\n","# print(\"sepal_lengthとpetal_lengthの検証データ\")\n","# print(X_test)\n","# print(\"virgicolorとvirginicaの訓練データ\")\n","# print(y_train)\n","# print(\"virgicolorとvirginicaの検証データ\")\n","# print(y_test)\n","\n","\n","# #標準化は「平均が0、標準偏差が1になるようにデータを加工（スケーリング）」し、正規化は「最低が0、最高が1になるようにデータを加工（スケーリング）する」モジュールと説明されています。\n","# #標準化（standardization） と 正規化（normalization）\n","# from sklearn.preprocessing import StandardScaler\n","# # data = [[0, 0], [0, 0], [1, 1], [1, 1]]\n","\n","# #X_train, X_test, y_train, y_test\n","\n","# X_train_data = X_train #\"sepal_lengthとpetal_lengthの訓練データ\"\n","# scaler = StandardScaler()\n","# print(scaler.fit(X_train_data))\n","# # print(scaler.mean_)\n","# print(scaler.transform(X_train_data))\n","\n","# X_test_data = X_test #\"sepal_lengthとpetal_lengthの検証データ\"\n","# scaler = StandardScaler()\n","# print(scaler.fit(X_test_data))\n","# # print(scaler.fit(X_test_data))\n","# # print(scaler.mean_)\n","# print(scaler.transform(X_test_data))\n","\n","\n","# y_train_data = y_train #\"virgicolorとvirginicaの訓練データ\"\n","# scaler = StandardScaler()\n","# print(scaler.fit(y_train_data))\n","# # print(scaler.mean_)\n","# print(scaler.transform(y_train_data))\n","\n","# y_test_data = y_test #\"virgicolorとvirginicaの検証データ\"\n","# scaler = StandardScaler()\n","# print(scaler.fit(y_test_data))\n","# # print(scaler.fit(y_test_data))\n","# # print(scaler.mean_)\n","# print(scaler.transform(y_test_data))\n","\n","\n","\n","# def decision_region(X, y, model, step=0.01, title='decision region', xlabel='xlabel', ylabel='ylabel', target_names=['versicolor', 'virginica']):\n","#     \"\"\"\n","#     2値分類を2次元の特徴量で学習したモデルの決定領域を描く。\n","#     背景の色が学習したモデルによる推定値から描画される。\n","#     散布図の点は訓練データまたは検証データである。\n","#     Parameters\n","#     ----------------\n","#     X : ndarray, shape(n_samples, 2)\n","#         特徴量\n","#     y : ndarray, shape(n_samples,)\n","#         ラベル\n","#     model : object\n","#         学習したモデルのインスンタスを入れる\n","#     step : float, (default : 0.1)\n","#         推定値を計算する間隔を設定する\n","#     title : str\n","#         グラフのタイトルの文章を与える\n","#     xlabel, ylabel : str\n","#         軸ラベルの文章を与える\n","#     target_names= : list of str\n","#         凡例の一覧を与える\n","#     \"\"\"\n","#     # setting\n","#     scatter_color = ['red', 'blue']\n","#     contourf_color = ['pink', 'skyblue']\n","#     n_class = 2\n","#     # pred\n","#     mesh_f0, mesh_f1  = np.meshgrid(np.arange(np.min(X[:,0])-0.5, np.max(X[:,0])+0.5, step), np.arange(np.min(X[:,1])-0.5, np.max(X[:,1])+0.5, step))\n","#     mesh = np.c_[np.ravel(mesh_f0),np.ravel(mesh_f1)]\n","#     y_pred = model.predict(mesh).reshape(mesh_f0.shape)\n","#     # plot\n","#     plt.title(title)\n","#     plt.xlabel(xlabel)\n","#     plt.ylabel(ylabel)\n","#     plt.contourf(mesh_f0, mesh_f1, y_pred, n_class-1, cmap=ListedColormap(contourf_color))\n","#     plt.contour(mesh_f0, mesh_f1, y_pred, n_class-1, colors='y', linewidths=3, alpha=0.5)\n","#     for i, target in enumerate(set(y)):\n","#         plt.scatter(X[y==target][:, 0], X[y==target][:, 1], s=80, color=scatter_color[i], label=target_names[i], marker='o')\n","#     patches = [mpatches.Patch(color=scatter_color[i], label=target_names[i]) for i in range(n_class)]\n","#     plt.legend(handles=patches)\n","#     plt.legend()\n","#     plt.show()\n","\n","# #訓練データをプロット\n","# # X_train_data_list = list(itertools.chain.from_iterable(X_train_data))\n","# # print(X_train_data_list)\n","# X1=scaler.transform(X_train_data)\n","# # print(X1)\n","# y1=list(itertools.chain.from_iterable(y_train_data))\n","# # print(y1)\n","# from sklearn.neighbors import KNeighborsClassifier\n","# neigh = KNeighborsClassifier(n_neighbors=3)\n","# model = neigh.fit(X1,y1)\n","# decision_region(X1, y1, model, step=0.01, title='decision region', xlabel='xlabel', ylabel='ylabel', target_names=['versicolor', 'virginica'])\n","\n","# #検証データをプロット\n","# X2=scaler.transform(X_test_data)\n","# # print(X2)\n","# y2=list(itertools.chain.from_iterable(y_test_data))\n","# # print(y2)\n","# decision_region(X2, y2, model, step=0.01, title='decision region', xlabel='xlabel', ylabel='ylabel', target_names=['versicolor', 'virginica'])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vobLai3-aOke","executionInfo":{"status":"aborted","timestamp":1628650011115,"user_tz":-540,"elapsed":9,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}}},"source":["import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap\n","import matplotlib.patches as mpatches\n","import numpy as np\n","import itertools\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import LinearSVC\n","\n","iris_dataset = load_iris()\n","\n","\n","\n","#説明変数\n","iris_dataset_data = pd.DataFrame(iris_dataset.data, columns=[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"])\n","iris_dataset_all = pd.concat([iris_dataset_data], axis=1)\n","X = iris_dataset_all\n","# print(X)\n","print(type(X))\n","#目的変数（花の種類）も同様にyに格納してください。\n","iris_dataset_target = pd.DataFrame(iris_dataset.target, columns=[\"Species\"])\n","iris_dataset_all2 = pd.concat([iris_dataset_target], axis=1)\n","y = iris_dataset_all2\n","print(type(y))\n","# print(y)\n","\n","# df = pd.concat([X, y], axis=1)\n","# print(df)\n","\n","#sepal_lengthとpetal_length\n","print(\"sepal_lengthとpetal_lengthのデータフレーム\")\n","x=X.loc[:,['sepal_length','petal_length']]\n","print(type(x))\n","print(x)\n","\n","oldy=y[(y['Species'] == 1) | (y['Species'] == 2)]\n","print(type(oldy))\n","print(oldy)\n","\n","#PandasのDataFrameをNumPyのndarrayに変換\n","print(\"sepal_lengthとpetal_lengthのndarray\")\n","x=x.loc[50:149,['sepal_length','petal_length']]\n","print(type(x))\n","print(x)\n","print(\"xの型は\")\n","print(type(x))\n","X = x.values\n","print(X)\n","print(\"Xの型は\")\n","print(type(X))\n","# X_list=X.tolist()\n","# print(X_list)\n","# print(\"X_listの型は\")\n","# print(type(X_list))\n","\n","\n","print(\"X2の型は\")\n","print(type(X))\n","X=X.tolist()\n","print(X)\n","\n","#PandasのDataFrameをNumPyのndarrayに変換\n","print(\"virgicolorとvirginicaのndarray\")\n","oldy = oldy\n","# oldy = y[(y['y'] != 0)]\n","print(oldy)\n","print(oldy.shape)\n","print(\"oldyの型は\")\n","print(type(oldy))\n","y = oldy.values\n","print(\"yの型は\")\n","print(type(y))\n","#訓練データ75%、検証データ25%として分割\n","X_train, X_test, y_train, y_test = train_test_split(\n","X, y, train_size= 0.75, test_size=0.25)\n","print(\"sepal_lengthとpetal_lengthの訓練データ\")\n","print(X_train)\n","print(\"sepal_lengthとpetal_lengthの検証データ\")\n","print(X_test)\n","print(\"virgicolorとvirginicaの訓練データ\")\n","print(y_train)\n","print(\"virgicolorとvirginicaの検証データ\")\n","print(y_test)\n","\n","\n","#標準化は「平均が0、標準偏差が1になるようにデータを加工（スケーリング）」し、正規化は「最低が0、最高が1になるようにデータを加工（スケーリング）する」モジュールと説明されています。\n","#標準化（standardization） と 正規化（normalization）\n","from sklearn.preprocessing import StandardScaler\n","# data = [[0, 0], [0, 0], [1, 1], [1, 1]]\n","\n","#X_train, X_test, y_train, y_test\n","\n","X_train_data = X_train #\"sepal_lengthとpetal_lengthの訓練データ\"\n","scaler = StandardScaler()\n","print(scaler.fit(X_train_data))\n","# print(scaler.mean_)\n","print(scaler.transform(X_train_data))\n","\n","X_test_data = X_test #\"sepal_lengthとpetal_lengthの検証データ\"\n","scaler = StandardScaler()\n","print(scaler.fit(X_test_data))\n","# print(scaler.fit(X_test_data))\n","# print(scaler.mean_)\n","print(scaler.transform(X_test_data))\n","\n","\n","y_train_data = y_train #\"virgicolorとvirginicaの訓練データ\"\n","scaler = StandardScaler()\n","print(scaler.fit(y_train_data))\n","# print(scaler.mean_)\n","print(scaler.transform(y_train_data))\n","\n","y_test_data = y_test #\"virgicolorとvirginicaの検証データ\"\n","scaler = StandardScaler()\n","print(scaler.fit(y_test_data))\n","# print(scaler.fit(y_test_data))\n","# print(scaler.mean_)\n","print(scaler.transform(y_test_data))\n","\n","\n","\n","def decision_region(X, y, model, step=0.01, title='decision region', xlabel='xlabel', ylabel='ylabel', target_names=['versicolor', 'virginica']):\n","    \"\"\"\n","    2値分類を2次元の特徴量で学習したモデルの決定領域を描く。\n","    背景の色が学習したモデルによる推定値から描画される。\n","    散布図の点は訓練データまたは検証データである。\n","    Parameters\n","    ----------------\n","    X : ndarray, shape(n_samples, 2)\n","        特徴量\n","    y : ndarray, shape(n_samples,)\n","        ラベル\n","    model : object\n","        学習したモデルのインスンタスを入れる\n","    step : float, (default : 0.1)\n","        推定値を計算する間隔を設定する\n","    title : str\n","        グラフのタイトルの文章を与える\n","    xlabel, ylabel : str\n","        軸ラベルの文章を与える\n","    target_names= : list of str\n","        凡例の一覧を与える\n","    \"\"\"\n","    # setting\n","    scatter_color = ['red', 'blue']\n","    contourf_color = ['pink', 'skyblue']\n","    n_class = 2\n","    # pred\n","    mesh_f0, mesh_f1  = np.meshgrid(np.arange(np.min(X[:,0])-0.5, np.max(X[:,0])+0.5, step), np.arange(np.min(X[:,1])-0.5, np.max(X[:,1])+0.5, step))\n","    mesh = np.c_[np.ravel(mesh_f0),np.ravel(mesh_f1)]\n","    y_pred = model.predict(mesh).reshape(mesh_f0.shape)\n","    # plot\n","    plt.title(title)\n","    plt.xlabel(xlabel)\n","    plt.ylabel(ylabel)\n","    plt.contourf(mesh_f0, mesh_f1, y_pred, n_class-1, cmap=ListedColormap(contourf_color))\n","    plt.contour(mesh_f0, mesh_f1, y_pred, n_class-1, colors='y', linewidths=3, alpha=0.5)\n","    for i, target in enumerate(set(y)):\n","        plt.scatter(X[y==target][:, 0], X[y==target][:, 1], s=80, color=scatter_color[i], label=target_names[i], marker='o')\n","    patches = [mpatches.Patch(color=scatter_color[i], label=target_names[i]) for i in range(n_class)]\n","    plt.legend(handles=patches)\n","    plt.legend()\n","    plt.show()\n","\n","#訓練データをプロット\n","# X_train_data_list = list(itertools.chain.from_iterable(X_train_data))\n","# print(X_train_data_list)\n","X1=scaler.transform(X_train_data)\n","# print(X1)\n","y1=list(itertools.chain.from_iterable(y_train_data))\n","# print(y1)\n","from sklearn.neighbors import KNeighborsClassifier\n","neigh = KNeighborsClassifier(n_neighbors=3)\n","model = neigh.fit(X1,y1)\n","decision_region(X1, y1, model, step=0.01, title='decision region', xlabel='xlabel', ylabel='ylabel', target_names=['versicolor', 'virginica'])\n","\n","#検証データをプロット\n","X2=scaler.transform(X_test_data)\n","# print(X2)\n","y2=list(itertools.chain.from_iterable(y_test_data))\n","# print(y2)\n","decision_region(X2, y2, model, step=0.01, title='decision region', xlabel='xlabel', ylabel='ylabel', target_names=['versicolor', 'virginica'])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0G7eEv4EByL0","executionInfo":{"status":"aborted","timestamp":1628650011115,"user_tz":-540,"elapsed":9,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}}},"source":["#スクラッチSVM実装でシンプルデータセット１を使用して、学習と正答率を算出する\n","\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","import random\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import classification_report\n","import pprint\n","from sklearn import linear_model, metrics, preprocessing #機械学習用のライブラリを利用\n","from mlxtend.plotting import plot_decision_regions #学習結果をプロットする外部ライブラリを利用\n","\n","#シンプルデータセット1作成コード\n","np.random.seed(seed=0)\n","n_samples = 500\n","f0 = [-1, 2]\n","f1 = [2, -1]\n","cov = [[1.0,0.8], [0.8, 1.0]]\n","f0 = np.random.multivariate_normal(f0, cov, n_samples // 2)\n","f1 = np.random.multivariate_normal(f1, cov, n_samples // 2)\n","X1_1 = np.concatenate([f0, f1])\n","y1_1= np.concatenate([\n","    np.full(n_samples // 2, 1),\n","    np.full(n_samples // 2, -1)\n","])\n","\n","print(\"X1_1\")\n","print(X1_1.shape)\n","print(\"y1_1\")\n","print(y1_1.shape)\n","\n","\n","#トレーニングデータとテストデータに分けて実行してみる------------------\n","X_train, X_test, y_train, y_test=train_test_split(X1_1, y1_1, train_size=0.8)\n","\n","\n","\n","scaler = StandardScaler()\n","scaler.fit(X_train)\n","X_train=scaler.transform(X_train)\n","X_test=scaler.transform(X_test)\n","\n","import numpy as np\n","# X = [10 ,10]\n","X=X_train\n","print(\"X1\")\n","print(X_train)\n","# print(X.shape)\n","X = np.array(X)\n","print(\"X2\")\n","print(X.T)\n","print(X.T.shape)\n","h = X @ X.T\n","print(\"h\")\n","print(h)\n","print(h.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HkUSAZLYDI-W","executionInfo":{"status":"aborted","timestamp":1628650011117,"user_tz":-540,"elapsed":11,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}}},"source":[""],"execution_count":null,"outputs":[]}]}