{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TensorFlow.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"156M87jnFvJDqPYP4DRsglEBznNjRy3M8","authorship_tag":"ABX9TyN4+rihWEoHG9hX9bbK2row"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"U0jBS86Xas6o"},"source":["Sprintの目的\n","フレームワークを用いたコードを読めるようになる\n","フレームワークを習得し続けられるようになる\n","理論を知っている範囲をフレームワークで動かす\n","\n","どのように学ぶか\n","TensorFlowのサンプルコードを元に、これまで扱ってきたデータセットを学習していきます。\n","\n","\n","\n","2.コードリーディング\n","\n","TensorFlowによって2値分類を行うサンプルコードを載せました。今回はこれをベースにして進めます。\n","\n","\n","tf.estimator などの高レベルAPIは使用していません。低レベルなところから見ていくことにします。\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3iEt6Q4HatEo"},"source":["【問題1】スクラッチを振り返る\n","ここまでのスクラッチを振り返り、ディープラーニングを実装するためにはどのようなものが必要だったかを列挙してください。\n","\n","\n","（例）\n","\n","\n","重みを初期化する必要があった\n","エポックのループが必要だった\n","\n","それらがフレームワークにおいてはどのように実装されるかを今回覚えていきましょう。\n","\n","\n","データセットの用意\n","以前から使用しているIrisデータセットを使用します。以下のサンプルコードではIris.csvが同じ階層にある想定です。\n","\n","\n","Iris Species\n","\n","\n","目的変数はSpeciesですが、3種類ある中から以下の2種類のみを取り出して使用します。\n","\n","\n","Iris-versicolor\n","Iris-virginica\n"]},{"cell_type":"markdown","metadata":{"id":"BJPLJuglatLm"},"source":["【問題１回答】\n","・重みを初期化する必要があった\n","\n","・エポックのループが必要だった\n","\n","・中間層の活性化関数が必要だった\n","\n","・全結合層が必要だった\n","\n","・最適化手法が必要だった\n","\n","・順伝播が必要だった\n","\n","・逆伝播が必要だった"]},{"cell_type":"markdown","metadata":{"id":"woEVJe5latQ-"},"source":["【問題2】スクラッチとTensorFlowの対応を考える\n","以下のサンプルコードを見て、先ほど列挙した「ディープラーニングを実装するために必要なもの」がTensorFlowではどう実装されているかを確認してください。\n","\n","\n","それを簡単に言葉でまとめてください。単純な一対一の対応であるとは限りません。\n","\n","\n","《サンプルコード》\n","\n","\n","＊TensorFlow バージョン 2.4 で動作を確認済みです。\n","\n","\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","76\n","77\n","78\n","79\n","80\n","81\n","82\n","83\n","84\n","85\n","86\n","87\n","88\n","89\n","90\n","91\n","92\n","93\n","94\n","95\n","96\n","97\n","98\n","99\n","100\n","101\n","102\n","103\n","104\n","105\n","106\n","107\n","108\n","109\n","110\n","111\n","112\n","113\n","114\n","115\n","116\n","117\n","118\n","119\n","120\n","121\n","122\n","123\n","124\n","125\n","126\n","127\n","128\n","129\n","130\n","131\n","132\n","133\n","134\n","135\n","136\n","137\n","138\n","139\n","140\n","141\n","142\n","143\n","144\n","145\n","146\n","147\n","148\n","\"\"\"\n","TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n","\"\"\"\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","# データセットの読み込み\n","dataset_path =\"Iris.csv\"\n","df = pd.read_csv(dataset_path)\n","# データフレームから条件抽出\n","df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n","y = df[\"Species\"]\n","X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n","y = np.array(y)\n","X = np.array(X).astype(np.float32)\n","# ラベルを数値に変換\n","y[y=='Iris-versicolor'] = 0\n","y[y=='Iris-virginica'] = 1\n","y = y.astype(np.float32)[:, np.newaxis]\n","# trainとtestに分割\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","# さらにtrainとvalに分割\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n","class GetMiniBatch:\n","    \"\"\"\n","    ミニバッチを取得するイテレータ\n","    Parameters\n","    ----------\n","    X : 次の形のndarray, shape (n_samples, n_features)\n","      訓練データ\n","    y : 次の形のndarray, shape (n_samples, 1)\n","      正解値\n","    batch_size : int\n","      バッチサイズ\n","    seed : int\n","      NumPyの乱数のシード\n","    \"\"\"\n","    def __init__(self, X, y, batch_size = 10, seed=0):\n","        self.batch_size = batch_size\n","        np.random.seed(seed)\n","        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n","        self.X = X[shuffle_index]\n","        self.y = y[shuffle_index]\n","        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n","    def __len__(self):\n","        return self._stop\n","    def __getitem__(self,item):\n","        p0 = item*self.batch_size\n","        p1 = item*self.batch_size + self.batch_size\n","        return self.X[p0:p1], self.y[p0:p1]        \n","    def __iter__(self):\n","        self._counter = 0\n","        return self\n","    def __next__(self):\n","        if self._counter >= self._stop:\n","            raise StopIteration()\n","        p0 = self._counter*self.batch_size\n","        p1 = self._counter*self.batch_size + self.batch_size\n","        self._counter += 1\n","        return self.X[p0:p1], self.y[p0:p1]\n","# ハイパーパラメータの設定\n","learning_rate = 0.01\n","batch_size = 10\n","num_epochs = 10\n","n_hidden1 = 50\n","n_hidden2 = 100\n","n_input = X_train.shape[1]\n","n_samples = X_train.shape[0]\n","n_classes = 1\n","# trainのミニバッチイテレータ\n","get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n","\n","class MyModel(tf.keras.Model):\n","    def __init__(self):\n","        super().__init__()\n","        # 重みとバイアスの宣言\n","        self.w1 = tf.Variable(tf.random.normal([n_input, n_hidden1]), trainable=True)\n","        self.w2 = tf.Variable(tf.random.normal([n_hidden1, n_hidden2]), trainable=True)\n","        self.w3 = tf.Variable(tf.random.normal([n_hidden2, n_classes]), trainable=True)\n","        self.b1 = tf.Variable(tf.random.normal([n_hidden1]), trainable=True)\n","        self.b2 = tf.Variable(tf.random.normal([n_hidden2]), trainable=True)\n","        self.b3 = tf.Variable(tf.random.normal([n_classes]), trainable=True)\n","    def call(self, x):\n","        \"\"\"\n","        単純な3層ニューラルネットワーク\n","        \"\"\"\n","        layer_1 = tf.add(tf.matmul(x, self.w1), self.b1)\n","        layer_1 = tf.nn.relu(layer_1)\n","        layer_2 = tf.add(tf.matmul(layer_1, self.w2), self.b2)\n","        layer_2 = tf.nn.relu(layer_2)\n","        layer_output = tf.matmul(layer_2, self.w3) + self.b3  # tf.addと+は等価である\n","        return layer_output\n","model = MyModel()\n","\n","# # 最適化手法\n","optimizer = tf.keras.optimizers.Adam(learning_rate)\n","\n","def train(x, y):\n","    logits = model(x, training=True)\n","    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(y, logits))\n","    return loss\n","\n","def evaluate(x, y):\n","    logits = model(x)\n","    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(y, logits))\n","    # 推定結果\n","    correct_pred = tf.equal(tf.sign(y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n","    # 指標値計算\n","    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n","    return loss, accuracy\n","\n","# 計算グラフの実行\n","for epoch in range(num_epochs):\n","    # エポックごとにループ\n","    total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n","    total_loss = 0\n","    total_acc = 0\n","    for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n","        # ミニバッチごとにループ\n","        with tf.GradientTape() as tape:\n","            loss = train(mini_batch_x, mini_batch_y)\n","        grads = tape.gradient(loss, model.trainable_weights)\n","        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n","        total_loss += loss\n","    loss = total_loss / n_samples\n","    val_loss, val_acc = evaluate(X_val, y_val)\n","    print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, val_acc))\n","_, test_acc = evaluate(X_test, y_test)\n","print(\"test_acc : {:.3f}\".format(test_acc))\n","\n"]},{"cell_type":"markdown","metadata":{"id":"B76q3opEhWNY"},"source":["【問題２回答】\n","\n","・重みを初期化する必要があった\n","\n","⇨SimpleInitializerというクラスで、初期化してたが、\n","tf.Variableを使用して、重みとバイアスを初期化してる\n","\n","・エポックのループが必要だった\n","\n","⇨テンソルフローでも使用してるが、\n","DNNでは、順伝播と逆伝播使用してたが、\n","それがない。（AとZと　dAとdZの計算がない）\n","⇨fit内でエポック使用してたが、fitがない\n","\n","・中間層の活性化関数が必要だった\n","\n","⇨tf.nn.reluになった\n","\n","・全結合層が必要だった\n","\n","⇨⇨全結合層FCクラス使用してない\n","\n","・最適化手法が必要だった\n","\n","tf.keras.optimizers.を使用している\n","\n","・全結合層に書いた順伝播が必要だった\n","\n","⇨使用してない\n","\n","・全結合層に書いた逆伝播が必要だった\n","\n","⇨使用してない\n","\n","\n","・ディープラーニングでも一般的に使われる最適化アルゴリズムに「最急降下法」があります。本来であればアルゴリズムの処理をスクラッチでコーディングしなくてはいけません。しかし、TensorFlowを使うことで、容易に最急降下法の処理を組み込むことが可能になります。"]},{"cell_type":"markdown","metadata":{"id":"Q3E1aSNzatXK"},"source":["3.他のデータセットへの適用\n","\n","これまで扱ってきた小さなデータセットが他にもいくつかあります。上記サンプルコードを書き換え、これらに対して学習・推定を行うニューラルネットワークを作成してください。\n","\n","\n","Iris（3種類すべての目的変数を使用）\n","House Prices\n","\n","どのデータセットも train, val, test の3種類に分けて使用してください。\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tasMy2O2ateP"},"source":["【問題3】3種類すべての目的変数を使用したIrisのモデルを作成\n","Irisデータセットのtrain.csvの中で、目的変数Speciesに含まれる3種類すべてを分類できるモデルを作成してください。\n","\n","\n","Iris Species\n","\n","\n","2クラスの分類と3クラス以上の分類の違いを考慮してください。それがTensorFlowでどのように書き換えられるかを公式ドキュメントなどを参考に調べてください。\n","\n","\n","《ヒント》\n","\n","\n","以下の2箇所は2クラス分類特有の処理です。\n","\n","\n","1\n","loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits))\n","\n","1\n","correct_pred = tf.equal(tf.sign(Y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n","\n","メソッドは以下のように公式ドキュメントを確認してください。\n","\n","\n","tf.nn.sigmoid_cross_entropy_with_logits  |  TensorFlow\n","\n","\n","tf.math.sign  |  TensorFlow\n","\n","\n","＊tf.signとtf.math.signは同じ働きをします。"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"df5piUrdau7h","executionInfo":{"status":"ok","timestamp":1629978002361,"user_tz":-540,"elapsed":1061,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"536b243d-6301-44d4-8926-2072d1b2e8d9"},"source":["# \"\"\"\n","# TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n","# \"\"\"\n","# import numpy as np\n","# import pandas as pd\n","# from sklearn.model_selection import train_test_split\n","# import tensorflow as tf\n","# # データセットの読み込み\n","# #dataset_path =\"Iris.csv\"\n","# dataset_path ='/content/drive/MyDrive/DIC/Iris.csv'\n","# df = pd.read_csv(dataset_path)  \n","# df.head\n","# print(df)\n","# # データフレームから条件抽出\n","# # df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n","# df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")|(df[\"Species\"] == \"Iris-setosa\")]\n","# y = df[\"Species\"]\n","# X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n","# y = np.array(y)\n","# X = np.array(X).astype(np.float32)\n","# # ラベルを数値に変換\n","# y[y=='Iris-versicolor'] = 0\n","# y[y=='Iris-virginica'] = 1\n","# y[y=='Iris-setosa'] = 2\n","# y = y.astype(np.float32)[:, np.newaxis]\n","# # trainとtestに分割\n","# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","# # さらにtrainとvalに分割\n","# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n","# class GetMiniBatch:\n","#     \"\"\"\n","#     ミニバッチを取得するイテレータ\n","#     Parameters\n","#     ----------\n","#     X : 次の形のndarray, shape (n_samples, n_features)\n","#       訓練データ\n","#     y : 次の形のndarray, shape (n_samples, 1)\n","#       正解値\n","#     batch_size : int\n","#       バッチサイズ\n","#     seed : int\n","#       NumPyの乱数のシード\n","#     \"\"\"\n","#     def __init__(self, X, y, batch_size = 10, seed=0):\n","#         self.batch_size = batch_size\n","#         np.random.seed(seed)\n","#         shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n","#         self.X = X[shuffle_index]\n","#         self.y = y[shuffle_index]\n","#         self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n","#     def __len__(self):\n","#         return self._stop\n","#     def __getitem__(self,item):\n","#         p0 = item*self.batch_size\n","#         p1 = item*self.batch_size + self.batch_size\n","#         return self.X[p0:p1], self.y[p0:p1]        \n","#     def __iter__(self):\n","#         self._counter = 0\n","#         return self\n","#     def __next__(self):\n","#         if self._counter >= self._stop:\n","#             raise StopIteration()\n","#         p0 = self._counter*self.batch_size\n","#         p1 = self._counter*self.batch_size + self.batch_size\n","#         self._counter += 1\n","#         return self.X[p0:p1], self.y[p0:p1]\n","# # ハイパーパラメータの設定\n","# learning_rate = 0.01\n","# batch_size = 10\n","# num_epochs = 10\n","# n_hidden1 = 50\n","# n_hidden2 = 100\n","# n_input = X_train.shape[1]\n","# n_samples = X_train.shape[0]\n","# n_classes = 1\n","# # trainのミニバッチイテレータ\n","# get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n","\n","# class MyModel(tf.keras.Model):\n","#     def __init__(self):\n","#         super().__init__()\n","#         # 重みとバイアスの宣言\n","#         self.w1 = tf.Variable(tf.random.normal([n_input, n_hidden1]), trainable=True)\n","#         self.w2 = tf.Variable(tf.random.normal([n_hidden1, n_hidden2]), trainable=True)\n","#         self.w3 = tf.Variable(tf.random.normal([n_hidden2, n_classes]), trainable=True)\n","#         self.b1 = tf.Variable(tf.random.normal([n_hidden1]), trainable=True)\n","#         self.b2 = tf.Variable(tf.random.normal([n_hidden2]), trainable=True)\n","#         self.b3 = tf.Variable(tf.random.normal([n_classes]), trainable=True)\n","#     def call(self, x):\n","#         \"\"\"\n","#         単純な3層ニューラルネットワーク\n","#         \"\"\"\n","#         layer_1 = tf.add(tf.matmul(x, self.w1), self.b1)\n","#         layer_1 = tf.nn.relu(layer_1)\n","#         layer_2 = tf.add(tf.matmul(layer_1, self.w2), self.b2)\n","#         layer_2 = tf.nn.relu(layer_2)\n","#         layer_output = tf.matmul(layer_2, self.w3) + self.b3  # tf.addと+は等価である\n","#         return layer_output\n","# model = MyModel()\n","\n","# # # 最適化手法\n","# optimizer = tf.keras.optimizers.Adam(learning_rate)\n","# #loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=u, labels=y_))\n","# def train(x, y):\n","#     logits = model(x, training=True)\n","#     loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(y, logits))\n","#     return loss\n","\n","# def evaluate(x, y):\n","#     logits = model(x)\n","#     loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(y, logits))\n","#     # 推定結果\n","#     # correct_pred = tf.equal(tf.sign(y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n","#     correct_pred = tf.equal(tf.sign(y - 1/3), tf.sign(tf.sigmoid(logits) - 1/3))\n","#     # 指標値計算\n","#     accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n","#     return loss, accuracy\n","\n","# # 計算グラフの実行\n","# for epoch in range(num_epochs):\n","#     # エポックごとにループ\n","#     total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n","#     total_loss = 0\n","#     total_acc = 0\n","#     for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n","#         # ミニバッチごとにループ\n","#         with tf.GradientTape() as tape:\n","#             loss = train(mini_batch_x, mini_batch_y)\n","#         grads = tape.gradient(loss, model.trainable_weights)\n","#         optimizer.apply_gradients(zip(grads, model.trainable_weights))\n","#         total_loss += loss\n","#     loss = total_loss / n_samples\n","#     val_loss, val_acc = evaluate(X_val, y_val)\n","#     # print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, val_acc))\n","# # _, test_acc = evaluate(X_test, y_test)\n","# test_acc = evaluate(X_test, y_test)\n","# print(\"test_acc : {:.3f}\".format(test_acc))\n","\n","\"\"\"\n","TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n","\"\"\"\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from sklearn.preprocessing import OneHotEncoder \n","\n","# データセットの読み込み\n","dataset_path ='/content/drive/MyDrive/DIC/Iris.csv'\n","df = pd.read_csv(dataset_path)\n","\n","# データフレームから条件抽出\n","y = df[\"Species\"]\n","X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n","y = np.array(y)\n","X = np.array(X)\n","\n","# ラベルを数値に変換\n","y[y=='Iris-setosa'] = 0\n","y[y=='Iris-versicolor'] = 1\n","y[y=='Iris-virginica'] = 2\n","y = y.astype(np.int)[:, np.newaxis]\n","print(\"y.shape = \", y.shape)\n","\n","# one-hot-vectol化\n","enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n","#y_train_one_hot = enc.fit_transform(y[:, np.newaxis])\n","y_train_one_hot = enc.fit_transform(y)\n","\n","# trainとtestに分割\n","X_train, X_test, y_train, y_test = train_test_split(X, y_train_one_hot, test_size=0.2, random_state=0)\n","\n","# さらにtrainとvalに分割\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n","\n","tf.compat.v1.reset_default_graph()\n","\n","class GetMiniBatch:\n","    \"\"\"\n","    ミニバッチを取得するイテレータ\n","\n","    Parameters\n","    ----------\n","    X : 次の形のndarray, shape (n_samples, n_features)\n","      訓練データ\n","    y : 次の形のndarray, shape (n_samples, 1)\n","      正解値\n","    batch_size : int\n","      バッチサイズ\n","    seed : int\n","      NumPyの乱数のシード\n","    \"\"\"\n","    def __init__(self, X, y, batch_size = 10, seed=0):\n","        self.batch_size = batch_size\n","        np.random.seed(seed)\n","        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n","        self.X = X[shuffle_index]\n","        self.y = y[shuffle_index]\n","        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n","        \n","    def __len__(self):\n","        return self._stop\n","    \n","    def __getitem__(self,item):\n","        p0 = item*self.batch_size\n","        p1 = item*self.batch_size + self.batch_size\n","        return self.X[p0:p1], self.y[p0:p1]        \n","    \n","    def __iter__(self):\n","        self._counter = 0\n","        return self\n","    \n","    def __next__(self):\n","        if self._counter >= self._stop:\n","            raise StopIteration()\n","        p0 = self._counter*self.batch_size\n","        p1 = self._counter*self.batch_size + self.batch_size\n","        self._counter += 1\n","        return self.X[p0:p1], self.y[p0:p1]\n","    \n","# ハイパーパラメータの設定\n","learning_rate = 0.01\n","batch_size = 10\n","num_epochs = 20\n","n_hidden1 = 50\n","n_hidden2 = 100\n","n_classes = 3\n","n_input = X_train.shape[1]\n","n_samples = X_train.shape[0]\n","\n","\n","# 計算グラフに渡す引数の形を決める\n","X = tf.compat.v1.placeholder(\"float\", [None, n_input])\n","Y = tf.compat.v1.placeholder(\"float\", [None, n_classes])\n","\n","# trainのミニバッチイテレータ\n","get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n","\n","def example_net(x):\n","    \"\"\"\n","    単純な3層ニューラルネットワーク\n","    \"\"\"\n","    # 重みとバイアスの宣言\n","    he_initializer1 = tf.initializers.he_normal()\n","    he_initializer2 = tf.initializers.he_normal()\n","    he_initializer3 = tf.initializers.he_normal()\n","    \n","    weights = {\n","        'w1': tf.compat.v1.get_variable(name = \"W1\", shape=[n_input, n_hidden1], initializer=he_initializer1),\n","        'w2': tf.compat.v1.get_variable(name = \"W2\", shape=[n_hidden1, n_hidden2], initializer=he_initializer2),\n","        'w3': tf.compat.v1.get_variable(name = \"W3\", shape=[n_hidden2, n_classes], initializer=he_initializer3),\n","    }\n","    biases = {\n","        'b1': tf.compat.v1.Variable(tf.compat.v1.random_normal([n_hidden1])),\n","        'b2': tf.compat.v1.Variable(tf.compat.v1.random_normal([n_hidden2])),\n","        'b3': tf.compat.v1.Variable(tf.compat.v1.random_normal([n_classes]))\n","    }\n","    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n","    layer_1 = tf.nn.relu(layer_1)\n","    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n","    layer_2 = tf.nn.relu(layer_2)\n","    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] # tf.addと+は等価である\n","    return layer_output\n","\n","# ネットワーク構造の読み込み 出力：logits                              \n","logits = example_net(X)\n","\n","# 目的関数\n","loss_op = tf.reduce_mean(tf.compat.v1.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=logits))\n","\n","# 最適化手法\n","optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n","train_op = optimizer.minimize(loss_op)\n","\n","# 推定値\n","y_pred = tf.nn.softmax(logits)\n","\n","\n","# 推定結果\n","#                       Y:正解ラベル、              y_pred:推定ラベル\n","correct_pred = tf.equal(tf.argmax(Y, 1), tf.argmax(y_pred, 1))\n","\n","# 指標値計算\n","accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n","\n","# variableの初期化\n","init = tf.compat.v1.global_variables_initializer()\n","\n","\n","# 計算グラフの実行\n","with tf.compat.v1.Session() as sess:\n","    sess.run(init)\n","    \n","    train_loss_list = []\n","    val_loss_list = []\n","    train_acc_list = []\n","    val_acc_list = []\n","    for epoch in range(num_epochs):\n","        # エポックごとにループ\n","        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n","        total_loss = 0\n","        total_acc = 0\n","        total_val_loss = 0\n","        total_val_acc = 0\n","        \n","        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n","            # ミニバッチごとにループ\n","            _, loss, acc = sess.run([train_op, loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n","            val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n","            total_loss += loss\n","            total_acc += acc\n","            total_val_loss += val_loss\n","            total_val_acc += val_acc            \n","            \n","        total_loss /= total_batch\n","        total_acc /= total_batch\n","        total_val_loss /= total_batch\n","        total_val_acc /= total_batch\n","        \n","        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch + 1, total_loss, total_val_loss, total_acc, total_val_acc))\n","        train_loss_list.append(total_loss)\n","        val_loss_list.append(total_val_loss)\n","        train_acc_list.append(total_acc)\n","        val_acc_list.append(total_val_acc)\n","        \n","    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n","    print(\"test_acc : {:.3f}\".format(test_acc))\n","\n","\n"],"execution_count":188,"outputs":[{"output_type":"stream","text":["y.shape =  (150, 1)\n","Epoch 1, loss : 2.9276, val_loss : 2.6899, acc : 0.423, val_acc : 0.425\n","Epoch 2, loss : 0.6383, val_loss : 0.7137, acc : 0.740, val_acc : 0.733\n","Epoch 3, loss : 0.4118, val_loss : 0.5258, acc : 0.820, val_acc : 0.762\n","Epoch 4, loss : 0.2677, val_loss : 0.3841, acc : 0.880, val_acc : 0.838\n","Epoch 5, loss : 0.1180, val_loss : 0.2647, acc : 0.950, val_acc : 0.896\n","Epoch 6, loss : 0.0671, val_loss : 0.2116, acc : 0.990, val_acc : 0.921\n","Epoch 7, loss : 0.0548, val_loss : 0.2132, acc : 0.980, val_acc : 0.917\n","Epoch 8, loss : 0.0575, val_loss : 0.2224, acc : 0.990, val_acc : 0.917\n","Epoch 9, loss : 0.0583, val_loss : 0.2263, acc : 0.980, val_acc : 0.925\n","Epoch 10, loss : 0.0539, val_loss : 0.2250, acc : 0.980, val_acc : 0.925\n","Epoch 11, loss : 0.0505, val_loss : 0.2253, acc : 0.990, val_acc : 0.925\n","Epoch 12, loss : 0.0493, val_loss : 0.2284, acc : 0.980, val_acc : 0.929\n","Epoch 13, loss : 0.0503, val_loss : 0.2346, acc : 0.980, val_acc : 0.917\n","Epoch 14, loss : 0.0537, val_loss : 0.2439, acc : 0.970, val_acc : 0.908\n","Epoch 15, loss : 0.0600, val_loss : 0.2568, acc : 0.970, val_acc : 0.900\n","Epoch 16, loss : 0.0689, val_loss : 0.2728, acc : 0.960, val_acc : 0.900\n","Epoch 17, loss : 0.0775, val_loss : 0.2862, acc : 0.960, val_acc : 0.896\n","Epoch 18, loss : 0.0804, val_loss : 0.2908, acc : 0.960, val_acc : 0.900\n","Epoch 19, loss : 0.0737, val_loss : 0.2833, acc : 0.960, val_acc : 0.904\n","Epoch 20, loss : 0.0574, val_loss : 0.2638, acc : 0.960, val_acc : 0.904\n","test_acc : 0.967\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oIgQcPCHaz5T"},"source":["【問題4】House Pricesのモデルを作成\n","回帰問題のデータセットであるHouse Pricesを使用したモデルを作成してください。\n","\n","\n","House Prices: Advanced Regression Techniques\n","\n","\n","この中のtrain.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使ってください。説明変数はさらに増やしても構いません。\n","\n","\n","分類問題と回帰問題の違いを考慮してください。"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rWXRFe0v4W8K","executionInfo":{"status":"ok","timestamp":1629978002362,"user_tz":-540,"elapsed":7,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"5dc0680f-c267-4ed1-c333-3c7532e9cf44"},"source":["# テンソルフロー\n","import tensorflow as tf\n","# 計算やデータ処理のライブラリ\n","import numpy as np\n","import pandas as pd\n","# データ可視化のライブラリ\n","import matplotlib.pyplot as plt\n","# データセットの取得&処理のライブラリ\n","from sklearn.datasets import load_boston\n","from sklearn.model_selection import train_test_split\n","# インポートの確認\n","print(tf.__version__)\n","print(np.__version__)\n","print(pd.__version__)\n"],"execution_count":189,"outputs":[{"output_type":"stream","text":["2.6.0\n","1.19.5\n","1.1.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"id":"D5L-BVqv4gfQ","executionInfo":{"status":"ok","timestamp":1629978003190,"user_tz":-540,"elapsed":831,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"3918bdf1-8348-40b9-efb5-da27fa279b1e"},"source":["# # データの読み込み\n","# boston = load_boston()\n","# # Pandasのデータフレーム形式へ変換\n","# df = pd.DataFrame(boston.data, columns=boston.feature_names)\n","# df['target'] = boston.target\n","# # データの最初の5行を表示\n","# df.head()\n","\n","\n","# データの読み込み\n","df = pd.read_csv('/content/drive/MyDrive/DIC/train.csv')\n","# print(df)\n","df.head()\n"],"execution_count":190,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>MSSubClass</th>\n","      <th>MSZoning</th>\n","      <th>LotFrontage</th>\n","      <th>LotArea</th>\n","      <th>Street</th>\n","      <th>Alley</th>\n","      <th>LotShape</th>\n","      <th>LandContour</th>\n","      <th>Utilities</th>\n","      <th>LotConfig</th>\n","      <th>LandSlope</th>\n","      <th>Neighborhood</th>\n","      <th>Condition1</th>\n","      <th>Condition2</th>\n","      <th>BldgType</th>\n","      <th>HouseStyle</th>\n","      <th>OverallQual</th>\n","      <th>OverallCond</th>\n","      <th>YearBuilt</th>\n","      <th>YearRemodAdd</th>\n","      <th>RoofStyle</th>\n","      <th>RoofMatl</th>\n","      <th>Exterior1st</th>\n","      <th>Exterior2nd</th>\n","      <th>MasVnrType</th>\n","      <th>MasVnrArea</th>\n","      <th>ExterQual</th>\n","      <th>ExterCond</th>\n","      <th>Foundation</th>\n","      <th>BsmtQual</th>\n","      <th>BsmtCond</th>\n","      <th>BsmtExposure</th>\n","      <th>BsmtFinType1</th>\n","      <th>BsmtFinSF1</th>\n","      <th>BsmtFinType2</th>\n","      <th>BsmtFinSF2</th>\n","      <th>BsmtUnfSF</th>\n","      <th>TotalBsmtSF</th>\n","      <th>Heating</th>\n","      <th>...</th>\n","      <th>CentralAir</th>\n","      <th>Electrical</th>\n","      <th>1stFlrSF</th>\n","      <th>2ndFlrSF</th>\n","      <th>LowQualFinSF</th>\n","      <th>GrLivArea</th>\n","      <th>BsmtFullBath</th>\n","      <th>BsmtHalfBath</th>\n","      <th>FullBath</th>\n","      <th>HalfBath</th>\n","      <th>BedroomAbvGr</th>\n","      <th>KitchenAbvGr</th>\n","      <th>KitchenQual</th>\n","      <th>TotRmsAbvGrd</th>\n","      <th>Functional</th>\n","      <th>Fireplaces</th>\n","      <th>FireplaceQu</th>\n","      <th>GarageType</th>\n","      <th>GarageYrBlt</th>\n","      <th>GarageFinish</th>\n","      <th>GarageCars</th>\n","      <th>GarageArea</th>\n","      <th>GarageQual</th>\n","      <th>GarageCond</th>\n","      <th>PavedDrive</th>\n","      <th>WoodDeckSF</th>\n","      <th>OpenPorchSF</th>\n","      <th>EnclosedPorch</th>\n","      <th>3SsnPorch</th>\n","      <th>ScreenPorch</th>\n","      <th>PoolArea</th>\n","      <th>PoolQC</th>\n","      <th>Fence</th>\n","      <th>MiscFeature</th>\n","      <th>MiscVal</th>\n","      <th>MoSold</th>\n","      <th>YrSold</th>\n","      <th>SaleType</th>\n","      <th>SaleCondition</th>\n","      <th>SalePrice</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>60</td>\n","      <td>RL</td>\n","      <td>65.0</td>\n","      <td>8450</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>Inside</td>\n","      <td>Gtl</td>\n","      <td>CollgCr</td>\n","      <td>Norm</td>\n","      <td>Norm</td>\n","      <td>1Fam</td>\n","      <td>2Story</td>\n","      <td>7</td>\n","      <td>5</td>\n","      <td>2003</td>\n","      <td>2003</td>\n","      <td>Gable</td>\n","      <td>CompShg</td>\n","      <td>VinylSd</td>\n","      <td>VinylSd</td>\n","      <td>BrkFace</td>\n","      <td>196.0</td>\n","      <td>Gd</td>\n","      <td>TA</td>\n","      <td>PConc</td>\n","      <td>Gd</td>\n","      <td>TA</td>\n","      <td>No</td>\n","      <td>GLQ</td>\n","      <td>706</td>\n","      <td>Unf</td>\n","      <td>0</td>\n","      <td>150</td>\n","      <td>856</td>\n","      <td>GasA</td>\n","      <td>...</td>\n","      <td>Y</td>\n","      <td>SBrkr</td>\n","      <td>856</td>\n","      <td>854</td>\n","      <td>0</td>\n","      <td>1710</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>Gd</td>\n","      <td>8</td>\n","      <td>Typ</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>Attchd</td>\n","      <td>2003.0</td>\n","      <td>RFn</td>\n","      <td>2</td>\n","      <td>548</td>\n","      <td>TA</td>\n","      <td>TA</td>\n","      <td>Y</td>\n","      <td>0</td>\n","      <td>61</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2008</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>208500</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>20</td>\n","      <td>RL</td>\n","      <td>80.0</td>\n","      <td>9600</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>FR2</td>\n","      <td>Gtl</td>\n","      <td>Veenker</td>\n","      <td>Feedr</td>\n","      <td>Norm</td>\n","      <td>1Fam</td>\n","      <td>1Story</td>\n","      <td>6</td>\n","      <td>8</td>\n","      <td>1976</td>\n","      <td>1976</td>\n","      <td>Gable</td>\n","      <td>CompShg</td>\n","      <td>MetalSd</td>\n","      <td>MetalSd</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>TA</td>\n","      <td>TA</td>\n","      <td>CBlock</td>\n","      <td>Gd</td>\n","      <td>TA</td>\n","      <td>Gd</td>\n","      <td>ALQ</td>\n","      <td>978</td>\n","      <td>Unf</td>\n","      <td>0</td>\n","      <td>284</td>\n","      <td>1262</td>\n","      <td>GasA</td>\n","      <td>...</td>\n","      <td>Y</td>\n","      <td>SBrkr</td>\n","      <td>1262</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1262</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>TA</td>\n","      <td>6</td>\n","      <td>Typ</td>\n","      <td>1</td>\n","      <td>TA</td>\n","      <td>Attchd</td>\n","      <td>1976.0</td>\n","      <td>RFn</td>\n","      <td>2</td>\n","      <td>460</td>\n","      <td>TA</td>\n","      <td>TA</td>\n","      <td>Y</td>\n","      <td>298</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2007</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>181500</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>60</td>\n","      <td>RL</td>\n","      <td>68.0</td>\n","      <td>11250</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>IR1</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>Inside</td>\n","      <td>Gtl</td>\n","      <td>CollgCr</td>\n","      <td>Norm</td>\n","      <td>Norm</td>\n","      <td>1Fam</td>\n","      <td>2Story</td>\n","      <td>7</td>\n","      <td>5</td>\n","      <td>2001</td>\n","      <td>2002</td>\n","      <td>Gable</td>\n","      <td>CompShg</td>\n","      <td>VinylSd</td>\n","      <td>VinylSd</td>\n","      <td>BrkFace</td>\n","      <td>162.0</td>\n","      <td>Gd</td>\n","      <td>TA</td>\n","      <td>PConc</td>\n","      <td>Gd</td>\n","      <td>TA</td>\n","      <td>Mn</td>\n","      <td>GLQ</td>\n","      <td>486</td>\n","      <td>Unf</td>\n","      <td>0</td>\n","      <td>434</td>\n","      <td>920</td>\n","      <td>GasA</td>\n","      <td>...</td>\n","      <td>Y</td>\n","      <td>SBrkr</td>\n","      <td>920</td>\n","      <td>866</td>\n","      <td>0</td>\n","      <td>1786</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>Gd</td>\n","      <td>6</td>\n","      <td>Typ</td>\n","      <td>1</td>\n","      <td>TA</td>\n","      <td>Attchd</td>\n","      <td>2001.0</td>\n","      <td>RFn</td>\n","      <td>2</td>\n","      <td>608</td>\n","      <td>TA</td>\n","      <td>TA</td>\n","      <td>Y</td>\n","      <td>0</td>\n","      <td>42</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>2008</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>223500</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>70</td>\n","      <td>RL</td>\n","      <td>60.0</td>\n","      <td>9550</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>IR1</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>Corner</td>\n","      <td>Gtl</td>\n","      <td>Crawfor</td>\n","      <td>Norm</td>\n","      <td>Norm</td>\n","      <td>1Fam</td>\n","      <td>2Story</td>\n","      <td>7</td>\n","      <td>5</td>\n","      <td>1915</td>\n","      <td>1970</td>\n","      <td>Gable</td>\n","      <td>CompShg</td>\n","      <td>Wd Sdng</td>\n","      <td>Wd Shng</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>TA</td>\n","      <td>TA</td>\n","      <td>BrkTil</td>\n","      <td>TA</td>\n","      <td>Gd</td>\n","      <td>No</td>\n","      <td>ALQ</td>\n","      <td>216</td>\n","      <td>Unf</td>\n","      <td>0</td>\n","      <td>540</td>\n","      <td>756</td>\n","      <td>GasA</td>\n","      <td>...</td>\n","      <td>Y</td>\n","      <td>SBrkr</td>\n","      <td>961</td>\n","      <td>756</td>\n","      <td>0</td>\n","      <td>1717</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>Gd</td>\n","      <td>7</td>\n","      <td>Typ</td>\n","      <td>1</td>\n","      <td>Gd</td>\n","      <td>Detchd</td>\n","      <td>1998.0</td>\n","      <td>Unf</td>\n","      <td>3</td>\n","      <td>642</td>\n","      <td>TA</td>\n","      <td>TA</td>\n","      <td>Y</td>\n","      <td>0</td>\n","      <td>35</td>\n","      <td>272</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2006</td>\n","      <td>WD</td>\n","      <td>Abnorml</td>\n","      <td>140000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>60</td>\n","      <td>RL</td>\n","      <td>84.0</td>\n","      <td>14260</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>IR1</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>FR2</td>\n","      <td>Gtl</td>\n","      <td>NoRidge</td>\n","      <td>Norm</td>\n","      <td>Norm</td>\n","      <td>1Fam</td>\n","      <td>2Story</td>\n","      <td>8</td>\n","      <td>5</td>\n","      <td>2000</td>\n","      <td>2000</td>\n","      <td>Gable</td>\n","      <td>CompShg</td>\n","      <td>VinylSd</td>\n","      <td>VinylSd</td>\n","      <td>BrkFace</td>\n","      <td>350.0</td>\n","      <td>Gd</td>\n","      <td>TA</td>\n","      <td>PConc</td>\n","      <td>Gd</td>\n","      <td>TA</td>\n","      <td>Av</td>\n","      <td>GLQ</td>\n","      <td>655</td>\n","      <td>Unf</td>\n","      <td>0</td>\n","      <td>490</td>\n","      <td>1145</td>\n","      <td>GasA</td>\n","      <td>...</td>\n","      <td>Y</td>\n","      <td>SBrkr</td>\n","      <td>1145</td>\n","      <td>1053</td>\n","      <td>0</td>\n","      <td>2198</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>Gd</td>\n","      <td>9</td>\n","      <td>Typ</td>\n","      <td>1</td>\n","      <td>TA</td>\n","      <td>Attchd</td>\n","      <td>2000.0</td>\n","      <td>RFn</td>\n","      <td>3</td>\n","      <td>836</td>\n","      <td>TA</td>\n","      <td>TA</td>\n","      <td>Y</td>\n","      <td>192</td>\n","      <td>84</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>2008</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>250000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 81 columns</p>\n","</div>"],"text/plain":["   Id  MSSubClass MSZoning  ...  SaleType  SaleCondition SalePrice\n","0   1          60       RL  ...        WD         Normal    208500\n","1   2          20       RL  ...        WD         Normal    181500\n","2   3          60       RL  ...        WD         Normal    223500\n","3   4          70       RL  ...        WD        Abnorml    140000\n","4   5          60       RL  ...        WD         Normal    250000\n","\n","[5 rows x 81 columns]"]},"metadata":{},"execution_count":190}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SqlmuTRc4vJB","executionInfo":{"status":"ok","timestamp":1629978003191,"user_tz":-540,"elapsed":28,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"a218cad1-b452-46de-a665-9fd33311b794"},"source":["# # 特徴量とターゲットに切り分け\n","# X_data = np.array(boston.data)\n","# y_data = np.array(boston.target)\n","# # １行目のデータの特徴量（X)とターゲット（y）を確認\n","# print(X_data[0:1])\n","# print(y_data[0:1])\n","\n","\n","\n","x=df.loc[:,['GrLivArea','YearBuilt']]\n","X_data = np.array(x)\n","print(X_data[0:1])\n","# print(type(x))\n","# print(x)\n","\n","target = df.loc[:, ['SalePrice']]\n","y_data = np.array(target)\n","print(y_data[0:1])\n","# print(target[:])\n","# print(type(target))\n","\n"],"execution_count":191,"outputs":[{"output_type":"stream","text":["[[1710 2003]]\n","[[208500]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QnjeVoHj42-M","executionInfo":{"status":"ok","timestamp":1629978003192,"user_tz":-540,"elapsed":25,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"a69be284-32dd-4f1e-c102-056fd03db238"},"source":["# 正規化\n","def norm(data):\n","  mean = np.mean(data, axis=0)\n","  std = np.std(data, axis=0)\n","  return (data - mean) / std\n","# データを変更\n","X_data = norm(X_data)\n","print(X_data[0:1])\n"],"execution_count":192,"outputs":[{"output_type":"stream","text":["[[0.37033344 1.05099379]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oU-rmGt45Cdp","executionInfo":{"status":"ok","timestamp":1629978003192,"user_tz":-540,"elapsed":22,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"015bcca1-ec43-4cf8-c4cc-d5bd16997c96"},"source":["# 1を追加する前のサイズ\n","print(X_data.shape)\n","# 1を作成\n","# ones = np.ones((506, 1))\n","ones = np.ones((1460, 1))\n","# 1を追加\n","X_data = np.c_[ones, X_data]\n","X_data.shape\n"],"execution_count":193,"outputs":[{"output_type":"stream","text":["(1460, 2)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(1460, 3)"]},"metadata":{},"execution_count":193}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6MtqrVsE5Sgr","executionInfo":{"status":"ok","timestamp":1629978003193,"user_tz":-540,"elapsed":20,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"2133e1f0-bf1e-422a-dafe-0162381902ce"},"source":["# 訓練データとテストデータへ切り分け\n","X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n","# y_train = y_train.reshape(404,1)\n","y_train = y_train.reshape(1168,1)\n","# y_test = y_test.reshape(102,1)\n","y_test = y_test.reshape(292,1)\n","print(X_train.shape)\n","print(y_train.shape)\n","print(X_test.shape)\n","print(y_test.shape)\n"],"execution_count":194,"outputs":[{"output_type":"stream","text":["(1168, 3)\n","(1168, 1)\n","(292, 3)\n","(292, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZZRvblWR5XY9","executionInfo":{"status":"ok","timestamp":1629978003193,"user_tz":-540,"elapsed":18,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}}},"source":["# 学習率とエポック（反復処理回数）\n","learning_rate = 0.01\n","training_epochs = 101\n","# 特徴量の数\n","n_dim = X_data.shape[1]\n","tf.compat.v1.disable_eager_execution()\n","# 特徴量（X)とターゲット（y）のプレースホルダー\n","# X = tf.placeholder(tf.float32,[None,n_dim])\n","# Y = tf.placeholder(tf.float32,[None,1])\n","X = tf.compat.v1.placeholder(tf.float32,[None,n_dim])\n","Y = tf.compat.v1.placeholder(tf.float32,[None,1])\n","# 係数（W）と定数項（b）の変数\n","W = tf.Variable(tf.ones([n_dim,1]))\n","b = tf.Variable(0.0)\n"],"execution_count":195,"outputs":[]},{"cell_type":"code","metadata":{"id":"AL5Q8f1z8o5e","executionInfo":{"status":"ok","timestamp":1629978003194,"user_tz":-540,"elapsed":18,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}}},"source":["# 線形モデル\n","y = tf.add(b, tf.matmul(X, W))\n","# コスト関数\n","cost = tf.reduce_mean(tf.square(y - Y))\n","# 最適化\n","# training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n","# training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n","opt = tf.compat.v1.train.GradientDescentOptimizer(learning_rate)\n","training_step = opt.minimize(cost)"],"execution_count":196,"outputs":[]},{"cell_type":"code","metadata":{"id":"T3GgNEvP_aRf","executionInfo":{"status":"ok","timestamp":1629978003194,"user_tz":-540,"elapsed":17,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}}},"source":["# 初期化\n","# init = tf.global_variables_initializer()\n","init = tf.compat.v1.global_variables_initializer()\n","cost_history = []\n","# モデル訓練開始\n","# sess = tf.Session()\n","sess = tf.compat.v1.Session()\n","sess.run(init)\n","for epoch in range(training_epochs):\n","  sess.run(training_step, feed_dict={X:X_train, Y:y_train})\n","  cost_history = np.append(cost_history, sess.run(cost, feed_dict={X:X_train, Y:y_train}))\n","  if epoch % 100 == 0:\n","    W_val = sess.run(W)\n","    b_val = sess.run(b)\n"],"execution_count":197,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aN0tBkV8ElP1","executionInfo":{"status":"ok","timestamp":1629978003194,"user_tz":-540,"elapsed":16,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"1c379cce-9b18-4a3a-844a-a44c288894d7"},"source":["# 誤差（cost）を確認\n","print(cost_history[1])\n","print(cost_history[50])\n","print(cost_history[100])\n"],"execution_count":198,"outputs":[{"output_type":"stream","text":["33553827840.0\n","2938533632.0\n","2146661120.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1PwZJoRsElXD","executionInfo":{"status":"ok","timestamp":1629978003195,"user_tz":-540,"elapsed":15,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}}},"source":["# テストデータを使って予測\n","pred_test = sess.run(y, feed_dict={X: X_test})\n"],"execution_count":199,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"-kAY9WE-Eled","executionInfo":{"status":"ok","timestamp":1629978003195,"user_tz":-540,"elapsed":14,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"183c141d-5e2c-4906-e5c5-4e0e198b10ab"},"source":["pred = pd.DataFrame({\"実際の不動産価格\":y_test[:,0], \"予測した不動産価格\":pred_test[:,0]})\n","pred.head()\n"],"execution_count":200,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>実際の不動産価格</th>\n","      <th>予測した不動産価格</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>154500</td>\n","      <td>132766.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>325000</td>\n","      <td>291656.125000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>115000</td>\n","      <td>94847.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>159000</td>\n","      <td>166902.937500</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>315500</td>\n","      <td>220907.578125</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   実際の不動産価格      予測した不動産価格\n","0    154500  132766.000000\n","1    325000  291656.125000\n","2    115000   94847.000000\n","3    159000  166902.937500\n","4    315500  220907.578125"]},"metadata":{},"execution_count":200}]},{"cell_type":"markdown","metadata":{"id":"wvPygU9QJ1hX"},"source":["【問題4回答まとめ】House Pricesのモデルを作成 回帰問題のデータセットであるHouse Pricesを使用したモデルを作成して、学習させて、住宅価格の正解値と予想値を比較した。\n","\n","分類問題と回帰問題の違いを考慮してください。\n","初めに、分類問題のアヤメのコードと同様な流れで解こうとしたが、出来なかった。そこで、有名なボストンの住宅価格のコードを参考にして解いたら住宅価格が予測できた。つまり、この問題は、回帰問題でない回答できないことが分かった。"]},{"cell_type":"code","metadata":{"id":"_bPMsYPtEl5d","executionInfo":{"status":"ok","timestamp":1629978003195,"user_tz":-540,"elapsed":13,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}}},"source":[""],"execution_count":200,"outputs":[]},{"cell_type":"code","metadata":{"id":"ePEMNzyD9uoL","executionInfo":{"status":"ok","timestamp":1629978003196,"user_tz":-540,"elapsed":14,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}}},"source":[""],"execution_count":200,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LNaBp2Vua0Wl"},"source":["【問題5】MNISTのモデルを作成\n","ニューラルネットワークのスクラッチで使用したMNISTを分類するモデルを作成してください。\n","\n","\n","3クラス以上の分類という点ではひとつ前のIrisと同様です。入力が画像であるという点で異なります。\n","\n","\n","スクラッチで実装したモデルの再現を目指してください。"]},{"cell_type":"code","metadata":{"id":"qbLz4XuyOPNx","executionInfo":{"status":"ok","timestamp":1629978003196,"user_tz":-540,"elapsed":13,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}}},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"],"execution_count":201,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"OIeCvqZyOPVZ","executionInfo":{"status":"ok","timestamp":1629978004011,"user_tz":-540,"elapsed":828,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"1def2ff7-4ec9-4847-83a4-9b6393f83fd2"},"source":["import numpy as np\n","from keras.datasets import mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","\n","print(X_train.shape) # (60000, 28, 28)\n","print(X_test.shape) # (10000, 28, 28)\n","print(X_train[0].dtype) # uint8\n","print(X_train[0])\n","\n","X_train = X_train.reshape(-1, 784)\n","X_test = X_test.reshape(-1, 784)\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","index = 0\n","image = X_train[index].reshape(28,28)\n","# X_train[index]: (784,)\n","# image: (28, 28)\n","plt.imshow(image, 'gray')\n","plt.title('label : {}'.format(y_train[index]))\n","plt.show()\n","\n","index = 0\n","image = X_train[index].reshape(28,28)\n","image = image.astype(np.float) # float型に変換\n","image -= 105.35 # 意図的に負の小数値を作り出してみる\n","plt.imshow(image, 'gray')\n","plt.title('label : {}'.format(y_train[index]))\n","plt.show()\n","print(image) # 値を確認\n","\n","plt.imshow(image, 'gray', vmin = 0, vmax = 255)\n","\n","\n","X_train = X_train.astype(np.float)\n","X_test = X_test.astype(np.float)\n","X_train /= 255\n","X_test /= 255\n","print(X_train.max()) # 1.0\n","print(X_train.min()) # 0.0"],"execution_count":202,"outputs":[{"output_type":"stream","text":["(60000, 28, 28)\n","(10000, 28, 28)\n","uint8\n","[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n","  175  26 166 255 247 127   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n","  225 172 253 242 195  64   0   0   0   0]\n"," [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n","   93  82  82  56  39   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n","   25   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n","  150  27   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n","  253 187   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n","  253 249  64   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n","  253 207   2   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n","  250 182   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n","   78   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]]\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"stream","text":["[[-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -102.35  -87.35  -87.35  -87.35   20.65   30.65\n","    69.65  -79.35   60.65  149.65  141.65   21.65 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -75.35\n","   -69.35  -11.35   48.65   64.65  147.65  147.65  147.65  147.65  147.65\n","   119.65   66.65  147.65  136.65   89.65  -41.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -56.35  132.65\n","   147.65  147.65  147.65  147.65  147.65  147.65  147.65  147.65  145.65\n","   -12.35  -23.35  -23.35  -49.35  -66.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35  113.65\n","   147.65  147.65  147.65  147.65  147.65   92.65   76.65  141.65  135.65\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -25.35\n","    50.65    1.65  147.65  147.65   99.65  -94.35 -105.35  -62.35   48.65\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","   -91.35 -104.35   48.65  147.65  -15.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35   33.65  147.65   84.65 -103.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35  -94.35   84.65  147.65  -35.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35  -70.35  135.65  119.65   54.65    2.65 -104.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35  -24.35  134.65  147.65  147.65   13.65\n","   -80.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35  -60.35   80.65  147.65  147.65\n","    44.65  -78.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -89.35  -12.35  146.65\n","   147.65   81.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  143.65\n","   147.65  143.65  -41.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35  -59.35   24.65   77.65  147.65\n","   147.65  101.65 -103.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35  -66.35   42.65  123.65  147.65  147.65  147.65\n","   144.65   76.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35  -81.35    8.65  115.65  147.65  147.65  147.65  147.65   95.65\n","   -27.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -82.35\n","   -39.35  107.65  147.65  147.65  147.65  147.65   92.65  -24.35 -103.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35   65.65  113.65\n","   147.65  147.65  147.65  147.65   89.65  -25.35  -96.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35  -50.35   66.65  120.65  147.65  147.65\n","   147.65  147.65  138.65   27.65  -94.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35   30.65  147.65  147.65  147.65  106.65\n","    29.65   26.65  -89.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]]\n","1.0\n","0.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I-xvAY_VOPb7","executionInfo":{"status":"ok","timestamp":1629978004848,"user_tz":-540,"elapsed":840,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"472d1b12-154e-4166-c30d-8bdcc633c788"},"source":["from sklearn.preprocessing import OneHotEncoder\n","enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n","y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n","y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n","print(y_train.shape) # (60000,)\n","print(y_train_one_hot.shape) # (60000, 10)\n","print(y_train_one_hot.dtype) # float64"],"execution_count":203,"outputs":[{"output_type":"stream","text":["(60000,)\n","(60000, 10)\n","float64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f1f7q7QqOPip","executionInfo":{"status":"ok","timestamp":1629978004848,"user_tz":-540,"elapsed":5,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"3e85612b-924a-4483-f873-d033f7bed6a6"},"source":["X_train, X_test, y_train, y_test= train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n","print(X_train.shape) # (48000, 784)\n","print(X_test.shape) # (12000, 784)"],"execution_count":204,"outputs":[{"output_type":"stream","text":["(48000, 784)\n","(12000, 784)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-BTz_-4Va0hL","executionInfo":{"status":"ok","timestamp":1629979820649,"user_tz":-540,"elapsed":1815803,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"e9300e70-c6c2-498f-ba4a-ac51b86def31"},"source":["\"\"\"\n","TensorFlowで実装したニューラルネットワークを使いMNISTデータセットを10値分類する\n","\"\"\"\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from sklearn.preprocessing import OneHotEncoder \n","from keras.datasets import mnist\n","\n","# データセットの読み込み\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# one-hot-vectol化\n","enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n","y_train = enc.fit_transform(y_train[:, np.newaxis])\n","y_test = enc.fit_transform(y_test[:, np.newaxis])\n","\n","X_train = X_train /255\n","X_test = X_test /255\n","\n","X_train = X_train.reshape(-1, 784)\n","X_test = X_test.reshape(-1, 784)\n","\n","# さらにtrainとvalに分割\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n","\n","# tf.reset_default_graph()\n","\n","class GetMiniBatch:\n","    \"\"\"\n","    ミニバッチを取得するイテレータ\n","\n","    Parameters\n","    ----------\n","    X : 次の形のndarray, shape (n_samples, n_features)\n","      訓練データ\n","    y : 次の形のndarray, shape (n_samples, 1)\n","      正解値\n","    batch_size : int\n","      バッチサイズ\n","    seed : int\n","      NumPyの乱数のシード\n","    \"\"\"\n","    def __init__(self, X, y, batch_size = 10, seed=0):\n","        self.batch_size = batch_size\n","        np.random.seed(seed)\n","        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n","        self.X = X[shuffle_index]\n","        self.y = y[shuffle_index]\n","        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n","        \n","    def __len__(self):\n","        return self._stop\n","    \n","    def __getitem__(self,item):\n","        p0 = item*self.batch_size\n","        p1 = item*self.batch_size + self.batch_size\n","        return self.X[p0:p1], self.y[p0:p1]        \n","    \n","    def __iter__(self):\n","        self._counter = 0\n","        return self\n","    \n","    def __next__(self):\n","        if self._counter >= self._stop:\n","            raise StopIteration()\n","        p0 = self._counter*self.batch_size\n","        p1 = self._counter*self.batch_size + self.batch_size\n","        self._counter += 1\n","        return self.X[p0:p1], self.y[p0:p1]\n","    \n","# ハイパーパラメータの設定\n","learning_rate = 0.0008\n","batch_size = 20\n","num_epochs = 5\n","n_hidden1 = 400\n","n_hidden2 = 200\n","n_classes = 10\n","n_input = X_train.shape[1]\n","n_samples = X_train.shape[0]\n","\n","# 計算グラフに渡す引数の形を決める\n","X = tf.compat.v1.placeholder(\"float\", [None, n_input])\n","Y = tf.compat.v1.placeholder(\"float\", [None, n_classes])\n","\n","# trainのミニバッチイテレータ\n","get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n","\n","def example_net(x):\n","    \"\"\"\n","    単純な3層ニューラルネットワーク\n","    \"\"\"\n","    # 重みとバイアスの宣言\n","    he_initializer1 = tf.initializers.he_normal()\n","    he_initializer2 = tf.initializers.he_normal()\n","    he_initializer3 = tf.initializers.he_normal()\n","\n","\n","    weights = {\n","        'wa': tf.compat.v1.get_variable(name = \"WA\", shape=[n_input, n_hidden1], initializer=he_initializer1),\n","        'wb': tf.compat.v1.get_variable(name = \"WB\", shape=[n_hidden1, n_hidden2], initializer=he_initializer2),\n","        'wc': tf.compat.v1.get_variable(name = \"WC\", shape=[n_hidden2, n_classes], initializer=he_initializer3),\n","    }\n","\n","    biases = {\n","        'ba': tf.compat.v1.Variable(tf.compat.v1.random_normal([n_hidden1])),\n","        'bb': tf.compat.v1.Variable(tf.compat.v1.random_normal([n_hidden2])),\n","        'bc': tf.compat.v1.Variable(tf.compat.v1.random_normal([n_classes]))\n","    }\n","\n","    layer_1 = tf.add(tf.matmul(x, weights['wa']), biases['ba'])\n","    layer_1 = tf.nn.relu(layer_1)\n","    layer_2 = tf.add(tf.matmul(layer_1, weights['wb']), biases['bb'])\n","    layer_2 = tf.nn.relu(layer_2)\n","    layer_output = tf.matmul(layer_2, weights['wc']) + biases['bc'] # tf.addと+は等価である \n","    \n","    return layer_output\n","\n","# ネットワーク構造の読み込み 出力：logits                              \n","logits = example_net(X)\n","\n","# 目的関数\n","loss_op = tf.reduce_mean(tf.compat.v1.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=logits))\n","\n","# 最適化手法\n","optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n","train_op = optimizer.minimize(loss_op)\n","\n","y_pred = tf.nn.softmax(logits)\n","\n","# 推定結果\n","#                       Y:正解ラベル、              y_pred:推定ラベル\n","correct_pred = tf.equal(tf.argmax(Y, 1), tf.argmax(y_pred, 1))\n","\n","# 指標値計算\n","accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n","\n","# variableの初期化\n","init = tf.compat.v1.global_variables_initializer()\n","\n","print(\"Learning Start!\")\n","    \n","# 計算グラフの実行\n","with tf.compat.v1.Session() as sess:\n","    sess.run(init)\n","    train_loss_list = []\n","    val_loss_list = []\n","    train_acc_list = []\n","    val_acc_list = []\n","    for epoch in range(num_epochs):\n","        # エポックごとにループ\n","        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n","        total_loss = 0\n","        total_acc = 0\n","        total_val_loss = 0\n","        total_val_acc = 0\n","        \n","        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n","            # ミニバッチごとにループ\n","            _, loss, acc = sess.run([train_op, loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n","            val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})            \n","            total_loss += loss\n","            total_acc += acc\n","            total_val_loss += val_loss\n","            total_val_acc += val_acc            \n","            \n","        total_loss /= total_batch\n","        total_acc /= total_batch\n","        total_val_loss /= total_batch\n","        total_val_acc /= total_batch\n","        \n","        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch + 1, total_loss, total_val_loss, total_acc, total_val_acc))\n","        train_loss_list.append(total_loss)\n","        val_loss_list.append(total_val_loss)\n","        train_acc_list.append(total_acc)\n","        val_acc_list.append(total_val_acc)\n","        \n","    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n","    print(\"test_acc : {:.3f}\".format(test_acc))\n","    print(\"Learning Finish!\")"],"execution_count":205,"outputs":[{"output_type":"stream","text":["Learning Start!\n","Epoch 1, loss : 0.2317, val_loss : 0.2175, acc : 0.929, val_acc : 0.933\n","Epoch 2, loss : 0.0903, val_loss : 0.1047, acc : 0.972, val_acc : 0.967\n","Epoch 3, loss : 0.0556, val_loss : 0.0971, acc : 0.982, val_acc : 0.971\n","Epoch 4, loss : 0.0400, val_loss : 0.0981, acc : 0.987, val_acc : 0.973\n","Epoch 5, loss : 0.0285, val_loss : 0.0995, acc : 0.990, val_acc : 0.975\n","test_acc : 0.975\n","Learning Finish!\n"],"name":"stdout"}]}]}