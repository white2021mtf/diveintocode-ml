{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TensorFlow.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"156M87jnFvJDqPYP4DRsglEBznNjRy3M8","authorship_tag":"ABX9TyOnHBX0JNERcVZx8Qh1ESd6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"U0jBS86Xas6o"},"source":["Sprintの目的\n","フレームワークを用いたコードを読めるようになる\n","フレームワークを習得し続けられるようになる\n","理論を知っている範囲をフレームワークで動かす\n","\n","どのように学ぶか\n","TensorFlowのサンプルコードを元に、これまで扱ってきたデータセットを学習していきます。\n","\n","\n","\n","2.コードリーディング\n","\n","TensorFlowによって2値分類を行うサンプルコードを載せました。今回はこれをベースにして進めます。\n","\n","\n","tf.estimator などの高レベルAPIは使用していません。低レベルなところから見ていくことにします。\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3iEt6Q4HatEo"},"source":["【問題1】スクラッチを振り返る\n","ここまでのスクラッチを振り返り、ディープラーニングを実装するためにはどのようなものが必要だったかを列挙してください。\n","\n","\n","（例）\n","\n","\n","重みを初期化する必要があった\n","エポックのループが必要だった\n","\n","それらがフレームワークにおいてはどのように実装されるかを今回覚えていきましょう。\n","\n","\n","データセットの用意\n","以前から使用しているIrisデータセットを使用します。以下のサンプルコードではIris.csvが同じ階層にある想定です。\n","\n","\n","Iris Species\n","\n","\n","目的変数はSpeciesですが、3種類ある中から以下の2種類のみを取り出して使用します。\n","\n","\n","Iris-versicolor\n","Iris-virginica\n"]},{"cell_type":"markdown","metadata":{"id":"BJPLJuglatLm"},"source":["【問題１回答】\n","・重みを初期化する必要があった\n","\n","・エポックのループが必要だった\n","\n","・中間層の活性化関数が必要だった\n","\n","・全結合層が必要だった\n","\n","・最適化手法が必要だった\n","\n","・順伝播が必要だった\n","\n","・逆伝播が必要だった"]},{"cell_type":"markdown","metadata":{"id":"woEVJe5latQ-"},"source":["【問題2】スクラッチとTensorFlowの対応を考える\n","以下のサンプルコードを見て、先ほど列挙した「ディープラーニングを実装するために必要なもの」がTensorFlowではどう実装されているかを確認してください。\n","\n","\n","それを簡単に言葉でまとめてください。単純な一対一の対応であるとは限りません。\n","\n","\n","《サンプルコード》\n","\n","\n","＊TensorFlow バージョン 2.4 で動作を確認済みです。\n","\n","\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","76\n","77\n","78\n","79\n","80\n","81\n","82\n","83\n","84\n","85\n","86\n","87\n","88\n","89\n","90\n","91\n","92\n","93\n","94\n","95\n","96\n","97\n","98\n","99\n","100\n","101\n","102\n","103\n","104\n","105\n","106\n","107\n","108\n","109\n","110\n","111\n","112\n","113\n","114\n","115\n","116\n","117\n","118\n","119\n","120\n","121\n","122\n","123\n","124\n","125\n","126\n","127\n","128\n","129\n","130\n","131\n","132\n","133\n","134\n","135\n","136\n","137\n","138\n","139\n","140\n","141\n","142\n","143\n","144\n","145\n","146\n","147\n","148\n","\"\"\"\n","TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n","\"\"\"\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","# データセットの読み込み\n","dataset_path =\"Iris.csv\"\n","df = pd.read_csv(dataset_path)\n","# データフレームから条件抽出\n","df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n","y = df[\"Species\"]\n","X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n","y = np.array(y)\n","X = np.array(X).astype(np.float32)\n","# ラベルを数値に変換\n","y[y=='Iris-versicolor'] = 0\n","y[y=='Iris-virginica'] = 1\n","y = y.astype(np.float32)[:, np.newaxis]\n","# trainとtestに分割\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","# さらにtrainとvalに分割\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n","class GetMiniBatch:\n","    \"\"\"\n","    ミニバッチを取得するイテレータ\n","    Parameters\n","    ----------\n","    X : 次の形のndarray, shape (n_samples, n_features)\n","      訓練データ\n","    y : 次の形のndarray, shape (n_samples, 1)\n","      正解値\n","    batch_size : int\n","      バッチサイズ\n","    seed : int\n","      NumPyの乱数のシード\n","    \"\"\"\n","    def __init__(self, X, y, batch_size = 10, seed=0):\n","        self.batch_size = batch_size\n","        np.random.seed(seed)\n","        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n","        self.X = X[shuffle_index]\n","        self.y = y[shuffle_index]\n","        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n","    def __len__(self):\n","        return self._stop\n","    def __getitem__(self,item):\n","        p0 = item*self.batch_size\n","        p1 = item*self.batch_size + self.batch_size\n","        return self.X[p0:p1], self.y[p0:p1]        \n","    def __iter__(self):\n","        self._counter = 0\n","        return self\n","    def __next__(self):\n","        if self._counter >= self._stop:\n","            raise StopIteration()\n","        p0 = self._counter*self.batch_size\n","        p1 = self._counter*self.batch_size + self.batch_size\n","        self._counter += 1\n","        return self.X[p0:p1], self.y[p0:p1]\n","# ハイパーパラメータの設定\n","learning_rate = 0.01\n","batch_size = 10\n","num_epochs = 10\n","n_hidden1 = 50\n","n_hidden2 = 100\n","n_input = X_train.shape[1]\n","n_samples = X_train.shape[0]\n","n_classes = 1\n","# trainのミニバッチイテレータ\n","get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n","\n","class MyModel(tf.keras.Model):\n","    def __init__(self):\n","        super().__init__()\n","        # 重みとバイアスの宣言\n","        self.w1 = tf.Variable(tf.random.normal([n_input, n_hidden1]), trainable=True)\n","        self.w2 = tf.Variable(tf.random.normal([n_hidden1, n_hidden2]), trainable=True)\n","        self.w3 = tf.Variable(tf.random.normal([n_hidden2, n_classes]), trainable=True)\n","        self.b1 = tf.Variable(tf.random.normal([n_hidden1]), trainable=True)\n","        self.b2 = tf.Variable(tf.random.normal([n_hidden2]), trainable=True)\n","        self.b3 = tf.Variable(tf.random.normal([n_classes]), trainable=True)\n","    def call(self, x):\n","        \"\"\"\n","        単純な3層ニューラルネットワーク\n","        \"\"\"\n","        layer_1 = tf.add(tf.matmul(x, self.w1), self.b1)\n","        layer_1 = tf.nn.relu(layer_1)\n","        layer_2 = tf.add(tf.matmul(layer_1, self.w2), self.b2)\n","        layer_2 = tf.nn.relu(layer_2)\n","        layer_output = tf.matmul(layer_2, self.w3) + self.b3  # tf.addと+は等価である\n","        return layer_output\n","model = MyModel()\n","\n","# # 最適化手法\n","optimizer = tf.keras.optimizers.Adam(learning_rate)\n","\n","def train(x, y):\n","    logits = model(x, training=True)\n","    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(y, logits))\n","    return loss\n","\n","def evaluate(x, y):\n","    logits = model(x)\n","    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(y, logits))\n","    # 推定結果\n","    correct_pred = tf.equal(tf.sign(y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n","    # 指標値計算\n","    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n","    return loss, accuracy\n","\n","# 計算グラフの実行\n","for epoch in range(num_epochs):\n","    # エポックごとにループ\n","    total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n","    total_loss = 0\n","    total_acc = 0\n","    for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n","        # ミニバッチごとにループ\n","        with tf.GradientTape() as tape:\n","            loss = train(mini_batch_x, mini_batch_y)\n","        grads = tape.gradient(loss, model.trainable_weights)\n","        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n","        total_loss += loss\n","    loss = total_loss / n_samples\n","    val_loss, val_acc = evaluate(X_val, y_val)\n","    print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, val_acc))\n","_, test_acc = evaluate(X_test, y_test)\n","print(\"test_acc : {:.3f}\".format(test_acc))\n","\n"]},{"cell_type":"markdown","metadata":{"id":"B76q3opEhWNY"},"source":["【問題２回答】\n","\n","・重みを初期化する必要があった\n","\n","⇨SimpleInitializerというクラスで、初期化してたが、\n","tf.Variableを使用して、重みとバイアスを初期化してる\n","\n","・エポックのループが必要だった\n","\n","⇨テンソルフローでも使用してるが、\n","DNNでは、順伝播と逆伝播使用してたが、\n","それがない。（AとZと　dAとdZの計算がない）\n","⇨fit内でエポック使用してたが、fitがない\n","\n","・中間層の活性化関数が必要だった\n","\n","⇨tf.nn.reluになった\n","\n","・全結合層が必要だった\n","\n","⇨⇨全結合層FCクラス使用してない\n","\n","・最適化手法が必要だった\n","\n","tf.keras.optimizers.を使用している\n","\n","・全結合層に書いた順伝播が必要だった\n","\n","⇨使用してない\n","\n","・全結合層に書いた逆伝播が必要だった\n","\n","⇨使用してない\n","\n","\n","・ディープラーニングでも一般的に使われる最適化アルゴリズムに「最急降下法」があります。本来であればアルゴリズムの処理をスクラッチでコーディングしなくてはいけません。しかし、TensorFlowを使うことで、容易に最急降下法の処理を組み込むことが可能になります。"]},{"cell_type":"markdown","metadata":{"id":"Q3E1aSNzatXK"},"source":["3.他のデータセットへの適用\n","\n","これまで扱ってきた小さなデータセットが他にもいくつかあります。上記サンプルコードを書き換え、これらに対して学習・推定を行うニューラルネットワークを作成してください。\n","\n","\n","Iris（3種類すべての目的変数を使用）\n","House Prices\n","\n","どのデータセットも train, val, test の3種類に分けて使用してください。\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tasMy2O2ateP"},"source":["【問題3】3種類すべての目的変数を使用したIrisのモデルを作成\n","Irisデータセットのtrain.csvの中で、目的変数Speciesに含まれる3種類すべてを分類できるモデルを作成してください。\n","\n","\n","Iris Species\n","\n","\n","2クラスの分類と3クラス以上の分類の違いを考慮してください。それがTensorFlowでどのように書き換えられるかを公式ドキュメントなどを参考に調べてください。\n","\n","\n","《ヒント》\n","\n","\n","以下の2箇所は2クラス分類特有の処理です。\n","\n","\n","1\n","loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits))\n","\n","1\n","correct_pred = tf.equal(tf.sign(Y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n","\n","メソッドは以下のように公式ドキュメントを確認してください。\n","\n","\n","tf.nn.sigmoid_cross_entropy_with_logits  |  TensorFlow\n","\n","\n","tf.math.sign  |  TensorFlow\n","\n","\n","＊tf.signとtf.math.signは同じ働きをします。"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"df5piUrdau7h","executionInfo":{"status":"ok","timestamp":1629935331035,"user_tz":-540,"elapsed":2739,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"f9073a33-f970-4c57-caed-0acad8761b2d"},"source":["\n","#scikit-learnからデータの取り出し\n","from sklearn import datasets\n","iris = datasets.load_iris()\n"," \n","#アヤメの分類に使用するデータの確認\n","print(iris.DESCR)\n","iris.data\n","iris.target\n"," \n","#アヤメの分類の学習\n","from sklearn.model_selection import train_test_split as split\n","x_train, x_test, y_train, y_test = split(iris.data,iris.target,train_size=0.8,test_size=0.2)\n","import tensorflow as tf\n","import keras\n","from keras.layers import Dense,Activation\n"," \n","#ニュートラルネットワークで使用するモデル作成\n","model = keras.models.Sequential()\n","model.add(Dense(units=32,input_dim=4))\n","model.add(Activation('relu'))\n","model.add(Dense(units=3))\n","model.add(Activation('softmax'))\n","model.compile(loss='sparse_categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n"," \n","#教師あり学習の実行\n","model.fit(x_train,y_train,epochs=100)\n"," \n","#評価の実行\n","score = model.evaluate(x_test,y_test,batch_size = 1)\n","print(score[1])\n"," \n","#1つのデータに対する評価の実行方法\n","import numpy as np\n","x = np.array([[5.1,3.5,1.4,0.2]])\n","r = model.predict(x)\n","print(r)\n","r.argmax()"],"execution_count":11,"outputs":[{"output_type":"stream","text":[".. _iris_dataset:\n","\n","Iris plants dataset\n","--------------------\n","\n","**Data Set Characteristics:**\n","\n","    :Number of Instances: 150 (50 in each of three classes)\n","    :Number of Attributes: 4 numeric, predictive attributes and the class\n","    :Attribute Information:\n","        - sepal length in cm\n","        - sepal width in cm\n","        - petal length in cm\n","        - petal width in cm\n","        - class:\n","                - Iris-Setosa\n","                - Iris-Versicolour\n","                - Iris-Virginica\n","                \n","    :Summary Statistics:\n","\n","    ============== ==== ==== ======= ===== ====================\n","                    Min  Max   Mean    SD   Class Correlation\n","    ============== ==== ==== ======= ===== ====================\n","    sepal length:   4.3  7.9   5.84   0.83    0.7826\n","    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n","    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n","    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n","    ============== ==== ==== ======= ===== ====================\n","\n","    :Missing Attribute Values: None\n","    :Class Distribution: 33.3% for each of 3 classes.\n","    :Creator: R.A. Fisher\n","    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n","    :Date: July, 1988\n","\n","The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n","from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n","Machine Learning Repository, which has two wrong data points.\n","\n","This is perhaps the best known database to be found in the\n","pattern recognition literature.  Fisher's paper is a classic in the field and\n","is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n","data set contains 3 classes of 50 instances each, where each class refers to a\n","type of iris plant.  One class is linearly separable from the other 2; the\n","latter are NOT linearly separable from each other.\n","\n",".. topic:: References\n","\n","   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n","     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n","     Mathematical Statistics\" (John Wiley, NY, 1950).\n","   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n","     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n","   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n","     Structure and Classification Rule for Recognition in Partially Exposed\n","     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n","     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n","   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n","     on Information Theory, May 1972, 431-433.\n","   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n","     conceptual clustering system finds 3 classes in the data.\n","   - Many, many more ...\n","Epoch 1/100\n","4/4 [==============================] - 0s 3ms/step - loss: 1.4356 - accuracy: 0.3250\n","Epoch 2/100\n","4/4 [==============================] - 0s 2ms/step - loss: 1.2431 - accuracy: 0.3583\n","Epoch 3/100\n","4/4 [==============================] - 0s 8ms/step - loss: 1.1750 - accuracy: 0.3583\n","Epoch 4/100\n","4/4 [==============================] - 0s 3ms/step - loss: 1.1276 - accuracy: 0.3583\n","Epoch 5/100\n","4/4 [==============================] - 0s 3ms/step - loss: 1.0915 - accuracy: 0.3583\n","Epoch 6/100\n","4/4 [==============================] - 0s 3ms/step - loss: 1.0460 - accuracy: 0.3583\n","Epoch 7/100\n","4/4 [==============================] - 0s 4ms/step - loss: 1.0006 - accuracy: 0.3667\n","Epoch 8/100\n","4/4 [==============================] - 0s 5ms/step - loss: 0.9722 - accuracy: 0.3667\n","Epoch 9/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.9572 - accuracy: 0.4583\n","Epoch 10/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.9391 - accuracy: 0.4500\n","Epoch 11/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.9207 - accuracy: 0.5333\n","Epoch 12/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.9063 - accuracy: 0.5417\n","Epoch 13/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.8849 - accuracy: 0.6167\n","Epoch 14/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.8678 - accuracy: 0.6333\n","Epoch 15/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.8547 - accuracy: 0.6750\n","Epoch 16/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.8412 - accuracy: 0.7250\n","Epoch 17/100\n","4/4 [==============================] - 0s 5ms/step - loss: 0.8274 - accuracy: 0.7083\n","Epoch 18/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.8078 - accuracy: 0.7917\n","Epoch 19/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.7940 - accuracy: 0.7417\n","Epoch 20/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.7787 - accuracy: 0.8083\n","Epoch 21/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.7699 - accuracy: 0.7833\n","Epoch 22/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.7564 - accuracy: 0.7000\n","Epoch 23/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.7397 - accuracy: 0.7917\n","Epoch 24/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.7325 - accuracy: 0.7750\n","Epoch 25/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.7173 - accuracy: 0.7917\n","Epoch 26/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.7253 - accuracy: 0.7083\n","Epoch 27/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.6904 - accuracy: 0.8250\n","Epoch 28/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.6818 - accuracy: 0.7917\n","Epoch 29/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.6741 - accuracy: 0.7917\n","Epoch 30/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.6578 - accuracy: 0.7917\n","Epoch 31/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.6515 - accuracy: 0.8417\n","Epoch 32/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.6394 - accuracy: 0.7833\n","Epoch 33/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.6387 - accuracy: 0.7167\n","Epoch 34/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.6206 - accuracy: 0.8417\n","Epoch 35/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.6175 - accuracy: 0.8083\n","Epoch 36/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.6058 - accuracy: 0.8000\n","Epoch 37/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.5977 - accuracy: 0.8167\n","Epoch 38/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.5859 - accuracy: 0.8333\n","Epoch 39/100\n","4/4 [==============================] - 0s 5ms/step - loss: 0.5790 - accuracy: 0.7917\n","Epoch 40/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.5730 - accuracy: 0.8333\n","Epoch 41/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.5613 - accuracy: 0.8500\n","Epoch 42/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.5543 - accuracy: 0.8250\n","Epoch 43/100\n","4/4 [==============================] - 0s 5ms/step - loss: 0.5467 - accuracy: 0.8417\n","Epoch 44/100\n","4/4 [==============================] - 0s 5ms/step - loss: 0.5404 - accuracy: 0.8500\n","Epoch 45/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.9250\n","Epoch 46/100\n","4/4 [==============================] - 0s 5ms/step - loss: 0.5354 - accuracy: 0.8667\n","Epoch 47/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7417\n","Epoch 48/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.5248 - accuracy: 0.8917\n","Epoch 49/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.5132 - accuracy: 0.8833\n","Epoch 50/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.8333\n","Epoch 51/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.8583\n","Epoch 52/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.8750\n","Epoch 53/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.9167\n","Epoch 54/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.8833\n","Epoch 55/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.8750\n","Epoch 56/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.8750\n","Epoch 57/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.9250\n","Epoch 58/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.8750\n","Epoch 59/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.8667\n","Epoch 60/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.8917\n","Epoch 61/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.9167\n","Epoch 62/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.8250\n","Epoch 63/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.8833\n","Epoch 64/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.9667\n","Epoch 65/100\n","4/4 [==============================] - 0s 5ms/step - loss: 0.4387 - accuracy: 0.8333\n","Epoch 66/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.8833\n","Epoch 67/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.9417\n","Epoch 68/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.9250\n","Epoch 69/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.8833\n","Epoch 70/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.9250\n","Epoch 71/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.9167\n","Epoch 72/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4133 - accuracy: 0.9000\n","Epoch 73/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.9000\n","Epoch 74/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.9500\n","Epoch 75/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.9000\n","Epoch 76/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.9000\n","Epoch 77/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.9417\n","Epoch 78/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3990 - accuracy: 0.8917\n","Epoch 79/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.8833\n","Epoch 80/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.9250\n","Epoch 81/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3877 - accuracy: 0.9667\n","Epoch 82/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.8917\n","Epoch 83/100\n","4/4 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.9417\n","Epoch 84/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.9417\n","Epoch 85/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3773 - accuracy: 0.8917\n","Epoch 86/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3819 - accuracy: 0.9333\n","Epoch 87/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3719 - accuracy: 0.9500\n","Epoch 88/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3707 - accuracy: 0.9333\n","Epoch 89/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3744 - accuracy: 0.9333\n","Epoch 90/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3688 - accuracy: 0.9167\n","Epoch 91/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3629 - accuracy: 0.9333\n","Epoch 92/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3637 - accuracy: 0.9083\n","Epoch 93/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3598 - accuracy: 0.9667\n","Epoch 94/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.9333\n","Epoch 95/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3548 - accuracy: 0.9417\n","Epoch 96/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3553 - accuracy: 0.9667\n","Epoch 97/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.9333\n","Epoch 98/100\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3498 - accuracy: 0.9333\n","Epoch 99/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.3459 - accuracy: 0.9583\n","Epoch 100/100\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.9500\n","30/30 [==============================] - 0s 1ms/step - loss: 0.3401 - accuracy: 1.0000\n","1.0\n","[[0.9293033  0.06758482 0.00311188]]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"oIgQcPCHaz5T"},"source":["【問題4】House Pricesのモデルを作成\n","回帰問題のデータセットであるHouse Pricesを使用したモデルを作成してください。\n","\n","\n","House Prices: Advanced Regression Techniques\n","\n","\n","この中のtrain.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使ってください。説明変数はさらに増やしても構いません。\n","\n","\n","分類問題と回帰問題の違いを考慮してください。"]},{"cell_type":"code","metadata":{"id":"ITFgq4CVa0Mt","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1629935895830,"user_tz":-540,"elapsed":562,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"a974e8f0-e276-4150-8b50-5352b7b60a2e"},"source":["\n","# #House Pricesのモデルを作成\n","# import pandas as pd\n","# # import os\n","# # os.listdir()\n","# # print(os.listdir())\n","\n","\n","# #House Pricesのモデルの学習\n","# from sklearn.model_selection import train_test_split as split\n","# import tensorflow as tf\n","# import keras\n","# from keras.layers import Dense,Activation\n","# from sklearn.preprocessing import StandardScaler\n","\n","# df = pd.read_csv('/content/drive/MyDrive/DIC/train.csv')\n","# # print(df)\n","# x=df.loc[:,['GrLivArea','YearBuilt']]\n","# # print(type(x))\n","# # print(x)\n","\n","# target = df.loc[:, ['SalePrice']]\n","# # print(target[:])\n","# # print(type(target))\n","\n","# X=x\n","# #print(df.sample(n=3))\n","# X = X.sample(n=32)#サンプル数を5００へ絞り込み\n","# # X=X.values\n","\n","# # X=X.tolist()\n","# # scaler = StandardScaler()\n","# # scaler.fit(X)\n","# # X=scaler.transform(X)\n","\n","# # 目的変数\n","# # Y = boston.target\n","# Y = target\n","# Y = Y.sample(n=32)#サンプル数を5００へ絞り込み\n","# # Y=Y.values\n","\n","# x_train, x_test, y_train, y_test = split(X,Y,train_size=0.8,test_size=0.2)\n","\n","# #ニュートラルネットワークで使用するモデル作成\n","# model = keras.models.Sequential()\n","# model.add(Dense(units=4,input_dim=2))\n","# model.add(Activation('relu'))\n","# model.add(Dense(units=4))\n","# model.add(Activation('softmax'))\n","# model.compile(loss='sparse_categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n","\n","# #教師あり学習の実行\n","# model.fit(x_train,y_train,epochs=5)\n","\n","# #評価の実行\n","# score = model.evaluate(x_test,y_test,batch_size = 1)\n","# print(score[1])\n","\n","# #1つのデータに対する評価の実行方法\n","# import numpy as np\n","# x = np.array([[5.1,3.5,1.4,0.2]])\n","# r = model.predict(x)\n","# print(r)\n","# r.argmax()\n","\n"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n"],"name":"stdout"},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-92456d19a418>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m#教師あり学習の実行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m#評価の実行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m:  Received a label value of 395192 which is outside the valid range of [0, 4).  Label values: 167000 133500 123000 174000 123000 79900 395192 130000 136500 105000 335000 310000 92900 208900 224000 144000 232600 52500 37900 302000 392000 150000 193000 367294 115000\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-23-92456d19a418>:53) ]] [Op:__inference_train_function_8217]\n\nFunction call stack:\ntrain_function\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rWXRFe0v4W8K","executionInfo":{"status":"ok","timestamp":1629941811358,"user_tz":-540,"elapsed":225,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"f23bbb05-2148-4257-a11c-d6c2e39cad8b"},"source":["# テンソルフロー\n","import tensorflow as tf\n","# 計算やデータ処理のライブラリ\n","import numpy as np\n","import pandas as pd\n","# データ可視化のライブラリ\n","import matplotlib.pyplot as plt\n","# データセットの取得&処理のライブラリ\n","from sklearn.datasets import load_boston\n","from sklearn.model_selection import train_test_split\n","# インポートの確認\n","print(tf.__version__)\n","print(np.__version__)\n","print(pd.__version__)\n"],"execution_count":57,"outputs":[{"output_type":"stream","text":["2.6.0\n","1.19.5\n","1.1.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"id":"D5L-BVqv4gfQ","executionInfo":{"status":"ok","timestamp":1629942326033,"user_tz":-540,"elapsed":555,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"ebe2a48f-1b5a-4b98-f1e7-9ff2a94d4dc4"},"source":["# # データの読み込み\n","# boston = load_boston()\n","# # Pandasのデータフレーム形式へ変換\n","# df = pd.DataFrame(boston.data, columns=boston.feature_names)\n","# df['target'] = boston.target\n","# # データの最初の5行を表示\n","# df.head()\n","\n","\n","# データの読み込み\n","df = pd.read_csv('/content/drive/MyDrive/DIC/train.csv')\n","# print(df)\n","df.head()\n"],"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>MSSubClass</th>\n","      <th>MSZoning</th>\n","      <th>LotFrontage</th>\n","      <th>LotArea</th>\n","      <th>Street</th>\n","      <th>Alley</th>\n","      <th>LotShape</th>\n","      <th>LandContour</th>\n","      <th>Utilities</th>\n","      <th>LotConfig</th>\n","      <th>LandSlope</th>\n","      <th>Neighborhood</th>\n","      <th>Condition1</th>\n","      <th>Condition2</th>\n","      <th>BldgType</th>\n","      <th>HouseStyle</th>\n","      <th>OverallQual</th>\n","      <th>OverallCond</th>\n","      <th>YearBuilt</th>\n","      <th>YearRemodAdd</th>\n","      <th>RoofStyle</th>\n","      <th>RoofMatl</th>\n","      <th>Exterior1st</th>\n","      <th>Exterior2nd</th>\n","      <th>MasVnrType</th>\n","      <th>MasVnrArea</th>\n","      <th>ExterQual</th>\n","      <th>ExterCond</th>\n","      <th>Foundation</th>\n","      <th>BsmtQual</th>\n","      <th>BsmtCond</th>\n","      <th>BsmtExposure</th>\n","      <th>BsmtFinType1</th>\n","      <th>BsmtFinSF1</th>\n","      <th>BsmtFinType2</th>\n","      <th>BsmtFinSF2</th>\n","      <th>BsmtUnfSF</th>\n","      <th>TotalBsmtSF</th>\n","      <th>Heating</th>\n","      <th>...</th>\n","      <th>CentralAir</th>\n","      <th>Electrical</th>\n","      <th>1stFlrSF</th>\n","      <th>2ndFlrSF</th>\n","      <th>LowQualFinSF</th>\n","      <th>GrLivArea</th>\n","      <th>BsmtFullBath</th>\n","      <th>BsmtHalfBath</th>\n","      <th>FullBath</th>\n","      <th>HalfBath</th>\n","      <th>BedroomAbvGr</th>\n","      <th>KitchenAbvGr</th>\n","      <th>KitchenQual</th>\n","      <th>TotRmsAbvGrd</th>\n","      <th>Functional</th>\n","      <th>Fireplaces</th>\n","      <th>FireplaceQu</th>\n","      <th>GarageType</th>\n","      <th>GarageYrBlt</th>\n","      <th>GarageFinish</th>\n","      <th>GarageCars</th>\n","      <th>GarageArea</th>\n","      <th>GarageQual</th>\n","      <th>GarageCond</th>\n","      <th>PavedDrive</th>\n","      <th>WoodDeckSF</th>\n","      <th>OpenPorchSF</th>\n","      <th>EnclosedPorch</th>\n","      <th>3SsnPorch</th>\n","      <th>ScreenPorch</th>\n","      <th>PoolArea</th>\n","      <th>PoolQC</th>\n","      <th>Fence</th>\n","      <th>MiscFeature</th>\n","      <th>MiscVal</th>\n","      <th>MoSold</th>\n","      <th>YrSold</th>\n","      <th>SaleType</th>\n","      <th>SaleCondition</th>\n","      <th>SalePrice</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>60</td>\n","      <td>RL</td>\n","      <td>65.0</td>\n","      <td>8450</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>Inside</td>\n","      <td>Gtl</td>\n","      <td>CollgCr</td>\n","      <td>Norm</td>\n","      <td>Norm</td>\n","      <td>1Fam</td>\n","      <td>2Story</td>\n","      <td>7</td>\n","      <td>5</td>\n","      <td>2003</td>\n","      <td>2003</td>\n","      <td>Gable</td>\n","      <td>CompShg</td>\n","      <td>VinylSd</td>\n","      <td>VinylSd</td>\n","      <td>BrkFace</td>\n","      <td>196.0</td>\n","      <td>Gd</td>\n","      <td>TA</td>\n","      <td>PConc</td>\n","      <td>Gd</td>\n","      <td>TA</td>\n","      <td>No</td>\n","      <td>GLQ</td>\n","      <td>706</td>\n","      <td>Unf</td>\n","      <td>0</td>\n","      <td>150</td>\n","      <td>856</td>\n","      <td>GasA</td>\n","      <td>...</td>\n","      <td>Y</td>\n","      <td>SBrkr</td>\n","      <td>856</td>\n","      <td>854</td>\n","      <td>0</td>\n","      <td>1710</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>Gd</td>\n","      <td>8</td>\n","      <td>Typ</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>Attchd</td>\n","      <td>2003.0</td>\n","      <td>RFn</td>\n","      <td>2</td>\n","      <td>548</td>\n","      <td>TA</td>\n","      <td>TA</td>\n","      <td>Y</td>\n","      <td>0</td>\n","      <td>61</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2008</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>208500</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>20</td>\n","      <td>RL</td>\n","      <td>80.0</td>\n","      <td>9600</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>FR2</td>\n","      <td>Gtl</td>\n","      <td>Veenker</td>\n","      <td>Feedr</td>\n","      <td>Norm</td>\n","      <td>1Fam</td>\n","      <td>1Story</td>\n","      <td>6</td>\n","      <td>8</td>\n","      <td>1976</td>\n","      <td>1976</td>\n","      <td>Gable</td>\n","      <td>CompShg</td>\n","      <td>MetalSd</td>\n","      <td>MetalSd</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>TA</td>\n","      <td>TA</td>\n","      <td>CBlock</td>\n","      <td>Gd</td>\n","      <td>TA</td>\n","      <td>Gd</td>\n","      <td>ALQ</td>\n","      <td>978</td>\n","      <td>Unf</td>\n","      <td>0</td>\n","      <td>284</td>\n","      <td>1262</td>\n","      <td>GasA</td>\n","      <td>...</td>\n","      <td>Y</td>\n","      <td>SBrkr</td>\n","      <td>1262</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1262</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>TA</td>\n","      <td>6</td>\n","      <td>Typ</td>\n","      <td>1</td>\n","      <td>TA</td>\n","      <td>Attchd</td>\n","      <td>1976.0</td>\n","      <td>RFn</td>\n","      <td>2</td>\n","      <td>460</td>\n","      <td>TA</td>\n","      <td>TA</td>\n","      <td>Y</td>\n","      <td>298</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2007</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>181500</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>60</td>\n","      <td>RL</td>\n","      <td>68.0</td>\n","      <td>11250</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>IR1</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>Inside</td>\n","      <td>Gtl</td>\n","      <td>CollgCr</td>\n","      <td>Norm</td>\n","      <td>Norm</td>\n","      <td>1Fam</td>\n","      <td>2Story</td>\n","      <td>7</td>\n","      <td>5</td>\n","      <td>2001</td>\n","      <td>2002</td>\n","      <td>Gable</td>\n","      <td>CompShg</td>\n","      <td>VinylSd</td>\n","      <td>VinylSd</td>\n","      <td>BrkFace</td>\n","      <td>162.0</td>\n","      <td>Gd</td>\n","      <td>TA</td>\n","      <td>PConc</td>\n","      <td>Gd</td>\n","      <td>TA</td>\n","      <td>Mn</td>\n","      <td>GLQ</td>\n","      <td>486</td>\n","      <td>Unf</td>\n","      <td>0</td>\n","      <td>434</td>\n","      <td>920</td>\n","      <td>GasA</td>\n","      <td>...</td>\n","      <td>Y</td>\n","      <td>SBrkr</td>\n","      <td>920</td>\n","      <td>866</td>\n","      <td>0</td>\n","      <td>1786</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>Gd</td>\n","      <td>6</td>\n","      <td>Typ</td>\n","      <td>1</td>\n","      <td>TA</td>\n","      <td>Attchd</td>\n","      <td>2001.0</td>\n","      <td>RFn</td>\n","      <td>2</td>\n","      <td>608</td>\n","      <td>TA</td>\n","      <td>TA</td>\n","      <td>Y</td>\n","      <td>0</td>\n","      <td>42</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>2008</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>223500</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>70</td>\n","      <td>RL</td>\n","      <td>60.0</td>\n","      <td>9550</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>IR1</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>Corner</td>\n","      <td>Gtl</td>\n","      <td>Crawfor</td>\n","      <td>Norm</td>\n","      <td>Norm</td>\n","      <td>1Fam</td>\n","      <td>2Story</td>\n","      <td>7</td>\n","      <td>5</td>\n","      <td>1915</td>\n","      <td>1970</td>\n","      <td>Gable</td>\n","      <td>CompShg</td>\n","      <td>Wd Sdng</td>\n","      <td>Wd Shng</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>TA</td>\n","      <td>TA</td>\n","      <td>BrkTil</td>\n","      <td>TA</td>\n","      <td>Gd</td>\n","      <td>No</td>\n","      <td>ALQ</td>\n","      <td>216</td>\n","      <td>Unf</td>\n","      <td>0</td>\n","      <td>540</td>\n","      <td>756</td>\n","      <td>GasA</td>\n","      <td>...</td>\n","      <td>Y</td>\n","      <td>SBrkr</td>\n","      <td>961</td>\n","      <td>756</td>\n","      <td>0</td>\n","      <td>1717</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>Gd</td>\n","      <td>7</td>\n","      <td>Typ</td>\n","      <td>1</td>\n","      <td>Gd</td>\n","      <td>Detchd</td>\n","      <td>1998.0</td>\n","      <td>Unf</td>\n","      <td>3</td>\n","      <td>642</td>\n","      <td>TA</td>\n","      <td>TA</td>\n","      <td>Y</td>\n","      <td>0</td>\n","      <td>35</td>\n","      <td>272</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2006</td>\n","      <td>WD</td>\n","      <td>Abnorml</td>\n","      <td>140000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>60</td>\n","      <td>RL</td>\n","      <td>84.0</td>\n","      <td>14260</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>IR1</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>FR2</td>\n","      <td>Gtl</td>\n","      <td>NoRidge</td>\n","      <td>Norm</td>\n","      <td>Norm</td>\n","      <td>1Fam</td>\n","      <td>2Story</td>\n","      <td>8</td>\n","      <td>5</td>\n","      <td>2000</td>\n","      <td>2000</td>\n","      <td>Gable</td>\n","      <td>CompShg</td>\n","      <td>VinylSd</td>\n","      <td>VinylSd</td>\n","      <td>BrkFace</td>\n","      <td>350.0</td>\n","      <td>Gd</td>\n","      <td>TA</td>\n","      <td>PConc</td>\n","      <td>Gd</td>\n","      <td>TA</td>\n","      <td>Av</td>\n","      <td>GLQ</td>\n","      <td>655</td>\n","      <td>Unf</td>\n","      <td>0</td>\n","      <td>490</td>\n","      <td>1145</td>\n","      <td>GasA</td>\n","      <td>...</td>\n","      <td>Y</td>\n","      <td>SBrkr</td>\n","      <td>1145</td>\n","      <td>1053</td>\n","      <td>0</td>\n","      <td>2198</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>Gd</td>\n","      <td>9</td>\n","      <td>Typ</td>\n","      <td>1</td>\n","      <td>TA</td>\n","      <td>Attchd</td>\n","      <td>2000.0</td>\n","      <td>RFn</td>\n","      <td>3</td>\n","      <td>836</td>\n","      <td>TA</td>\n","      <td>TA</td>\n","      <td>Y</td>\n","      <td>192</td>\n","      <td>84</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>2008</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>250000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 81 columns</p>\n","</div>"],"text/plain":["   Id  MSSubClass MSZoning  ...  SaleType  SaleCondition SalePrice\n","0   1          60       RL  ...        WD         Normal    208500\n","1   2          20       RL  ...        WD         Normal    181500\n","2   3          60       RL  ...        WD         Normal    223500\n","3   4          70       RL  ...        WD        Abnorml    140000\n","4   5          60       RL  ...        WD         Normal    250000\n","\n","[5 rows x 81 columns]"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SqlmuTRc4vJB","executionInfo":{"status":"ok","timestamp":1629942423183,"user_tz":-540,"elapsed":221,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"50663084-77c8-4896-b440-358a879e0426"},"source":["# # 特徴量とターゲットに切り分け\n","# X_data = np.array(boston.data)\n","# y_data = np.array(boston.target)\n","# # １行目のデータの特徴量（X)とターゲット（y）を確認\n","# print(X_data[0:1])\n","# print(y_data[0:1])\n","\n","\n","\n","x=df.loc[:,['GrLivArea','YearBuilt']]\n","X_data = np.array(x)\n","print(X_data[0:1])\n","# print(type(x))\n","# print(x)\n","\n","target = df.loc[:, ['SalePrice']]\n","y_data = np.array(target)\n","print(y_data[0:1])\n","# print(target[:])\n","# print(type(target))\n","\n","# X=x\n","# #print(df.sample(n=3))\n","# X = X.sample(n=32)#サンプル数を5００へ絞り込み\n","# # X=X.values\n","\n","# # X=X.tolist()\n","# # scaler = StandardScaler()\n","# # scaler.fit(X)\n","# # X=scaler.transform(X)\n","\n","# # 目的変数\n","# # Y = boston.target\n","# Y = target\n","# Y = Y.sample(n=32)#サンプル数を5００へ絞り込み\n","# # Y=Y.values"],"execution_count":59,"outputs":[{"output_type":"stream","text":["[[1710 2003]]\n","[[208500]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QnjeVoHj42-M","executionInfo":{"status":"ok","timestamp":1629942429120,"user_tz":-540,"elapsed":216,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"09ac1752-75f5-4302-c7f5-94c928d345c7"},"source":["# 正規化\n","def norm(data):\n","  mean = np.mean(data, axis=0)\n","  std = np.std(data, axis=0)\n","  return (data - mean) / std\n","# データを変更\n","X_data = norm(X_data)\n","print(X_data[0:1])\n"],"execution_count":60,"outputs":[{"output_type":"stream","text":["[[0.37033344 1.05099379]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oU-rmGt45Cdp","executionInfo":{"status":"ok","timestamp":1629942512386,"user_tz":-540,"elapsed":205,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"d3e68c4a-f9a1-4d7f-a75a-66bf03fbea1e"},"source":["# 1を追加する前のサイズ\n","print(X_data.shape)\n","# 1を作成\n","# ones = np.ones((506, 1))\n","ones = np.ones((1460, 1))\n","# 1を追加\n","X_data = np.c_[ones, X_data]\n","X_data.shape\n"],"execution_count":64,"outputs":[{"output_type":"stream","text":["(1460, 3)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(1460, 4)"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6MtqrVsE5Sgr","executionInfo":{"status":"ok","timestamp":1629942556042,"user_tz":-540,"elapsed":247,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"4cd917e7-1d30-44d8-91eb-555192dc0a62"},"source":["# 訓練データとテストデータへ切り分け\n","X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n","# y_train = y_train.reshape(404,1)\n","y_train = y_train.reshape(1168,1)\n","# y_test = y_test.reshape(102,1)\n","y_test = y_test.reshape(292,1)\n","print(X_train.shape)\n","print(y_train.shape)\n","print(X_test.shape)\n","print(y_test.shape)\n"],"execution_count":66,"outputs":[{"output_type":"stream","text":["(1168, 4)\n","(1168, 1)\n","(292, 4)\n","(292, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZZRvblWR5XY9","executionInfo":{"status":"ok","timestamp":1629942581795,"user_tz":-540,"elapsed":211,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}}},"source":["# 学習率とエポック（反復処理回数）\n","learning_rate = 0.01\n","training_epochs = 101\n","# 特徴量の数\n","n_dim = X_data.shape[1]\n","tf.compat.v1.disable_eager_execution()\n","# 特徴量（X)とターゲット（y）のプレースホルダー\n","# X = tf.placeholder(tf.float32,[None,n_dim])\n","# Y = tf.placeholder(tf.float32,[None,1])\n","X = tf.compat.v1.placeholder(tf.float32,[None,n_dim])\n","Y = tf.compat.v1.placeholder(tf.float32,[None,1])\n","# 係数（W）と定数項（b）の変数\n","W = tf.Variable(tf.ones([n_dim,1]))\n","b = tf.Variable(0.0)\n"],"execution_count":70,"outputs":[]},{"cell_type":"code","metadata":{"id":"AL5Q8f1z8o5e","executionInfo":{"status":"ok","timestamp":1629942588555,"user_tz":-540,"elapsed":209,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}}},"source":["# 線形モデル\n","y = tf.add(b, tf.matmul(X, W))\n","# コスト関数\n","cost = tf.reduce_mean(tf.square(y - Y))\n","# 最適化\n","# training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n","# training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n","opt = tf.compat.v1.train.GradientDescentOptimizer(learning_rate)\n","training_step = opt.minimize(cost)"],"execution_count":71,"outputs":[]},{"cell_type":"code","metadata":{"id":"T3GgNEvP_aRf","executionInfo":{"status":"ok","timestamp":1629942594932,"user_tz":-540,"elapsed":574,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}}},"source":["# 初期化\n","# init = tf.global_variables_initializer()\n","init = tf.compat.v1.global_variables_initializer()\n","cost_history = []\n","# モデル訓練開始\n","# sess = tf.Session()\n","sess = tf.compat.v1.Session()\n","sess.run(init)\n","for epoch in range(training_epochs):\n","  sess.run(training_step, feed_dict={X:X_train, Y:y_train})\n","  cost_history = np.append(cost_history, sess.run(cost, feed_dict={X:X_train, Y:y_train}))\n","  if epoch % 100 == 0:\n","    W_val = sess.run(W)\n","    b_val = sess.run(b)\n"],"execution_count":72,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aN0tBkV8ElP1","executionInfo":{"status":"ok","timestamp":1629942598599,"user_tz":-540,"elapsed":228,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"ed5cfa30-dfe7-4c15-9043-a3a418abd353"},"source":["# 誤差（cost）を確認\n","print(cost_history[1])\n","print(cost_history[50])\n","print(cost_history[100])\n"],"execution_count":73,"outputs":[{"output_type":"stream","text":["31296008192.0\n","2499912960.0\n","2140208640.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1PwZJoRsElXD","executionInfo":{"status":"ok","timestamp":1629942604174,"user_tz":-540,"elapsed":218,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}}},"source":["# テストデータを使って予測\n","pred_test = sess.run(y, feed_dict={X: X_test})\n"],"execution_count":74,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"-kAY9WE-Eled","executionInfo":{"status":"ok","timestamp":1629942608113,"user_tz":-540,"elapsed":217,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"f0ec0896-a878-474b-d97e-6f1962de367a"},"source":["pred = pd.DataFrame({\"実際の不動産価格\":y_test[:,0], \"予測した不動産価格\":pred_test[:,0]})\n","pred.head()\n"],"execution_count":75,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>実際の不動産価格</th>\n","      <th>予測した不動産価格</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>154500</td>\n","      <td>135481.328125</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>325000</td>\n","      <td>293833.531250</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>115000</td>\n","      <td>97429.656250</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>159000</td>\n","      <td>169295.859375</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>315500</td>\n","      <td>223569.140625</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   実際の不動産価格      予測した不動産価格\n","0    154500  135481.328125\n","1    325000  293833.531250\n","2    115000   97429.656250\n","3    159000  169295.859375\n","4    315500  223569.140625"]},"metadata":{},"execution_count":75}]},{"cell_type":"markdown","metadata":{"id":"wvPygU9QJ1hX"},"source":["【問題4回答まとめ】House Pricesのモデルを作成 回帰問題のデータセットであるHouse Pricesを使用したモデルを作成して、学習させて、住宅価格の正解値と予想値を比較した。\n","\n","分類問題と回帰問題の違いを考慮してください。\n","初めに、分類問題のアヤメのコードと同様な流れで解こうとしたが、出来なかった。そこで、有名なボストンの住宅価格のコードを参考にして解いたら住宅価格が予測できた。つまり、この問題は、回帰問題でない回答できないことが分かった。"]},{"cell_type":"code","metadata":{"id":"_bPMsYPtEl5d"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ePEMNzyD9uoL","executionInfo":{"status":"ok","timestamp":1629941746652,"user_tz":-540,"elapsed":247,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}}},"source":[""],"execution_count":56,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LNaBp2Vua0Wl"},"source":["【問題5】MNISTのモデルを作成\n","ニューラルネットワークのスクラッチで使用したMNISTを分類するモデルを作成してください。\n","\n","\n","3クラス以上の分類という点ではひとつ前のIrisと同様です。入力が画像であるという点で異なります。\n","\n","\n","スクラッチで実装したモデルの再現を目指してください。"]},{"cell_type":"code","metadata":{"id":"qbLz4XuyOPNx","executionInfo":{"status":"ok","timestamp":1629943996628,"user_tz":-540,"elapsed":347,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}}},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"],"execution_count":82,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"OIeCvqZyOPVZ","executionInfo":{"status":"ok","timestamp":1629944000791,"user_tz":-540,"elapsed":1143,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"de384501-5424-46b4-9142-d3aaeb8947d1"},"source":["import numpy as np\n","from keras.datasets import mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","\n","print(X_train.shape) # (60000, 28, 28)\n","print(X_test.shape) # (10000, 28, 28)\n","print(X_train[0].dtype) # uint8\n","print(X_train[0])\n","\n","X_train = X_train.reshape(-1, 784)\n","X_test = X_test.reshape(-1, 784)\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","index = 0\n","image = X_train[index].reshape(28,28)\n","# X_train[index]: (784,)\n","# image: (28, 28)\n","plt.imshow(image, 'gray')\n","plt.title('label : {}'.format(y_train[index]))\n","plt.show()\n","\n","index = 0\n","image = X_train[index].reshape(28,28)\n","image = image.astype(np.float) # float型に変換\n","image -= 105.35 # 意図的に負の小数値を作り出してみる\n","plt.imshow(image, 'gray')\n","plt.title('label : {}'.format(y_train[index]))\n","plt.show()\n","print(image) # 値を確認\n","\n","plt.imshow(image, 'gray', vmin = 0, vmax = 255)\n","\n","\n","X_train = X_train.astype(np.float)\n","X_test = X_test.astype(np.float)\n","X_train /= 255\n","X_test /= 255\n","print(X_train.max()) # 1.0\n","print(X_train.min()) # 0.0"],"execution_count":83,"outputs":[{"output_type":"stream","text":["(60000, 28, 28)\n","(10000, 28, 28)\n","uint8\n","[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n","  175  26 166 255 247 127   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n","  225 172 253 242 195  64   0   0   0   0]\n"," [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n","   93  82  82  56  39   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n","   25   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n","  150  27   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n","  253 187   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n","  253 249  64   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n","  253 207   2   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n","  250 182   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n","   78   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]]\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"stream","text":["[[-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -102.35  -87.35  -87.35  -87.35   20.65   30.65\n","    69.65  -79.35   60.65  149.65  141.65   21.65 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -75.35\n","   -69.35  -11.35   48.65   64.65  147.65  147.65  147.65  147.65  147.65\n","   119.65   66.65  147.65  136.65   89.65  -41.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -56.35  132.65\n","   147.65  147.65  147.65  147.65  147.65  147.65  147.65  147.65  145.65\n","   -12.35  -23.35  -23.35  -49.35  -66.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35  113.65\n","   147.65  147.65  147.65  147.65  147.65   92.65   76.65  141.65  135.65\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -25.35\n","    50.65    1.65  147.65  147.65   99.65  -94.35 -105.35  -62.35   48.65\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","   -91.35 -104.35   48.65  147.65  -15.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35   33.65  147.65   84.65 -103.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35  -94.35   84.65  147.65  -35.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35  -70.35  135.65  119.65   54.65    2.65 -104.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35  -24.35  134.65  147.65  147.65   13.65\n","   -80.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35  -60.35   80.65  147.65  147.65\n","    44.65  -78.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -89.35  -12.35  146.65\n","   147.65   81.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  143.65\n","   147.65  143.65  -41.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35  -59.35   24.65   77.65  147.65\n","   147.65  101.65 -103.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35  -66.35   42.65  123.65  147.65  147.65  147.65\n","   144.65   76.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35  -81.35    8.65  115.65  147.65  147.65  147.65  147.65   95.65\n","   -27.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -82.35\n","   -39.35  107.65  147.65  147.65  147.65  147.65   92.65  -24.35 -103.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35   65.65  113.65\n","   147.65  147.65  147.65  147.65   89.65  -25.35  -96.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35  -50.35   66.65  120.65  147.65  147.65\n","   147.65  147.65  138.65   27.65  -94.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35   30.65  147.65  147.65  147.65  106.65\n","    29.65   26.65  -89.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]\n"," [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n","  -105.35]]\n","1.0\n","0.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I-xvAY_VOPb7","executionInfo":{"status":"ok","timestamp":1629944006875,"user_tz":-540,"elapsed":207,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"cad6a7f7-6fb5-458e-eb2a-34b35c5fb981"},"source":["from sklearn.preprocessing import OneHotEncoder\n","enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n","y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n","y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n","print(y_train.shape) # (60000,)\n","print(y_train_one_hot.shape) # (60000, 10)\n","print(y_train_one_hot.dtype) # float64"],"execution_count":84,"outputs":[{"output_type":"stream","text":["(60000,)\n","(60000, 10)\n","float64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f1f7q7QqOPip","executionInfo":{"status":"ok","timestamp":1629944009866,"user_tz":-540,"elapsed":327,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"9fd15fbb-303b-4a70-f929-b9accbf53c2c"},"source":["x_train, x_test, y_train, y_test= train_test_split(X_train, y_train, test_size=0.2)\n","print(x_train.shape) # (48000, 784)\n","print(x_test.shape) # (12000, 784)"],"execution_count":85,"outputs":[{"output_type":"stream","text":["(48000, 784)\n","(12000, 784)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-BTz_-4Va0hL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629945993269,"user_tz":-540,"elapsed":29809,"user":{"displayName":"木村剛","photoUrl":"","userId":"13118920826758032389"}},"outputId":"9c398133-e422-42b1-e03e-8c1af0b81870"},"source":["import tensorflow as tf\n","import numpy as np\n","\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n","\n","#255の整数値だが，0〜1の実数に変換する：\n","x_train, x_test = x_train / 255.0, x_test / 255.0\n","\n","#簡単なモデルを定義\n","model = tf.keras.models.Sequential([\n","  tf.keras.layers.Flatten(input_shape=(28, 28)),\n","  tf.keras.layers.Dense(128, activation='relu'),\n","  tf.keras.layers.Dropout(0.2),\n","  tf.keras.layers.Dense(10)\n","])\n","\n","loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","model.compile(optimizer='adam',\n","              loss=loss_fn,\n","              metrics=['accuracy'])\n","\n","#学習\n","model.fit(x_train, y_train, epochs=5)\n","\n","#評価\n","model.evaluate(x_test, y_test)\n","\n","#予測\n","# y_pred = tf.argmax(model.predict(x_test), axis=-1).numpy()"],"execution_count":96,"outputs":[{"output_type":"stream","text":["Train on 60000 samples\n","Epoch 1/5\n","60000/60000 [==============================] - 5s 86us/sample - loss: 0.2958 - accuracy: 0.9131\n","Epoch 2/5\n","60000/60000 [==============================] - 5s 91us/sample - loss: 0.1422 - accuracy: 0.9583\n","Epoch 3/5\n","60000/60000 [==============================] - 5s 91us/sample - loss: 0.1057 - accuracy: 0.9675\n","Epoch 4/5\n","60000/60000 [==============================] - 5s 90us/sample - loss: 0.0871 - accuracy: 0.9725\n","Epoch 5/5\n","60000/60000 [==============================] - 5s 91us/sample - loss: 0.0759 - accuracy: 0.9755\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["[0.0757194505580701, 0.9757]"]},"metadata":{},"execution_count":96}]}]}